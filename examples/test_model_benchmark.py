#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ¨¡å‹åŸºå‡†æµ‹è¯•ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ¨¡å‹åŸºå‡†æµ‹è¯•æ¡†æ¶è¯„ä¼°å’Œæ¯”è¾ƒä¸åŒçš„é¢„æµ‹ç®—æ³•
"""

import os
import sys
import numpy as np
from typing import List, Tuple, Dict
from collections import Counter

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from core_modules import logger_manager, data_manager, cache_manager

# å¯¼å…¥æ¨¡å‹åŸºå‡†æµ‹è¯•æ¡†æ¶
from improvements.model_benchmark import get_model_benchmark

# å¯¼å…¥é¢„æµ‹å™¨
try:
    from predictor_modules import get_traditional_predictor, get_advanced_predictor
    PREDICTORS_AVAILABLE = True
except ImportError:
    PREDICTORS_AVAILABLE = False
    print("âš ï¸ é¢„æµ‹å™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿé¢„æµ‹å™¨")

# å¯¼å…¥å¢å¼ºé©¬å°”å¯å¤«é¢„æµ‹å™¨
try:
    from improvements.enhanced_markov import get_markov_predictor
    ENHANCED_MARKOV_AVAILABLE = True
except ImportError:
    ENHANCED_MARKOV_AVAILABLE = False
    print("âš ï¸ å¢å¼ºé©¬å°”å¯å¤«æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†è·³è¿‡ç›¸å…³æµ‹è¯•")

# å¯¼å…¥LSTMé¢„æµ‹å™¨
try:
    from advanced_lstm_predictor import AdvancedLSTMPredictor, TENSORFLOW_AVAILABLE
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("âš ï¸ LSTMé¢„æµ‹å™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†è·³è¿‡ç›¸å…³æµ‹è¯•")

# å¯¼å…¥é«˜çº§é›†æˆé¢„æµ‹å™¨
try:
    from improvements.advanced_ensemble import AdvancedEnsemblePredictor
    ADVANCED_ENSEMBLE_AVAILABLE = True
except ImportError:
    ADVANCED_ENSEMBLE_AVAILABLE = False
    print("âš ï¸ é«˜çº§é›†æˆé¢„æµ‹å™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†è·³è¿‡ç›¸å…³æµ‹è¯•")


def mock_random_predict(historical_data) -> List[Tuple[List[int], List[int]]]:
    """éšæœºé¢„æµ‹ï¼ˆåŸºå‡†æ¨¡å‹ï¼‰"""
    return [(sorted(np.random.choice(range(1, 36), 5, replace=False)), 
            sorted(np.random.choice(range(1, 13), 2, replace=False))) for _ in range(3)]


def mock_frequency_predict(historical_data) -> List[Tuple[List[int], List[int]]]:
    """é¢‘ç‡é¢„æµ‹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    front_counter = Counter()
    back_counter = Counter()
    
    for _, row in historical_data.iterrows():
        front_balls, back_balls = data_manager.parse_balls(row)
        front_counter.update(front_balls)
        back_counter.update(back_balls)
    
    front_most_common = [ball for ball, _ in front_counter.most_common(5)]
    back_most_common = [ball for ball, _ in back_counter.most_common(2)]
    
    return [(sorted(front_most_common), sorted(back_most_common)) for _ in range(3)]


def mock_hot_cold_predict(historical_data) -> List[Tuple[List[int], List[int]]]:
    """å†·çƒ­å·é¢„æµ‹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    # è®¡ç®—é¢‘ç‡
    front_counter = Counter()
    back_counter = Counter()
    
    # ä½¿ç”¨æœ€è¿‘100æœŸæ•°æ®
    recent_data = historical_data.head(100)
    for _, row in recent_data.iterrows():
        front_balls, back_balls = data_manager.parse_balls(row)
        front_counter.update(front_balls)
        back_counter.update(back_balls)
    
    # è®¡ç®—å¹³å‡é¢‘ç‡
    front_avg = sum(front_counter.values()) / len(front_counter) if front_counter else 0
    back_avg = sum(back_counter.values()) / len(back_counter) if back_counter else 0
    
    # çƒ­å·ï¼ˆé«˜äºå¹³å‡é¢‘ç‡ï¼‰
    front_hot = [ball for ball, count in front_counter.items() if count > front_avg]
    back_hot = [ball for ball, count in back_counter.items() if count > back_avg]
    
    # å†·å·ï¼ˆä½äºå¹³å‡é¢‘ç‡ï¼‰
    front_cold = [ball for ball, count in front_counter.items() if count <= front_avg]
    back_cold = [ball for ball, count in back_counter.items() if count <= back_avg]
    
    # ç»„åˆçƒ­å·å’Œå†·å·
    predictions = []
    for _ in range(3):
        # é€‰æ‹©3ä¸ªçƒ­å·å’Œ2ä¸ªå†·å·
        front_selected = []
        if len(front_hot) >= 3:
            front_selected.extend(np.random.choice(front_hot, 3, replace=False))
        else:
            front_selected.extend(front_hot)
            front_selected.extend(np.random.choice(front_cold, 3 - len(front_hot), replace=False))
        
        # è¡¥å……å†·å·
        remaining_cold = [b for b in front_cold if b not in front_selected]
        if len(remaining_cold) >= 2:
            front_selected.extend(np.random.choice(remaining_cold, 2, replace=False))
        else:
            front_selected.extend(remaining_cold)
            # å¦‚æœå†·å·ä¸è¶³ï¼Œä»æ‰€æœ‰å·ç ä¸­éšæœºé€‰æ‹©
            all_balls = list(range(1, 36))
            remaining_balls = [b for b in all_balls if b not in front_selected]
            front_selected.extend(np.random.choice(remaining_balls, 2 - len(remaining_cold), replace=False))
        
        # ååŒºé€‰æ‹©1ä¸ªçƒ­å·å’Œ1ä¸ªå†·å·
        back_selected = []
        if back_hot:
            back_selected.append(np.random.choice(back_hot))
        else:
            back_selected.append(np.random.choice(range(1, 13)))
        
        remaining_cold = [b for b in back_cold if b not in back_selected]
        if remaining_cold:
            back_selected.append(np.random.choice(remaining_cold))
        else:
            remaining_balls = [b for b in range(1, 13) if b not in back_selected]
            back_selected.append(np.random.choice(remaining_balls))
        
        predictions.append((sorted(front_selected), sorted(back_selected)))
    
    return predictions


def mock_missing_predict(historical_data) -> List[Tuple[List[int], List[int]]]:
    """é—æ¼å€¼é¢„æµ‹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    # è®¡ç®—é—æ¼å€¼
    front_missing = {i: 0 for i in range(1, 36)}
    back_missing = {i: 0 for i in range(1, 13)}
    
    # ä½¿ç”¨æœ€è¿‘100æœŸæ•°æ®
    recent_data = historical_data.head(100)
    for _, row in recent_data.iterrows():
        front_balls, back_balls = data_manager.parse_balls(row)
        
        # æ›´æ–°é—æ¼å€¼
        for ball in range(1, 36):
            if ball in front_balls:
                front_missing[ball] = 0
            else:
                front_missing[ball] += 1
        
        for ball in range(1, 13):
            if ball in back_balls:
                back_missing[ball] = 0
            else:
                back_missing[ball] += 1
    
    # é€‰æ‹©é—æ¼å€¼æœ€å¤§çš„å·ç 
    front_sorted = sorted(front_missing.items(), key=lambda x: x[1], reverse=True)
    back_sorted = sorted(back_missing.items(), key=lambda x: x[1], reverse=True)
    
    front_selected = [ball for ball, _ in front_sorted[:5]]
    back_selected = [ball for ball, _ in back_sorted[:2]]
    
    return [(sorted(front_selected), sorted(back_selected)) for _ in range(3)]


def register_real_predictors(benchmark):
    """æ³¨å†Œå®é™…é¢„æµ‹å™¨"""
    if not PREDICTORS_AVAILABLE:
        return False
    
    # è·å–é¢„æµ‹å™¨å®ä¾‹
    traditional = get_traditional_predictor()
    advanced = get_advanced_predictor()
    
    # æ³¨å†Œä¼ ç»Ÿé¢„æµ‹å™¨
    benchmark.register_model(
        "é¢‘ç‡é¢„æµ‹(å®é™…)", 
        lambda data: traditional.frequency_predict(3), 
        "åŸºäºå†å²é¢‘ç‡çš„é¢„æµ‹æ–¹æ³•", 
        "traditional"
    )
    
    benchmark.register_model(
        "å†·çƒ­å·é¢„æµ‹(å®é™…)", 
        lambda data: traditional.hot_cold_predict(3), 
        "åŸºäºå†·çƒ­å·çš„é¢„æµ‹æ–¹æ³•", 
        "traditional"
    )
    
    benchmark.register_model(
        "é—æ¼å€¼é¢„æµ‹(å®é™…)", 
        lambda data: traditional.missing_predict(3), 
        "åŸºäºé—æ¼å€¼çš„é¢„æµ‹æ–¹æ³•", 
        "traditional"
    )
    
    # æ³¨å†Œé«˜çº§é¢„æµ‹å™¨
    benchmark.register_model(
        "é©¬å°”å¯å¤«é¢„æµ‹", 
        lambda data: advanced.markov_predict(3), 
        "åŸºäºé©¬å°”å¯å¤«é“¾çš„é¢„æµ‹æ–¹æ³•", 
        "advanced"
    )
    
    benchmark.register_model(
        "è´å¶æ–¯é¢„æµ‹", 
        lambda data: advanced.bayesian_predict(3), 
        "åŸºäºè´å¶æ–¯åˆ†æçš„é¢„æµ‹æ–¹æ³•", 
        "advanced"
    )
    
    benchmark.register_model(
        "é›†æˆé¢„æµ‹", 
        lambda data: advanced.ensemble_predict(3), 
        "åŸºäºå¤šç§ç®—æ³•é›†æˆçš„é¢„æµ‹æ–¹æ³•", 
        "advanced"
    )
    
    return True


def register_enhanced_predictors(benchmark):
    """æ³¨å†Œå¢å¼ºé¢„æµ‹å™¨"""
    registered_count = 0
    
    # æ³¨å†Œå¢å¼ºé©¬å°”å¯å¤«é¢„æµ‹å™¨
    if ENHANCED_MARKOV_AVAILABLE:
        markov_predictor = get_markov_predictor()
        
        benchmark.register_model(
            "äºŒé˜¶é©¬å°”å¯å¤«", 
            lambda data: markov_predictor.multi_order_markov_predict(3, 300, 2), 
            "åŸºäºäºŒé˜¶é©¬å°”å¯å¤«é“¾çš„é¢„æµ‹æ–¹æ³•", 
            "enhanced"
        )
        
        benchmark.register_model(
            "ä¸‰é˜¶é©¬å°”å¯å¤«", 
            lambda data: markov_predictor.multi_order_markov_predict(3, 300, 3), 
            "åŸºäºä¸‰é˜¶é©¬å°”å¯å¤«é“¾çš„é¢„æµ‹æ–¹æ³•", 
            "enhanced"
        )
        
        benchmark.register_model(
            "è‡ªé€‚åº”é©¬å°”å¯å¤«", 
            lambda data: [tuple([pred['front_balls'], pred['back_balls']]) for pred in 
                         markov_predictor.adaptive_order_markov_predict(3, 300)], 
            "åŸºäºè‡ªé€‚åº”é˜¶æ•°é©¬å°”å¯å¤«é“¾çš„é¢„æµ‹æ–¹æ³•", 
            "enhanced"
        )
        
        registered_count += 3
    
    # æ³¨å†ŒLSTMé¢„æµ‹å™¨
    if TENSORFLOW_AVAILABLE:
        try:
            lstm_predictor = AdvancedLSTMPredictor()
            
            benchmark.register_model(
                "LSTMæ·±åº¦å­¦ä¹ ", 
                lambda data: lstm_predictor.lstm_predict(3), 
                "åŸºäºLSTMæ·±åº¦å­¦ä¹ çš„é¢„æµ‹æ–¹æ³•", 
                "deep_learning"
            )
            
            registered_count += 1
        except Exception as e:
            print(f"âš ï¸ LSTMé¢„æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # æ³¨å†Œé«˜çº§é›†æˆé¢„æµ‹å™¨
    if ADVANCED_ENSEMBLE_AVAILABLE and PREDICTORS_AVAILABLE:
        try:
            ensemble = AdvancedEnsemblePredictor()
            traditional = get_traditional_predictor()
            advanced = get_advanced_predictor()
            
            # æ³¨å†ŒåŸºç¡€é¢„æµ‹å™¨
            ensemble.register_predictor('frequency', traditional, weight=0.3)
            ensemble.register_predictor('markov', advanced, weight=0.4)
            ensemble.register_predictor('bayesian', advanced, weight=0.3)
            
            benchmark.register_model(
                "Stackingé›†æˆ", 
                lambda data: ensemble.stacking_predict(3), 
                "åŸºäºStackingçš„é›†æˆé¢„æµ‹æ–¹æ³•", 
                "ensemble"
            )
            
            benchmark.register_model(
                "åŠ æƒé›†æˆ", 
                lambda data: ensemble.weighted_ensemble_predict(3), 
                "åŸºäºæƒé‡çš„é›†æˆé¢„æµ‹æ–¹æ³•", 
                "ensemble"
            )
            
            benchmark.register_model(
                "è‡ªé€‚åº”é›†æˆ", 
                lambda data: ensemble.adaptive_ensemble_predict(3), 
                "åŸºäºè‡ªé€‚åº”æƒé‡çš„é›†æˆé¢„æµ‹æ–¹æ³•", 
                "ensemble"
            )
            
            registered_count += 3
        except Exception as e:
            print(f"âš ï¸ é«˜çº§é›†æˆé¢„æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    return registered_count


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ¨¡å‹åŸºå‡†æµ‹è¯•...")
    
    # è·å–åŸºå‡†æµ‹è¯•å®ä¾‹
    benchmark = get_model_benchmark()
    
    # æ³¨å†Œæ¨¡æ‹Ÿé¢„æµ‹å™¨
    print("\nğŸ“ æ³¨å†Œæ¨¡æ‹Ÿé¢„æµ‹å™¨...")
    benchmark.register_model("éšæœºé¢„æµ‹", mock_random_predict, "å®Œå…¨éšæœºçš„é¢„æµ‹æ–¹æ³•", "baseline")
    benchmark.register_model("é¢‘ç‡é¢„æµ‹(æ¨¡æ‹Ÿ)", mock_frequency_predict, "åŸºäºå†å²é¢‘ç‡çš„æ¨¡æ‹Ÿé¢„æµ‹æ–¹æ³•", "mock")
    benchmark.register_model("å†·çƒ­å·é¢„æµ‹(æ¨¡æ‹Ÿ)", mock_hot_cold_predict, "åŸºäºå†·çƒ­å·çš„æ¨¡æ‹Ÿé¢„æµ‹æ–¹æ³•", "mock")
    benchmark.register_model("é—æ¼å€¼é¢„æµ‹(æ¨¡æ‹Ÿ)", mock_missing_predict, "åŸºäºé—æ¼å€¼çš„æ¨¡æ‹Ÿé¢„æµ‹æ–¹æ³•", "mock")
    
    # æ³¨å†Œå®é™…é¢„æµ‹å™¨
    print("\nğŸ“ æ³¨å†Œå®é™…é¢„æµ‹å™¨...")
    real_registered = register_real_predictors(benchmark)
    if real_registered:
        print(f"âœ… æˆåŠŸæ³¨å†Œå®é™…é¢„æµ‹å™¨")
    else:
        print(f"âš ï¸ å®é™…é¢„æµ‹å™¨æ³¨å†Œå¤±è´¥ï¼Œå°†ä»…ä½¿ç”¨æ¨¡æ‹Ÿé¢„æµ‹å™¨")
    
    # æ³¨å†Œå¢å¼ºé¢„æµ‹å™¨
    print("\nğŸ“ æ³¨å†Œå¢å¼ºé¢„æµ‹å™¨...")
    enhanced_count = register_enhanced_predictors(benchmark)
    if enhanced_count > 0:
        print(f"âœ… æˆåŠŸæ³¨å†Œ {enhanced_count} ä¸ªå¢å¼ºé¢„æµ‹å™¨")
    else:
        print(f"âš ï¸ å¢å¼ºé¢„æµ‹å™¨æ³¨å†Œå¤±è´¥ï¼Œå°†ä»…ä½¿ç”¨åŸºç¡€é¢„æµ‹å™¨")
    
    # è®¾ç½®æµ‹è¯•å‚æ•°
    test_periods = 20  # æµ‹è¯•æœŸæ•°
    
    # è¯„ä¼°æ‰€æœ‰æ¨¡å‹
    print(f"\nğŸ“Š è¯„ä¼°æ‰€æœ‰æ¨¡å‹ (æµ‹è¯•æœŸæ•°: {test_periods})...")
    benchmark.evaluate_all_models(test_periods=test_periods, verbose=True)
    
    # æ¯”è¾ƒæ¨¡å‹
    print("\nğŸ”„ æ¯”è¾ƒæ¨¡å‹...")
    benchmark.compare_models(verbose=True)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“ ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
    report_path = "output/model_benchmark_report.md"
    benchmark.generate_report(report_path)
    print(f"âœ… è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    # å¯è§†åŒ–æ¯”è¾ƒ
    print("\nğŸ“ˆ å¯è§†åŒ–æ¨¡å‹æ¯”è¾ƒ...")
    comparison_path = "output/model_comparison.png"
    benchmark.visualize_comparison(output_path=comparison_path)
    print(f"âœ… æ¯”è¾ƒå›¾è¡¨å·²ä¿å­˜åˆ°: {comparison_path}")
    
    # å¯è§†åŒ–æœ€ä½³æ¨¡å‹æ€§èƒ½
    if benchmark.comparison and 'overall_ranking' in benchmark.comparison:
        best_model = next(iter(benchmark.comparison['overall_ranking'].keys()), None)
        if best_model:
            print(f"\nğŸ“Š å¯è§†åŒ–æœ€ä½³æ¨¡å‹ ({best_model}) æ€§èƒ½...")
            performance_path = f"output/{best_model}_performance.png"
            benchmark.visualize_model_performance(best_model, output_path=performance_path)
            print(f"âœ… æ€§èƒ½å›¾è¡¨å·²ä¿å­˜åˆ°: {performance_path}")
    
    # ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ä¿å­˜è¯„ä¼°ç»“æœ...")
    results_path = "output/model_benchmark_results.json"
    benchmark.save_results(results_path)
    print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    print("\nâœ… æ¨¡å‹åŸºå‡†æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs("output", exist_ok=True)
    
    # è¿è¡Œä¸»å‡½æ•°
    main()