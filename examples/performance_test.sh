#!/bin/bash

# æ€§èƒ½æµ‹è¯•è„šæœ¬
# ç”¨äºæµ‹è¯•ä¸åŒæ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡

# è®¾ç½®æ—¥æœŸ
DATE=$(date +"%Y%m%d")
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_DIR="output/performance_${DATE}"
mkdir -p ${OUTPUT_DIR}

echo "âš¡ å¼€å§‹æ€§èƒ½æµ‹è¯•æµç¨‹ (${DATE})"

# æµ‹è¯•å‚æ•°
TEST_PERIODS=(10 20 50 100)
CATEGORIES=("traditional" "advanced" "enhanced" "deep_learning" "ensemble")

# è¿è¡Œæ¨¡å‹åŸºå‡†æµ‹è¯•
for periods in "${TEST_PERIODS[@]}"; do
    echo "ğŸ” è¿è¡Œæ¨¡å‹åŸºå‡†æµ‹è¯• (æµ‹è¯•æœŸæ•°: ${periods})..."
    python3 improvements/model_evaluation_cli.py benchmark \
      --register-default \
      --predictor-config examples/predictors_config.json \
      --evaluate-all \
      --test-periods ${periods} \
      --compare \
      --report "${OUTPUT_DIR}/benchmark_report_${periods}_${TIMESTAMP}.md" \
      --visualize-comparison "${OUTPUT_DIR}/model_comparison_${periods}_${TIMESTAMP}.png" \
      --save-results "${OUTPUT_DIR}/benchmark_results_${periods}_${TIMESTAMP}.json" \
      --output-dir ${OUTPUT_DIR}
done

# æ¯”è¾ƒä¸åŒç±»åˆ«çš„æ¨¡å‹
for category in "${CATEGORIES[@]}"; do
    echo "ğŸ”„ æ¯”è¾ƒ ${category} ç±»åˆ«çš„æ¨¡å‹..."
    python3 improvements/model_evaluation_cli.py benchmark \
      --load-results "${OUTPUT_DIR}/benchmark_results_50_${TIMESTAMP}.json" \
      --compare \
      --categories ${category} \
      --visualize-comparison "${OUTPUT_DIR}/model_comparison_${category}_${TIMESTAMP}.png" \
      --output-dir ${OUTPUT_DIR}
done

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
echo "ğŸ“Š ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š..."
python3 -c "
import json
import pandas as pd
import matplotlib.pyplot as plt
import os

# åŠ è½½ä¸åŒæœŸæ•°çš„æµ‹è¯•ç»“æœ
results = {}
for periods in [10, 20, 50, 100]:
    try:
        with open('${OUTPUT_DIR}/benchmark_results_{}_${TIMESTAMP}.json'.format(periods), 'r') as f:
            results[periods] = json.load(f)
    except:
        print('æ— æ³•åŠ è½½ {} æœŸæµ‹è¯•ç»“æœ'.format(periods))

# æå–æ€§èƒ½æ•°æ®
performance_data = {}
for periods, result in results.items():
    if 'results' in result:
        for model_name, model_info in result['results'].items():
            if model_name not in performance_data:
                performance_data[model_name] = {'periods': [], 'accuracy': [], 'time': [], 'category': model_info.get('category', 'unknown')}
            
            performance_data[model_name]['periods'].append(periods)
            performance_data[model_name]['accuracy'].append(model_info.get('metrics', {}).get('accuracy', 0))
            performance_data[model_name]['time'].append(model_info.get('avg_prediction_time', 0))

# åˆ›å»ºæ€§èƒ½æŠ¥å‘Š
report = ['# æ¨¡å‹æ€§èƒ½æµ‹è¯•æŠ¥å‘Š', '', '## æµ‹è¯•æ—¥æœŸ: ${TIMESTAMP}', '']

# æ·»åŠ å‡†ç¡®ç‡éšæµ‹è¯•æœŸæ•°å˜åŒ–çš„è¡¨æ ¼
report.append('## å‡†ç¡®ç‡éšæµ‹è¯•æœŸæ•°å˜åŒ–')
report.append('')
report.append('| æ¨¡å‹åç§° | ç±»åˆ« | 10æœŸ | 20æœŸ | 50æœŸ | 100æœŸ |')
report.append('| --- | --- | --- | --- | --- | --- |')

for model_name, data in sorted(performance_data.items(), key=lambda x: x[0]):
    accuracy_values = []
    for periods in [10, 20, 50, 100]:
        if periods in data['periods']:
            idx = data['periods'].index(periods)
            accuracy_values.append('{:.4f}'.format(data['accuracy'][idx]))
        else:
            accuracy_values.append('N/A')
    
    report.append('| {} | {} | {} | {} | {} | {} |'.format(
        model_name, data['category'], *accuracy_values
    ))

# æ·»åŠ é¢„æµ‹æ—¶é—´éšæµ‹è¯•æœŸæ•°å˜åŒ–çš„è¡¨æ ¼
report.append('')
report.append('## é¢„æµ‹æ—¶é—´éšæµ‹è¯•æœŸæ•°å˜åŒ– (ç§’)')
report.append('')
report.append('| æ¨¡å‹åç§° | ç±»åˆ« | 10æœŸ | 20æœŸ | 50æœŸ | 100æœŸ |')
report.append('| --- | --- | --- | --- | --- | --- |')

for model_name, data in sorted(performance_data.items(), key=lambda x: x[0]):
    time_values = []
    for periods in [10, 20, 50, 100]:
        if periods in data['periods']:
            idx = data['periods'].index(periods)
            time_values.append('{:.4f}'.format(data['time'][idx]))
        else:
            time_values.append('N/A')
    
    report.append('| {} | {} | {} | {} | {} | {} |'.format(
        model_name, data['category'], *time_values
    ))

# ä¿å­˜æŠ¥å‘Š
with open('${OUTPUT_DIR}/performance_report_${TIMESTAMP}.md', 'w') as f:
    f.write('\n'.join(report))

# åˆ›å»ºå‡†ç¡®ç‡å¯¹æ¯”å›¾
plt.figure(figsize=(12, 8))
for model_name, data in performance_data.items():
    if len(data['periods']) >= 2:  # è‡³å°‘æœ‰ä¸¤ä¸ªæ•°æ®ç‚¹æ‰èƒ½ç”»çº¿
        plt.plot(data['periods'], data['accuracy'], marker='o', label=model_name)

plt.title('æ¨¡å‹å‡†ç¡®ç‡éšæµ‹è¯•æœŸæ•°å˜åŒ–')
plt.xlabel('æµ‹è¯•æœŸæ•°')
plt.ylabel('å‡†ç¡®ç‡')
plt.grid(True, alpha=0.3)
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
plt.tight_layout()
plt.savefig('${OUTPUT_DIR}/accuracy_comparison_${TIMESTAMP}.png', dpi=300)

# åˆ›å»ºé¢„æµ‹æ—¶é—´å¯¹æ¯”å›¾
plt.figure(figsize=(12, 8))
for model_name, data in performance_data.items():
    if len(data['periods']) >= 2:  # è‡³å°‘æœ‰ä¸¤ä¸ªæ•°æ®ç‚¹æ‰èƒ½ç”»çº¿
        plt.plot(data['periods'], data['time'], marker='o', label=model_name)

plt.title('æ¨¡å‹é¢„æµ‹æ—¶é—´éšæµ‹è¯•æœŸæ•°å˜åŒ–')
plt.xlabel('æµ‹è¯•æœŸæ•°')
plt.ylabel('é¢„æµ‹æ—¶é—´ (ç§’)')
plt.grid(True, alpha=0.3)
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
plt.tight_layout()
plt.savefig('${OUTPUT_DIR}/time_comparison_${TIMESTAMP}.png', dpi=300)

print('âœ… æ€§èƒ½æŠ¥å‘Šå·²ç”Ÿæˆ')
"

echo "âœ… æ€§èƒ½æµ‹è¯•æµç¨‹å®Œæˆ"
echo "ğŸ“ ç»“æœä¿å­˜åœ¨: ${OUTPUT_DIR}"