#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿ Python API ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•åœ¨Pythonä»£ç ä¸­ç›´æ¥ä½¿ç”¨ç³»ç»ŸåŠŸèƒ½
"""

import os
import sys
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥ç³»ç»Ÿæ¨¡å—
from core_modules import data_manager, cache_manager, logger_manager
from analyzer_modules import basic_analyzer, advanced_analyzer, comprehensive_analyzer
from predictor_modules import get_traditional_predictor, get_advanced_predictor, get_super_predictor
from adaptive_learning_modules import enhanced_adaptive_predictor


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºAPIä½¿ç”¨"""
    print("ğŸ¯ å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿ Python API ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. æ•°æ®ç®¡ç†ç¤ºä¾‹
    print("\nğŸ“Š 1. æ•°æ®ç®¡ç†ç¤ºä¾‹")
    data_example()
    
    # 2. æ•°æ®åˆ†æç¤ºä¾‹
    print("\nğŸ” 2. æ•°æ®åˆ†æç¤ºä¾‹")
    analysis_example()
    
    # 3. å·ç é¢„æµ‹ç¤ºä¾‹
    print("\nğŸ¯ 3. å·ç é¢„æµ‹ç¤ºä¾‹")
    prediction_example()
    
    # 4. è‡ªé€‚åº”å­¦ä¹ ç¤ºä¾‹
    print("\nğŸ§  4. è‡ªé€‚åº”å­¦ä¹ ç¤ºä¾‹")
    learning_example()
    
    # 5. ç¼“å­˜ç®¡ç†ç¤ºä¾‹
    print("\nğŸ’¾ 5. ç¼“å­˜ç®¡ç†ç¤ºä¾‹")
    cache_example()
    
    print("\nğŸ‰ APIä½¿ç”¨ç¤ºä¾‹å®Œæˆï¼")


def data_example():
    """æ•°æ®ç®¡ç†ç¤ºä¾‹"""
    print("è·å–æ•°æ®...")
    
    # è·å–æ•°æ®
    df = data_manager.get_data()
    if df is not None:
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} æœŸ")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = data_manager.get_stats()
        print(f"ğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        print(f"  æ€»æœŸæ•°: {stats.get('total_periods', 0)}")
        print(f"  æœ€æ–°æœŸå·: {stats.get('latest_issue', 'N/A')}")
        print(f"  æ•°æ®èŒƒå›´: {stats.get('date_range', {}).get('start', 'N/A')} åˆ° {stats.get('date_range', {}).get('end', 'N/A')}")
        
        # è§£ææœ€æ–°ä¸€æœŸå·ç 
        latest_row = df.iloc[0]
        front_balls, back_balls = data_manager.parse_balls(latest_row)
        print(f"ğŸ¯ æœ€æ–°å¼€å¥–: {' '.join([str(b).zfill(2) for b in front_balls])} + {' '.join([str(b).zfill(2) for b in back_balls])}")
    else:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")


def analysis_example():
    """æ•°æ®åˆ†æç¤ºä¾‹"""
    print("è¿›è¡Œæ•°æ®åˆ†æ...")
    
    try:
        # åŸºç¡€åˆ†æ
        print("ğŸ“Š åŸºç¡€åˆ†æ:")
        freq_result = basic_analyzer.frequency_analysis(500)
        if freq_result:
            front_freq = freq_result.get('front_frequency', {})
            if front_freq:
                top_front = sorted(front_freq.items(), key=lambda x: x[1], reverse=True)[:5]
                print(f"  å‰åŒºé«˜é¢‘å·ç : {[f'{num}({count}æ¬¡)' for num, count in top_front]}")
        
        # é«˜çº§åˆ†æ
        print("ğŸ§  é«˜çº§åˆ†æ:")
        markov_result = advanced_analyzer.markov_analysis(300)
        if markov_result:
            print("  é©¬å°”å¯å¤«é“¾åˆ†æå®Œæˆ")
        
        bayesian_result = advanced_analyzer.bayesian_analysis(300)
        if bayesian_result:
            print("  è´å¶æ–¯åˆ†æå®Œæˆ")
        
        # ç»¼åˆåˆ†æ
        print("ğŸ”¬ ç»¼åˆåˆ†æ:")
        comprehensive_result = comprehensive_analyzer.comprehensive_analysis(500)
        if comprehensive_result:
            print("  ç»¼åˆåˆ†æå®Œæˆ")
            
            # ä¿å­˜åˆ†æç»“æœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"output/reports/api_analysis_{timestamp}.json"
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_result, f, ensure_ascii=False, indent=2, default=str)
            print(f"  åˆ†æç»“æœå·²ä¿å­˜: {filename}")
    
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")


def prediction_example():
    """å·ç é¢„æµ‹ç¤ºä¾‹"""
    print("è¿›è¡Œå·ç é¢„æµ‹...")
    
    try:
        # ä¼ ç»Ÿé¢„æµ‹
        print("ğŸ“Š ä¼ ç»Ÿé¢„æµ‹:")
        traditional_predictor = get_traditional_predictor()
        
        freq_pred = traditional_predictor.frequency_predict(3)
        print(f"  é¢‘ç‡é¢„æµ‹ ({len(freq_pred)} æ³¨):")
        for i, (front, back) in enumerate(freq_pred):
            front_str = ' '.join([str(b).zfill(2) for b in front])
            back_str = ' '.join([str(b).zfill(2) for b in back])
            print(f"    ç¬¬ {i+1} æ³¨: {front_str} + {back_str}")
        
        # é«˜çº§é¢„æµ‹
        print("ğŸ§  é«˜çº§é¢„æµ‹:")
        advanced_predictor = get_advanced_predictor()
        
        ensemble_pred = advanced_predictor.ensemble_predict(2)
        print(f"  é›†æˆé¢„æµ‹ ({len(ensemble_pred)} æ³¨):")
        for i, (front, back) in enumerate(ensemble_pred):
            front_str = ' '.join([str(b).zfill(2) for b in front])
            back_str = ' '.join([str(b).zfill(2) for b in back])
            print(f"    ç¬¬ {i+1} æ³¨: {front_str} + {back_str}")
        
        # æ··åˆç­–ç•¥é¢„æµ‹
        print("ğŸ¯ æ··åˆç­–ç•¥é¢„æµ‹:")
        mixed_pred = advanced_predictor.mixed_strategy_predict(2, strategy='balanced')
        print(f"  å¹³è¡¡ç­–ç•¥ ({len(mixed_pred)} æ³¨):")
        for pred in mixed_pred:
            front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
            back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])
            print(f"    ç¬¬ {pred['index']} æ³¨: {front_str} + {back_str} (é£é™©: {pred['risk_level']})")
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        all_predictions = {
            'frequency': freq_pred,
            'ensemble': ensemble_pred,
            'mixed_strategy': mixed_pred,
            'timestamp': datetime.now().isoformat()
        }
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"output/predictions/api_predictions_{timestamp}.json"
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(all_predictions, f, ensure_ascii=False, indent=2, default=str)
        print(f"ğŸ“ é¢„æµ‹ç»“æœå·²ä¿å­˜: {filename}")
    
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")


def learning_example():
    """è‡ªé€‚åº”å­¦ä¹ ç¤ºä¾‹"""
    print("è¿›è¡Œè‡ªé€‚åº”å­¦ä¹ ...")
    
    try:
        # ç®€çŸ­çš„å­¦ä¹ ç¤ºä¾‹ï¼ˆå‡å°‘æœŸæ•°ä»¥èŠ‚çœæ—¶é—´ï¼‰
        print("ğŸ”„ å¼€å§‹å­¦ä¹  (UCB1ç®—æ³•, 20æœŸæµ‹è¯•)...")
        
        results = enhanced_adaptive_predictor.enhanced_adaptive_learning(
            start_period=100,
            test_periods=20,
            algorithm='ucb1'
        )
        
        if results:
            print("âœ… å­¦ä¹ å®Œæˆ!")
            print(f"  æµ‹è¯•æœŸæ•°: {results.get('total_periods', 0)}")
            print(f"  ä¸­å¥–ç‡: {results.get('win_rate', 0):.3f}")
            print(f"  æœ€ä¼˜é¢„æµ‹å™¨: {results.get('best_predictor', 'N/A')}")
            
            # åŸºäºå­¦ä¹ ç»“æœè¿›è¡Œæ™ºèƒ½é¢„æµ‹
            print("ğŸ¯ åŸºäºå­¦ä¹ ç»“æœè¿›è¡Œæ™ºèƒ½é¢„æµ‹...")
            smart_pred = enhanced_adaptive_predictor.smart_predict(3)
            
            if smart_pred:
                print(f"  æ™ºèƒ½é¢„æµ‹ ({len(smart_pred)} æ³¨):")
                for i, pred in enumerate(smart_pred):
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])
                    confidence = pred.get('confidence', 0)
                    print(f"    ç¬¬ {i+1} æ³¨: {front_str} + {back_str} (ç½®ä¿¡åº¦: {confidence:.3f})")
            
            # ä¿å­˜å­¦ä¹ ç»“æœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"output/learning/api_learning_{timestamp}.json"
            enhanced_adaptive_predictor.save_enhanced_results(filename)
            print(f"ğŸ“ å­¦ä¹ ç»“æœå·²ä¿å­˜: {filename}")
        else:
            print("âŒ å­¦ä¹ å¤±è´¥")
    
    except Exception as e:
        print(f"âŒ å­¦ä¹ å¤±è´¥: {e}")


def cache_example():
    """ç¼“å­˜ç®¡ç†ç¤ºä¾‹"""
    print("ç¼“å­˜ç®¡ç†...")
    
    try:
        # è·å–ç¼“å­˜ä¿¡æ¯
        cache_info = cache_manager.get_cache_info()
        print("ğŸ“Š ç¼“å­˜ä¿¡æ¯:")
        
        for cache_type in ['models', 'analysis', 'data']:
            info = cache_info[cache_type]
            print(f"  {cache_type}: {info['files']} ä¸ªæ–‡ä»¶, {info['size_mb']:.2f} MB")
        
        print(f"  æ€»è®¡: {cache_info['total']['files']} ä¸ªæ–‡ä»¶, {cache_info['total']['size_mb']:.2f} MB")
        
        # æ¼”ç¤ºç¼“å­˜æ“ä½œ
        print("ğŸ’¾ ç¼“å­˜æ“ä½œæ¼”ç¤º:")
        
        # ä¿å­˜æµ‹è¯•æ•°æ®åˆ°ç¼“å­˜
        test_data = {'test': 'api_example', 'timestamp': datetime.now().isoformat()}
        cache_manager.save_cache('analysis', 'api_test', test_data)
        print("  ä¿å­˜æµ‹è¯•æ•°æ®åˆ°ç¼“å­˜")
        
        # ä»ç¼“å­˜åŠ è½½æ•°æ®
        loaded_data = cache_manager.load_cache('analysis', 'api_test')
        if loaded_data:
            print(f"  ä»ç¼“å­˜åŠ è½½æ•°æ®: {loaded_data}")
        
        # æ¸…ç†æµ‹è¯•ç¼“å­˜
        cache_manager.clear_cache('analysis')
        print("  æ¸…ç†åˆ†æç¼“å­˜")
    
    except Exception as e:
        print(f"âŒ ç¼“å­˜æ“ä½œå¤±è´¥: {e}")


def custom_analysis_example():
    """è‡ªå®šä¹‰åˆ†æç¤ºä¾‹"""
    print("\nğŸ”¬ 6. è‡ªå®šä¹‰åˆ†æç¤ºä¾‹")
    
    try:
        # è·å–æ•°æ®
        df = data_manager.get_data()
        if df is None:
            print("âŒ æ— æ³•è·å–æ•°æ®")
            return
        
        print("è¿›è¡Œè‡ªå®šä¹‰åˆ†æ...")
        
        # åˆ†ææœ€è¿‘100æœŸçš„å·ç åˆ†å¸ƒ
        recent_df = df.head(100)
        
        # ç»Ÿè®¡å‰åŒºå·ç é¢‘ç‡
        front_freq = {}
        back_freq = {}
        
        for _, row in recent_df.iterrows():
            front_balls, back_balls = data_manager.parse_balls(row)
            
            for ball in front_balls:
                front_freq[ball] = front_freq.get(ball, 0) + 1
            
            for ball in back_balls:
                back_freq[ball] = back_freq.get(ball, 0) + 1
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        print("ğŸ“Š æœ€è¿‘100æœŸåˆ†æç»“æœ:")
        
        # å‰åŒºçƒ­å·
        hot_front = sorted(front_freq.items(), key=lambda x: x[1], reverse=True)[:10]
        print(f"  å‰åŒºçƒ­å·: {[f'{num}({count})' for num, count in hot_front]}")
        
        # ååŒºçƒ­å·
        hot_back = sorted(back_freq.items(), key=lambda x: x[1], reverse=True)[:5]
        print(f"  ååŒºçƒ­å·: {[f'{num}({count})' for num, count in hot_back]}")
        
        # è®¡ç®—å¥‡å¶æ¯”
        odd_count = sum(1 for num in front_freq.keys() if num % 2 == 1)
        even_count = len(front_freq) - odd_count
        print(f"  å‰åŒºå¥‡å¶æ¯”: {odd_count}:{even_count}")
        
        # ä¿å­˜è‡ªå®šä¹‰åˆ†æç»“æœ
        custom_result = {
            'analysis_type': 'custom_recent_100',
            'front_frequency': front_freq,
            'back_frequency': back_freq,
            'hot_front': hot_front,
            'hot_back': hot_back,
            'odd_even_ratio': f"{odd_count}:{even_count}",
            'timestamp': datetime.now().isoformat()
        }
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"output/reports/custom_analysis_{timestamp}.json"
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(custom_result, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ“ è‡ªå®šä¹‰åˆ†æç»“æœå·²ä¿å­˜: {filename}")
    
    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰åˆ†æå¤±è´¥: {e}")


if __name__ == "__main__":
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs("output/reports", exist_ok=True)
    os.makedirs("output/predictions", exist_ok=True)
    os.makedirs("output/learning", exist_ok=True)
    
    # è¿è¡Œç¤ºä¾‹
    main()
    
    # è¿è¡Œè‡ªå®šä¹‰åˆ†æç¤ºä¾‹
    custom_analysis_example()
    
    print("\nğŸ’¡ æç¤º:")
    print("  - å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹æ­¤è„šæœ¬")
    print("  - æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶éƒ½ä¿å­˜åœ¨ output/ ç›®å½•ä¸‹")
    print("  - æŸ¥çœ‹å„æ¨¡å—çš„æºä»£ç äº†è§£æ›´å¤šAPIç”¨æ³•")
    print("  - ä½¿ç”¨ logger_manager è¿›è¡Œæ—¥å¿—è®°å½•")
    print("  - ä½¿ç”¨ cache_manager è¿›è¡Œç¼“å­˜ç®¡ç†")
