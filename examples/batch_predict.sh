#!/bin/bash

# æ‰¹é‡é¢„æµ‹è„šæœ¬
# ç”¨äºè¿è¡Œå¤šç§é¢„æµ‹ç®—æ³•å¹¶æ¯”è¾ƒç»“æœ

# è®¾ç½®æ—¥æœŸ
DATE=$(date +"%Y%m%d")
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_DIR="output/batch_${DATE}"
mkdir -p ${OUTPUT_DIR}

echo "ğŸš€ å¼€å§‹æ‰¹é‡é¢„æµ‹æµç¨‹ (${DATE})"

# è¿è¡Œæ¨¡å‹åŸºå‡†æµ‹è¯•
echo "ğŸ” è¿è¡Œæ¨¡å‹åŸºå‡†æµ‹è¯•..."
python3 improvements/model_evaluation_cli.py benchmark \
  --register-default \
  --predictor-config examples/predictors_config.json \
  --evaluate-all \
  --test-periods 20 \
  --compare \
  --report "${OUTPUT_DIR}/benchmark_report_${TIMESTAMP}.md" \
  --visualize-comparison "${OUTPUT_DIR}/model_comparison_${TIMESTAMP}.png" \
  --save-results "${OUTPUT_DIR}/benchmark_results_${TIMESTAMP}.json" \
  --output-dir ${OUTPUT_DIR}

# è·å–æœ€ä½³æ¨¡å‹
BEST_MODEL=$(python3 -c "
import json
with open('${OUTPUT_DIR}/benchmark_results_${TIMESTAMP}.json', 'r') as f:
    data = json.load(f)
if 'comparison' in data and 'overall_ranking' in data['comparison']:
    print(next(iter(data['comparison']['overall_ranking'].keys()), 'ensemble'))
else:
    print('ensemble')
")

echo "ğŸ† æœ€ä½³æ¨¡å‹: ${BEST_MODEL}"

# ä½¿ç”¨æœ€ä½³æ¨¡å‹ç”Ÿæˆé¢„æµ‹
echo "ğŸ¯ ä½¿ç”¨æœ€ä½³æ¨¡å‹ç”Ÿæˆé¢„æµ‹..."
python3 dlt_main.py predict -m ${BEST_MODEL} -c 5 --save "${OUTPUT_DIR}/predictions_best_${TIMESTAMP}.json"

# ç”Ÿæˆå¤å¼æŠ•æ³¨
echo "ğŸ² ç”Ÿæˆå¤å¼æŠ•æ³¨..."
python3 dlt_main.py predict -m compound --front-count 8 --back-count 4 --save "${OUTPUT_DIR}/predictions_compound_${TIMESTAMP}.json"

# ç”Ÿæˆ9ç§æ•°å­¦æ¨¡å‹é¢„æµ‹
echo "ğŸ§® ç”Ÿæˆ9ç§æ•°å­¦æ¨¡å‹é¢„æµ‹..."
python3 dlt_main.py predict -m nine_models -c 5 --save "${OUTPUT_DIR}/predictions_nine_models_${TIMESTAMP}.json"

echo "âœ… æ‰¹é‡é¢„æµ‹æµç¨‹å®Œæˆ"
echo "ğŸ“ ç»“æœä¿å­˜åœ¨: ${OUTPUT_DIR}"