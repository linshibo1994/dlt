#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ·±åº¦å­¦ä¹ å‘½ä»¤é›†
æä¾›è®­ç»ƒã€é¢„æµ‹ã€é›†æˆå’Œå…ƒå­¦ä¹ å‘½ä»¤
"""

import os
import sys
import argparse
import json
from typing import List, Dict, Tuple, Any, Optional, Union

from core_modules import logger_manager, data_manager, task_manager, with_progress


class CommandDefinition:
    """æ·±åº¦å­¦ä¹ å‘½ä»¤é›†"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ·±åº¦å­¦ä¹ å‘½ä»¤é›†"""
        self.commands = {
            'train': self.train_command,
            'predict': self.predict_command,
            'ensemble': self.ensemble_command,
            'metalearning': self.metalearning_command,
            'optimize': self.optimize_command,
            'info': self.info_command
        }
        
        logger_manager.info("æ·±åº¦å­¦ä¹ å‘½ä»¤é›†åˆå§‹åŒ–å®Œæˆ")
    
    def get_command_parser(self) -> argparse.ArgumentParser:
        """
        è·å–å‘½ä»¤è§£æå™¨
        
        Returns:
            å‘½ä»¤è§£æå™¨
        """
        parser = argparse.ArgumentParser(description='å¤§ä¹é€æ·±åº¦å­¦ä¹ é¢„æµ‹ç³»ç»Ÿ')
        subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
        
        # è®­ç»ƒå‘½ä»¤
        train_parser = subparsers.add_parser('train', help='è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹')
        train_parser.add_argument('-m', '--model', choices=['transformer', 'gan', 'all'], 
                                default='all', help='è¦è®­ç»ƒçš„æ¨¡å‹ç±»å‹')
        train_parser.add_argument('-p', '--periods', type=int, default=1000, 
                                help='ç”¨äºè®­ç»ƒçš„å†å²æœŸæ•°')
        train_parser.add_argument('-e', '--epochs', type=int, default=100, 
                                help='è®­ç»ƒè½®æ•°')
        train_parser.add_argument('-b', '--batch-size', type=int, default=32, 
                                help='æ‰¹å¤„ç†å¤§å°')
        train_parser.add_argument('--gpu', action='store_true', 
                                help='æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ')
        train_parser.add_argument('--save-model', action='store_true', 
                                help='æ˜¯å¦ä¿å­˜æ¨¡å‹')
        
        # é¢„æµ‹å‘½ä»¤
        predict_parser = subparsers.add_parser('predict', help='ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œé¢„æµ‹')
        predict_parser.add_argument('-m', '--model', choices=['transformer', 'gan', 'ensemble'], 
                                  default='ensemble', help='è¦ä½¿ç”¨çš„æ¨¡å‹ç±»å‹')
        predict_parser.add_argument('-c', '--count', type=int, default=5, 
                                  help='ç”Ÿæˆçš„é¢„æµ‹ç»“æœæ•°é‡')
        predict_parser.add_argument('--compound', action='store_true', 
                                  help='æ˜¯å¦ç”Ÿæˆå¤å¼æŠ•æ³¨')
        predict_parser.add_argument('--front-count', type=int, default=7, 
                                  help='å‰åŒºå·ç æ•°é‡ï¼ˆå¤å¼æŠ•æ³¨ï¼‰')
        predict_parser.add_argument('--back-count', type=int, default=3, 
                                  help='ååŒºå·ç æ•°é‡ï¼ˆå¤å¼æŠ•æ³¨ï¼‰')
        predict_parser.add_argument('--confidence', action='store_true', 
                                  help='æ˜¯å¦æ˜¾ç¤ºç½®ä¿¡åº¦')
        predict_parser.add_argument('--report', action='store_true', 
                                  help='æ˜¯å¦ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š')
        
        # é›†æˆå‘½ä»¤
        ensemble_parser = subparsers.add_parser('ensemble', help='ç®¡ç†æ¨¡å‹é›†æˆ')
        ensemble_parser.add_argument('action', choices=['list', 'add', 'remove', 'update', 'weights'], 
                                   help='é›†æˆæ“ä½œ')
        ensemble_parser.add_argument('-m', '--model', type=str, 
                                   help='æ¨¡å‹åç§°ï¼ˆç”¨äºadd/remove/updateæ“ä½œï¼‰')
        ensemble_parser.add_argument('-w', '--weight', type=float, 
                                   help='æ¨¡å‹æƒé‡ï¼ˆç”¨äºadd/updateæ“ä½œï¼‰')
        ensemble_parser.add_argument('--method', choices=['weighted', 'stacking'], 
                                   default='weighted', help='é›†æˆæ–¹æ³•')
        
        # å…ƒå­¦ä¹ å‘½ä»¤
        meta_parser = subparsers.add_parser('metalearning', help='ç®¡ç†å…ƒå­¦ä¹ ç³»ç»Ÿ')
        meta_parser.add_argument('action', choices=['status', 'enable', 'disable', 'retrain'], 
                               help='å…ƒå­¦ä¹ æ“ä½œ')
        meta_parser.add_argument('--auto-weight', action='store_true', 
                               help='æ˜¯å¦å¯ç”¨è‡ªåŠ¨æƒé‡è°ƒæ•´')
        meta_parser.add_argument('--auto-retrain', action='store_true', 
                               help='æ˜¯å¦å¯ç”¨è‡ªåŠ¨é‡è®­ç»ƒ')
        meta_parser.add_argument('--threshold', type=float, default=0.05, 
                               help='æ€§èƒ½é€€åŒ–é˜ˆå€¼ï¼ˆç”¨äºè‡ªåŠ¨é‡è®­ç»ƒï¼‰')
        
        # ä¼˜åŒ–å‘½ä»¤
        optimize_parser = subparsers.add_parser('optimize', help='ä¼˜åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹')
        optimize_parser.add_argument('action', choices=['quantize', 'cache', 'monitor'], 
                                   help='ä¼˜åŒ–æ“ä½œ')
        optimize_parser.add_argument('-m', '--model', choices=['transformer', 'gan', 'all'], 
                                   default='all', help='è¦ä¼˜åŒ–çš„æ¨¡å‹ç±»å‹')
        optimize_parser.add_argument('--type', choices=['float16', 'int8', 'dynamic'], 
                                   default='float16', help='é‡åŒ–ç±»å‹')
        optimize_parser.add_argument('--clear-cache', action='store_true', 
                                   help='æ˜¯å¦æ¸…é™¤ç¼“å­˜')
        optimize_parser.add_argument('--report', action='store_true', 
                                   help='æ˜¯å¦ç”Ÿæˆèµ„æºä½¿ç”¨æŠ¥å‘Š')
        
        # ä¿¡æ¯å‘½ä»¤
        info_parser = subparsers.add_parser('info', help='æ˜¾ç¤ºæ·±åº¦å­¦ä¹ ç³»ç»Ÿä¿¡æ¯')
        info_parser.add_argument('--gpu', action='store_true', 
                               help='æ˜¾ç¤ºGPUä¿¡æ¯')
        info_parser.add_argument('--models', action='store_true', 
                               help='æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯')
        info_parser.add_argument('--performance', action='store_true', 
                               help='æ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯')
        info_parser.add_argument('--all', action='store_true', 
                               help='æ˜¾ç¤ºæ‰€æœ‰ä¿¡æ¯')
        
        return parser 
   
    def execute_command(self, args: argparse.Namespace) -> int:
        """
        æ‰§è¡Œå‘½ä»¤
        
        Args:
            args: å‘½ä»¤å‚æ•°
            
        Returns:
            å‘½ä»¤æ‰§è¡Œç»“æœä»£ç 
        """
        command = args.command
        
        if command in self.commands:
            try:
                return self.commands[command](args)
            except Exception as e:
                logger_manager.error(f"æ‰§è¡Œå‘½ä»¤ {command} å¤±è´¥: {e}")
                return 1
        else:
            logger_manager.error(f"æœªçŸ¥å‘½ä»¤: {command}")
            return 1
    
    def train_command(self, args: argparse.Namespace) -> int:
        """
        è®­ç»ƒå‘½ä»¤
        
        Args:
            args: å‘½ä»¤å‚æ•°
            
        Returns:
            å‘½ä»¤æ‰§è¡Œç»“æœä»£ç 
        """
        logger_manager.info(f"æ‰§è¡Œè®­ç»ƒå‘½ä»¤: æ¨¡å‹={args.model}, æœŸæ•°={args.periods}, è½®æ•°={args.epochs}")
        
        # å¯¼å…¥æ¨¡å‹æ¨¡å—
        try:
            from .transformer_model import TransformerModel
            from .gan_model import GANModel
        except ImportError as e:
            logger_manager.error(f"å¯¼å…¥æ¨¡å‹æ¨¡å—å¤±è´¥: {e}")
            return 1
        
        # è·å–æ•°æ®
        df = data_manager.get_data(periods=args.periods)
        
        if df is None or len(df) == 0:
            logger_manager.error("è·å–è®­ç»ƒæ•°æ®å¤±è´¥")
            return 1
        
        # è®­ç»ƒæ¨¡å‹
        if args.model in ['transformer', 'all']:
            try:
                # åˆ›å»ºTransformeræ¨¡å‹
                transformer = TransformerModel()
                
                # è®­ç»ƒæ¨¡å‹
                transformer.train(df, epochs=args.epochs, batch_size=args.batch_size, 
                                use_gpu=args.gpu)
                
                # ä¿å­˜æ¨¡å‹
                if args.save_model:
                    transformer.save_model()
                
                logger_manager.info("Transformeræ¨¡å‹è®­ç»ƒå®Œæˆ")
            except Exception as e:
                logger_manager.error(f"è®­ç»ƒTransformeræ¨¡å‹å¤±è´¥: {e}")
                return 1
        
        if args.model in ['gan', 'all']:
            try:
                # åˆ›å»ºGANæ¨¡å‹
                gan = GANModel()
                
                # è®­ç»ƒæ¨¡å‹
                gan.train(df, epochs=args.epochs, batch_size=args.batch_size, 
                        use_gpu=args.gpu)
                
                # ä¿å­˜æ¨¡å‹
                if args.save_model:
                    gan.save_model()
                
                logger_manager.info("GANæ¨¡å‹è®­ç»ƒå®Œæˆ")
            except Exception as e:
                logger_manager.error(f"è®­ç»ƒGANæ¨¡å‹å¤±è´¥: {e}")
                return 1
        
        logger_manager.info("è®­ç»ƒå‘½ä»¤æ‰§è¡Œå®Œæˆ")
        return 0

    def predict_command(self, args: argparse.Namespace) -> int:
        """
        é¢„æµ‹å‘½ä»¤
        
        Args:
            args: å‘½ä»¤å‚æ•°
            
        Returns:
            å‘½ä»¤æ‰§è¡Œç»“æœä»£ç 
        """
        logger_manager.info(f"æ‰§è¡Œé¢„æµ‹å‘½ä»¤: æ¨¡å‹={args.model}, æ•°é‡={args.count}")
        
        # å¯¼å…¥æ¨¡å‹æ¨¡å—
        try:
            from .transformer_model import TransformerModel
            from .gan_model import GANModel
            from .ensemble_manager import EnsembleManager
        except ImportError as e:
            logger_manager.error(f"å¯¼å…¥æ¨¡å‹æ¨¡å—å¤±è´¥: {e}")
            return 1
        
        # è·å–æœ€æ–°æ•°æ®
        df = data_manager.get_data(periods=20)
        
        if df is None or len(df) == 0:
            logger_manager.error("è·å–é¢„æµ‹æ•°æ®å¤±è´¥")
            return 1
        
        # æ ¹æ®æ¨¡å‹ç±»å‹è¿›è¡Œé¢„æµ‹
        predictions = []
        confidences = []
        
        if args.model == 'transformer':
            try:
                # åˆ›å»ºTransformeræ¨¡å‹
                transformer = TransformerModel()
                
                # åŠ è½½æ¨¡å‹
                transformer.load_model()
                
                # é¢„æµ‹
                if args.compound:
                    pred, conf = transformer.predict_compound(
                        df, count=args.count, 
                        front_count=args.front_count, 
                        back_count=args.back_count
                    )
                else:
                    pred, conf = transformer.predict(df, count=args.count)
                
                predictions = pred
                confidences = conf
                
                logger_manager.info("Transformeræ¨¡å‹é¢„æµ‹å®Œæˆ")
            except Exception as e:
                logger_manager.error(f"Transformeræ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
                return 1
        
        elif args.model == 'gan':
            try:
                # åˆ›å»ºGANæ¨¡å‹
                gan = GANModel()
                
                # åŠ è½½æ¨¡å‹
                gan.load_model()
                
                # é¢„æµ‹
                if args.compound:
                    pred, conf = gan.predict_compound(
                        df, count=args.count, 
                        front_count=args.front_count, 
                        back_count=args.back_count
                    )
                else:
                    pred, conf = gan.predict(df, count=args.count)
                
                predictions = pred
                confidences = conf
                
                logger_manager.info("GANæ¨¡å‹é¢„æµ‹å®Œæˆ")
            except Exception as e:
                logger_manager.error(f"GANæ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
                return 1
        
        elif args.model == 'ensemble':
            try:
                # åˆ›å»ºé›†æˆç®¡ç†å™¨
                ensemble = EnsembleManager()
                
                # åŠ è½½æ¨¡å‹
                ensemble.load_models()
                
                # é¢„æµ‹
                if args.compound:
                    pred, conf = ensemble.predict_compound(
                        df, count=args.count, 
                        front_count=args.front_count, 
                        back_count=args.back_count
                    )
                else:
                    pred, conf = ensemble.predict(df, count=args.count)
                
                predictions = pred
                confidences = conf
                
                logger_manager.info("é›†æˆæ¨¡å‹é¢„æµ‹å®Œæˆ")
            except Exception as e:
                logger_manager.error(f"é›†æˆæ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
                return 1
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        print("\nğŸ¯ å¤§ä¹é€æ·±åº¦å­¦ä¹ é¢„æµ‹ç»“æœ")
        print("=" * 50)
        
        for i, (pred, conf) in enumerate(zip(predictions, confidences)):
            front_balls = pred[0]
            back_balls = pred[1]
            
            front_str = " ".join([f"{ball:02d}" for ball in front_balls])
            back_str = " ".join([f"{ball:02d}" for ball in back_balls])
            
            if args.confidence:
                print(f"é¢„æµ‹ {i+1}: å‰åŒº [{front_str}] ååŒº [{back_str}] ç½®ä¿¡åº¦: {conf:.4f}")
            else:
                print(f"é¢„æµ‹ {i+1}: å‰åŒº [{front_str}] ååŒº [{back_str}]")
        
        print("=" * 50)
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        if args.report:
            try:
                report_path = self._generate_prediction_report(
                    args.model, predictions, confidences, args.compound)
                print(f"\nğŸ“Š è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
            except Exception as e:
                logger_manager.error(f"ç”Ÿæˆé¢„æµ‹æŠ¥å‘Šå¤±è´¥: {e}")
        
        logger_manager.info("é¢„æµ‹å‘½ä»¤æ‰§è¡Œå®Œæˆ")
        return 0
    
    def _generate_prediction_report(self, model_type: str, predictions: List, 
                                  confidences: List, is_compound: bool) -> str:
        """
        ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š
        
        Args:
            model_type: æ¨¡å‹ç±»å‹
            predictions: é¢„æµ‹ç»“æœ
            confidences: ç½®ä¿¡åº¦
            is_compound: æ˜¯å¦ä¸ºå¤å¼æŠ•æ³¨
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        import time
        from pathlib import Path
        
        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        report_dir = Path("output/reports")
        report_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        report_file = report_dir / f"prediction_report_{model_type}_{timestamp}.json"
        
        # å‡†å¤‡æŠ¥å‘Šæ•°æ®
        report_data = {
            "model_type": model_type,
            "timestamp": timestamp,
            "is_compound": is_compound,
            "predictions": [],
            "statistics": {
                "avg_confidence": sum(confidences) / len(confidences) if confidences else 0,
                "max_confidence": max(confidences) if confidences else 0,
                "min_confidence": min(confidences) if confidences else 0
            }
        }
        
        # æ·»åŠ é¢„æµ‹ç»“æœ
        for i, (pred, conf) in enumerate(zip(predictions, confidences)):
            front_balls = pred[0]
            back_balls = pred[1]
            
            report_data["predictions"].append({
                "id": i + 1,
                "front_balls": front_balls,
                "back_balls": back_balls,
                "confidence": conf,
                "front_sum": sum(front_balls),
                "back_sum": sum(back_balls),
                "front_odd_count": sum(1 for x in front_balls if x % 2 == 1),
                "front_even_count": sum(1 for x in front_balls if x % 2 == 0),
                "front_big_count": sum(1 for x in front_balls if x > 17),
                "front_small_count": sum(1 for x in front_balls if x <= 17)
            })
        
        # ä¿å­˜æŠ¥å‘Š
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        return str(report_file)

    def ensemble_command(self, args: argparse.Namespace) -> int:
        """
        é›†æˆå‘½ä»¤
        
        Args:
            args: å‘½ä»¤å‚æ•°
            
        Returns:
            å‘½ä»¤æ‰§è¡Œç»“æœä»£ç 
        """
        logger_manager.info(f"æ‰§è¡Œé›†æˆå‘½ä»¤: æ“ä½œ={args.action}")
        
        # å¯¼å…¥é›†æˆç®¡ç†å™¨
        try:
            from .ensemble_manager import EnsembleManager
        except ImportError as e:
            logger_manager.error(f"å¯¼å…¥é›†æˆç®¡ç†å™¨å¤±è´¥: {e}")
            return 1
        
        # åˆ›å»ºé›†æˆç®¡ç†å™¨
        ensemble = EnsembleManager()
        
        # æ‰§è¡Œæ“ä½œ
        if args.action == 'list':
            # åˆ—å‡ºæ¨¡å‹
            models = ensemble.list_models()
            
            print("\nğŸ“‹ é›†æˆæ¨¡å‹åˆ—è¡¨")
            print("=" * 50)
            
            if not models:
                print("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            else:
                for i, (model_name, weight) in enumerate(models.items()):
                    print(f"{i+1}. {model_name}: æƒé‡ = {weight:.4f}")
            
            print("=" * 50)
            print(f"é›†æˆæ–¹æ³•: {ensemble.get_ensemble_method()}")
        
        elif args.action == 'add':
            # æ·»åŠ æ¨¡å‹
            if not args.model:
                logger_manager.error("æ·»åŠ æ¨¡å‹éœ€è¦æŒ‡å®šæ¨¡å‹åç§°")
                return 1
            
            weight = args.weight if args.weight is not None else 1.0
            success = ensemble.add_model(args.model, weight)
            
            if success:
                print(f"âœ… æˆåŠŸæ·»åŠ æ¨¡å‹ '{args.model}' åˆ°é›†æˆï¼Œæƒé‡ = {weight:.4f}")
            else:
                print(f"âŒ æ·»åŠ æ¨¡å‹ '{args.model}' å¤±è´¥")
                return 1
        
        elif args.action == 'remove':
            # ç§»é™¤æ¨¡å‹
            if not args.model:
                logger_manager.error("ç§»é™¤æ¨¡å‹éœ€è¦æŒ‡å®šæ¨¡å‹åç§°")
                return 1
            
            success = ensemble.remove_model(args.model)
            
            if success:
                print(f"âœ… æˆåŠŸä»é›†æˆä¸­ç§»é™¤æ¨¡å‹ '{args.model}'")
            else:
                print(f"âŒ ç§»é™¤æ¨¡å‹ '{args.model}' å¤±è´¥")
                return 1
        
        elif args.action == 'update':
            # æ›´æ–°æ¨¡å‹æƒé‡
            if not args.model or args.weight is None:
                logger_manager.error("æ›´æ–°æ¨¡å‹æƒé‡éœ€è¦æŒ‡å®šæ¨¡å‹åç§°å’Œæƒé‡")
                return 1
            
            success = ensemble.update_model_weight(args.model, args.weight)
            
            if success:
                print(f"âœ… æˆåŠŸæ›´æ–°æ¨¡å‹ '{args.model}' çš„æƒé‡ä¸º {args.weight:.4f}")
            else:
                print(f"âŒ æ›´æ–°æ¨¡å‹ '{args.model}' æƒé‡å¤±è´¥")
                return 1
        
        elif args.action == 'weights':
            # æ˜¾ç¤ºæƒé‡
            weights = ensemble.get_model_weights()
            
            print("\nâš–ï¸ æ¨¡å‹æƒé‡")
            print("=" * 50)
            
            if not weights:
                print("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹æƒé‡")
            else:
                for model_name, weight in weights.items():
                    print(f"{model_name}: {weight:.4f}")
            
            print("=" * 50)
        
        # è®¾ç½®é›†æˆæ–¹æ³•
        if args.method:
            ensemble.set_ensemble_method(args.method)
            print(f"âœ… é›†æˆæ–¹æ³•å·²è®¾ç½®ä¸º '{args.method}'")
        
        # ä¿å­˜é…ç½®
        ensemble.save_config()
        
        logger_manager.info("é›†æˆå‘½ä»¤æ‰§è¡Œå®Œæˆ")
        return 0
    
    def metalearning_command(self, args: argparse.Namespace) -> int:
        """
        å…ƒå­¦ä¹ å‘½ä»¤
        
        Args:
            args: å‘½ä»¤å‚æ•°
            
        Returns:
            å‘½ä»¤æ‰§è¡Œç»“æœä»£ç 
        """
        logger_manager.info(f"æ‰§è¡Œå…ƒå­¦ä¹ å‘½ä»¤: æ“ä½œ={args.action}")
        
        # å¯¼å…¥å…ƒå­¦ä¹ ç®¡ç†å™¨
        try:
            from .metalearning_manager import MetaLearningManager
        except ImportError as e:
            logger_manager.error(f"å¯¼å…¥å…ƒå­¦ä¹ ç®¡ç†å™¨å¤±è´¥: {e}")
            return 1
        
        # åˆ›å»ºå…ƒå­¦ä¹ ç®¡ç†å™¨
        meta = MetaLearningManager()
        
        # æ‰§è¡Œæ“ä½œ
        if args.action == 'status':
            # æ˜¾ç¤ºçŠ¶æ€
            status = meta.get_status()
            
            print("\nğŸ§  å…ƒå­¦ä¹ ç³»ç»ŸçŠ¶æ€")
            print("=" * 50)
            print(f"è‡ªåŠ¨æƒé‡è°ƒæ•´: {'å¯ç”¨' if status.get('auto_weight', False) else 'ç¦ç”¨'}")
            print(f"è‡ªåŠ¨é‡è®­ç»ƒ: {'å¯ç”¨' if status.get('auto_retrain', False) else 'ç¦ç”¨'}")
            print(f"æ€§èƒ½é€€åŒ–é˜ˆå€¼: {status.get('threshold', 0.05):.4f}")
            print(f"ä¸Šæ¬¡æƒé‡è°ƒæ•´: {status.get('last_weight_update', 'ä»æœª')}")
            print(f"ä¸Šæ¬¡é‡è®­ç»ƒ: {status.get('last_retrain', 'ä»æœª')}")
            print("=" * 50)
            
            # æ˜¾ç¤ºæ€§èƒ½è·Ÿè¸ª
            performance = meta.get_performance_tracking()
            
            if performance:
                print("\nğŸ“ˆ æ€§èƒ½è·Ÿè¸ª")
                print("=" * 50)
                
                for model_name, metrics in performance.items():
                    print(f"æ¨¡å‹: {model_name}")
                    print(f"  å‡†ç¡®ç‡: {metrics.get('accuracy', 0):.4f}")
                    print(f"  ä¸€è‡´æ€§: {metrics.get('consistency', 0):.4f}")
                    print(f"  é€‚åº”æ€§: {metrics.get('adaptability', 0):.4f}")
                    print(f"  è¶‹åŠ¿: {metrics.get('trend', 'ç¨³å®š')}")
                    print()
                
                print("=" * 50)
        
        elif args.action == 'enable':
            # å¯ç”¨åŠŸèƒ½
            if args.auto_weight:
                meta.enable_auto_weight_adjustment(True)
                print("âœ… è‡ªåŠ¨æƒé‡è°ƒæ•´å·²å¯ç”¨")
            
            if args.auto_retrain:
                meta.enable_auto_retraining(True)
                print("âœ… è‡ªåŠ¨é‡è®­ç»ƒå·²å¯ç”¨")
            
            if args.threshold is not None:
                meta.set_performance_threshold(args.threshold)
                print(f"âœ… æ€§èƒ½é€€åŒ–é˜ˆå€¼å·²è®¾ç½®ä¸º {args.threshold:.4f}")
        
        elif args.action == 'disable':
            # ç¦ç”¨åŠŸèƒ½
            if args.auto_weight:
                meta.enable_auto_weight_adjustment(False)
                print("âœ… è‡ªåŠ¨æƒé‡è°ƒæ•´å·²ç¦ç”¨")
            
            if args.auto_retrain:
                meta.enable_auto_retraining(False)
                print("âœ… è‡ªåŠ¨é‡è®­ç»ƒå·²ç¦ç”¨")
        
        elif args.action == 'retrain':
            # è§¦å‘é‡è®­ç»ƒ
            print("ğŸ”„ è§¦å‘æ¨¡å‹é‡è®­ç»ƒ...")
            success = meta.trigger_retraining()
            
            if success:
                print("âœ… æ¨¡å‹é‡è®­ç»ƒå®Œæˆ")
            else:
                print("âŒ æ¨¡å‹é‡è®­ç»ƒå¤±è´¥")
                return 1
        
        # ä¿å­˜é…ç½®
        meta.save_config()
        
        logger_manager.info("å…ƒå­¦ä¹ å‘½ä»¤æ‰§è¡Œå®Œæˆ")
        return 0    

    def optimize_command(self, args: argparse.Namespace) -> int:
        """
        ä¼˜åŒ–å‘½ä»¤
        
        Args:
            args: å‘½ä»¤å‚æ•°
            
        Returns:
            å‘½ä»¤æ‰§è¡Œç»“æœä»£ç 
        """
        logger_manager.info(f"æ‰§è¡Œä¼˜åŒ–å‘½ä»¤: æ“ä½œ={args.action}, æ¨¡å‹={args.model}")
        
        # å¯¼å…¥æ¨¡å‹ä¼˜åŒ–å™¨
        try:
            from .model_optimizer import ModelOptimizer
            from .transformer_model import TransformerModel
            from .gan_model import GANModel
        except ImportError as e:
            logger_manager.error(f"å¯¼å…¥æ¨¡å‹ä¼˜åŒ–å™¨å¤±è´¥: {e}")
            return 1
        
        # åˆ›å»ºæ¨¡å‹ä¼˜åŒ–å™¨
        optimizer = ModelOptimizer()
        
        # æ‰§è¡Œæ“ä½œ
        if args.action == 'quantize':
            # é‡åŒ–æ¨¡å‹
            print(f"ğŸ”„ ä½¿ç”¨ {args.type} é‡åŒ–æ¨¡å‹...")
            
            if args.model in ['transformer', 'all']:
                try:
                    # åŠ è½½Transformeræ¨¡å‹
                    transformer = TransformerModel()
                    transformer.load_model()
                    
                    # é‡åŒ–æ¨¡å‹
                    quantized_model = optimizer.quantize_model(
                        transformer.model, 'tensorflow', args.type)
                    
                    # æ›´æ–°æ¨¡å‹
                    transformer.model = quantized_model
                    
                    # ä¿å­˜æ¨¡å‹
                    transformer.save_model(suffix='_quantized')
                    
                    print("âœ… Transformeræ¨¡å‹é‡åŒ–å®Œæˆ")
                except Exception as e:
                    logger_manager.error(f"é‡åŒ–Transformeræ¨¡å‹å¤±è´¥: {e}")
                    return 1
            
            if args.model in ['gan', 'all']:
                try:
                    # åŠ è½½GANæ¨¡å‹
                    gan = GANModel()
                    gan.load_model()
                    
                    # é‡åŒ–ç”Ÿæˆå™¨
                    quantized_generator = optimizer.quantize_model(
                        gan.generator, 'tensorflow', args.type)
                    
                    # æ›´æ–°æ¨¡å‹
                    gan.generator = quantized_generator
                    
                    # ä¿å­˜æ¨¡å‹
                    gan.save_model(suffix='_quantized')
                    
                    print("âœ… GANæ¨¡å‹é‡åŒ–å®Œæˆ")
                except Exception as e:
                    logger_manager.error(f"é‡åŒ–GANæ¨¡å‹å¤±è´¥: {e}")
                    return 1
        
        elif args.action == 'cache':
            # ç®¡ç†ç¼“å­˜
            if args.clear_cache:
                optimizer.clear_result_cache()
                print("âœ… ç»“æœç¼“å­˜å·²æ¸…é™¤")
            else:
                # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
                cache_dir = os.path.join(optimizer.cache_dir, 'result_cache')
                cache_files = [f for f in os.listdir(cache_dir) if f.endswith('.pkl')]
                
                print("\nğŸ’¾ ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
                print("=" * 50)
                print(f"ç¼“å­˜æ–‡ä»¶æ•°é‡: {len(cache_files)}")
                
                if cache_files:
                    total_size = sum(os.path.getsize(os.path.join(cache_dir, f)) for f in cache_files)
                    print(f"ç¼“å­˜æ€»å¤§å°: {total_size / (1024 * 1024):.2f} MB")
                
                print("=" * 50)
        
        elif args.action == 'monitor':
            # èµ„æºç›‘æ§
            print("ğŸ“Š å¼€å§‹èµ„æºç›‘æ§...")
            optimizer.start_resource_monitoring()
            
            # æ¨¡æ‹Ÿä¸€äº›æ“ä½œ
            for i in range(5):
                print(f"æ‰§è¡Œæ“ä½œ {i+1}/5...")
                import time
                time.sleep(1)
                usage = optimizer.record_resource_usage()
                print(f"  CPU: {usage['cpu']:.1f}%, å†…å­˜: {usage['memory']:.1f}%, ç£ç›˜: {usage['disk']:.1f}%")
            
            # è·å–èµ„æºä½¿ç”¨æƒ…å†µæ‘˜è¦
            summary = optimizer.get_resource_usage_summary()
            
            print("\nğŸ“Š èµ„æºä½¿ç”¨æƒ…å†µæ‘˜è¦")
            print("=" * 50)
            
            for resource, metrics in summary.items():
                print(f"{resource.upper()}:")
                print(f"  æœ€å°å€¼: {metrics['min']:.1f}%")
                print(f"  æœ€å¤§å€¼: {metrics['max']:.1f}%")
                print(f"  å¹³å‡å€¼: {metrics['avg']:.1f}%")
                print(f"  å½“å‰å€¼: {metrics['current']:.1f}%")
                print()
            
            print("=" * 50)
            
            # ç”ŸæˆæŠ¥å‘Š
            if args.report:
                report_path = optimizer.save_resource_usage_report()
                print(f"\nğŸ“Š èµ„æºä½¿ç”¨æƒ…å†µæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
        logger_manager.info("ä¼˜åŒ–å‘½ä»¤æ‰§è¡Œå®Œæˆ")
        return 0
    
    def info_command(self, args: argparse.Namespace) -> int:
        """
        ä¿¡æ¯å‘½ä»¤
        
        Args:
            args: å‘½ä»¤å‚æ•°
            
        Returns:
            å‘½ä»¤æ‰§è¡Œç»“æœä»£ç 
        """
        logger_manager.info("æ‰§è¡Œä¿¡æ¯å‘½ä»¤")
        
        # æ˜¾ç¤ºæ‰€æœ‰ä¿¡æ¯
        if args.all:
            args.gpu = True
            args.models = True
            args.performance = True
        
        # æ˜¾ç¤ºGPUä¿¡æ¯
        if args.gpu:
            try:
                from .gpu_accelerator import GPUAccelerator
                
                # åˆ›å»ºGPUåŠ é€Ÿå™¨
                accelerator = GPUAccelerator()
                
                print("\nğŸ–¥ï¸ GPUä¿¡æ¯")
                print("=" * 50)
                print(f"GPUå¯ç”¨æ€§: {'å¯ç”¨' if accelerator.is_gpu_available() else 'ä¸å¯ç”¨'}")
                
                # æ˜¾ç¤ºGPUè®¾å¤‡
                devices = accelerator.get_gpu_devices()
                if devices:
                    print(f"å¯ç”¨GPUè®¾å¤‡: {len(devices)}")
                    for i, device in enumerate(devices):
                        print(f"  {i+1}. {device}")
                else:
                    print("æ²¡æœ‰å¯ç”¨çš„GPUè®¾å¤‡")
                
                # æ˜¾ç¤ºGPUå†…å­˜ä¿¡æ¯
                memory_info = accelerator.get_gpu_memory_info()
                if memory_info:
                    print("\nGPUå†…å­˜ä¿¡æ¯:")
                    for device, memory in memory_info.items():
                        print(f"  {device}:")
                        for key, value in memory.items():
                            print(f"    {key}: {value:.2f} GB")
                
                print("=" * 50)
            except Exception as e:
                logger_manager.error(f"è·å–GPUä¿¡æ¯å¤±è´¥: {e}")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        if args.models:
            try:
                # è·å–æ¨¡å‹æ–‡ä»¶
                model_dir = "models"
                if os.path.exists(model_dir):
                    model_files = [f for f in os.listdir(model_dir) if f.endswith('.h5') or f.endswith('.pt')]
                    
                    print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯")
                    print("=" * 50)
                    
                    if model_files:
                        print(f"å¯ç”¨æ¨¡å‹æ–‡ä»¶: {len(model_files)}")
                        for i, model_file in enumerate(model_files):
                            file_path = os.path.join(model_dir, model_file)
                            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB
                            import time
                            file_date = os.path.getmtime(file_path)
                            file_date_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(file_date))
                            
                            print(f"  {i+1}. {model_file}")
                            print(f"     å¤§å°: {file_size:.2f} MB")
                            print(f"     ä¿®æ”¹æ—¶é—´: {file_date_str}")
                    else:
                        print("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
                    
                    print("=" * 50)
                else:
                    print("\nâš ï¸ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
            except Exception as e:
                logger_manager.error(f"è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")
        
        # æ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
        if args.performance:
            try:
                from .metalearning_manager import MetaLearningManager
                
                # åˆ›å»ºå…ƒå­¦ä¹ ç®¡ç†å™¨
                meta = MetaLearningManager()
                
                # è·å–æ€§èƒ½è·Ÿè¸ª
                performance = meta.get_performance_tracking()
                
                print("\nğŸ“ˆ æ€§èƒ½ä¿¡æ¯")
                print("=" * 50)
                
                if performance:
                    for model_name, metrics in performance.items():
                        print(f"æ¨¡å‹: {model_name}")
                        print(f"  å‡†ç¡®ç‡: {metrics.get('accuracy', 0):.4f}")
                        print(f"  ä¸€è‡´æ€§: {metrics.get('consistency', 0):.4f}")
                        print(f"  é€‚åº”æ€§: {metrics.get('adaptability', 0):.4f}")
                        print(f"  è¶‹åŠ¿: {metrics.get('trend', 'ç¨³å®š')}")
                        print()
                else:
                    print("æ²¡æœ‰å¯ç”¨çš„æ€§èƒ½è·Ÿè¸ªä¿¡æ¯")
                
                print("=" * 50)
            except Exception as e:
                logger_manager.error(f"è·å–æ€§èƒ½ä¿¡æ¯å¤±è´¥: {e}")
        
        logger_manager.info("ä¿¡æ¯å‘½ä»¤æ‰§è¡Œå®Œæˆ")
        return 0


if __name__ == "__main__":
    # æµ‹è¯•æ·±åº¦å­¦ä¹ å‘½ä»¤é›†
    print("ğŸš€ æµ‹è¯•æ·±åº¦å­¦ä¹ å‘½ä»¤é›†...")
    
    # åˆ›å»ºå‘½ä»¤é›†
    commands = DeepLearningCommands()
    
    # è·å–å‘½ä»¤è§£æå™¨
    parser = commands.get_command_parser()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args(['info', '--all'])
    
    # æ‰§è¡Œå‘½ä»¤
    result = commands.execute_command(args)
    
    print(f"å‘½ä»¤æ‰§è¡Œç»“æœ: {'æˆåŠŸ' if result == 0 else 'å¤±è´¥'}")
    
    print("æ·±åº¦å­¦ä¹ å‘½ä»¤é›†æµ‹è¯•å®Œæˆ")