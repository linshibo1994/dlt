#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®å¢å¼ºå™¨
æä¾›æ•°æ®å¢å¼ºå’ŒåˆæˆåŠŸèƒ½
"""

import os
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Any, Optional, Union
from sklearn.utils import resample
from datetime import datetime

from core_modules import logger_manager, data_manager, cache_manager, task_manager, with_progress


class DataAugmentor:
    """æ•°æ®å¢å¼ºå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®å¢å¼ºå™¨"""
        self.df = data_manager.get_data()
        
        if self.df is None:
            logger_manager.error("æ•°æ®æœªåŠ è½½")
        else:
            logger_manager.info("æ•°æ®å¢å¼ºå™¨åˆå§‹åŒ–å®Œæˆ")
    
    @with_progress(100, "æ•°æ®å¢å¼º")
    def augment_data(self, progress_bar, data: np.ndarray, factor: float = 1.5,
                   method: str = 'noise') -> np.ndarray:
        """
        æ•°æ®å¢å¼º
        
        Args:
            progress_bar: è¿›åº¦æ¡
            data: è¾“å…¥æ•°æ®
            factor: å¢å¼ºå› å­ï¼Œè¡¨ç¤ºå¢å¼ºåçš„æ•°æ®é‡æ˜¯åŸå§‹æ•°æ®é‡çš„å¤šå°‘å€
            method: å¢å¼ºæ–¹æ³•ï¼Œæ”¯æŒ'noise', 'smote', 'bootstrap'
            
        Returns:
            å¢å¼ºåçš„æ•°æ®
        """
        if data is None or len(data) == 0:
            logger_manager.warning("è¾“å…¥æ•°æ®ä¸ºç©ºï¼Œæ— æ³•å¢å¼º")
            return np.array([])
        
        if factor <= 1.0:
            logger_manager.warning(f"å¢å¼ºå› å­ {factor} å°äºç­‰äº1.0ï¼Œä¸éœ€è¦å¢å¼º")
            return data
        
        original_size = len(data)
        augmented_size = int(original_size * factor)
        augmented_data = np.copy(data)
        
        # è®¡ç®—éœ€è¦ç”Ÿæˆçš„æ–°æ ·æœ¬æ•°é‡
        new_samples_count = augmented_size - original_size
        
        # æ›´æ–°è¿›åº¦æ¡æ€»æ•°
        progress_bar.total = new_samples_count
        
        if method == 'noise':
            # æ·»åŠ éšæœºå™ªå£°
            for i in range(new_samples_count):
                # éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬
                idx = np.random.randint(0, original_size)
                sample = np.copy(data[idx])
                
                # æ·»åŠ éšæœºå™ªå£°
                noise_level = 0.05  # 5%çš„å™ªå£°
                noise = np.random.normal(0, noise_level, sample.shape)
                
                # ç¡®ä¿å·ç ç‰¹å¾ï¼ˆå‰7ä¸ªï¼‰åœ¨å¢å¼ºåä»ç„¶æœ‰æ•ˆ
                augmented_sample = sample + noise
                
                # æ·»åŠ åˆ°å¢å¼ºæ•°æ®é›†
                augmented_data = np.vstack([augmented_data, augmented_sample])
                
                # æ›´æ–°è¿›åº¦
                progress_bar.update(1)
        
        elif method == 'bootstrap':
            # ä½¿ç”¨è‡ªåŠ©æ³•ï¼ˆBootstrapï¼‰
            bootstrap_samples = resample(data, n_samples=new_samples_count, random_state=42)
            augmented_data = np.vstack([augmented_data, bootstrap_samples])
            progress_bar.update(new_samples_count)
        
        elif method == 'smote':
            try:
                # ä½¿ç”¨SMOTEï¼ˆåˆæˆå°‘æ•°ç±»è¿‡é‡‡æ ·æŠ€æœ¯ï¼‰
                from imblearn.over_sampling import SMOTE
                
                # åˆ›å»ºæ ‡ç­¾ï¼ˆè¿™é‡Œåªæ˜¯ä¸ºäº†ä½¿ç”¨SMOTEï¼Œå®é™…ä¸Šæ²¡æœ‰æ„ä¹‰ï¼‰
                y = np.zeros(len(data))
                
                # åº”ç”¨SMOTE
                smote = SMOTE(sampling_strategy='auto', random_state=42)
                X_resampled, _ = smote.fit_resample(data, y)
                
                # å¦‚æœSMOTEç”Ÿæˆçš„æ ·æœ¬æ•°é‡ä¸è¶³ï¼Œä½¿ç”¨è‡ªåŠ©æ³•è¡¥å……
                if len(X_resampled) < augmented_size:
                    bootstrap_samples = resample(X_resampled, n_samples=augmented_size-len(X_resampled), random_state=42)
                    augmented_data = np.vstack([X_resampled, bootstrap_samples])
                else:
                    augmented_data = X_resampled[:augmented_size]
                
                progress_bar.update(new_samples_count)
            except Exception as e:
                logger_manager.error(f"SMOTEå¢å¼ºå¤±è´¥: {e}ï¼Œä½¿ç”¨å™ªå£°å¢å¼ºä»£æ›¿")
                return self.augment_data(progress_bar, data, factor, 'noise')
        
        else:
            logger_manager.warning(f"æœªçŸ¥çš„å¢å¼ºæ–¹æ³•: {method}ï¼Œä½¿ç”¨å™ªå£°å¢å¼ºä»£æ›¿")
            return self.augment_data(progress_bar, data, factor, 'noise')
        
        logger_manager.info(f"æ•°æ®å¢å¼ºå®Œæˆï¼Œæ–¹æ³•: {method}ï¼ŒåŸå§‹æ•°æ®é‡: {original_size}ï¼Œå¢å¼ºåæ•°æ®é‡: {len(augmented_data)}")
        
        return augmented_data
    
    def generate_synthetic_data(self, count: int, feature_dim: int,
                              method: str = 'random') -> np.ndarray:
        """
        ç”Ÿæˆåˆæˆæ•°æ®
        
        Args:
            count: æ ·æœ¬æ•°é‡
            feature_dim: ç‰¹å¾ç»´åº¦
            method: ç”Ÿæˆæ–¹æ³•ï¼Œæ”¯æŒ'random', 'gaussian', 'uniform'
            
        Returns:
            åˆæˆæ•°æ®
        """
        if count <= 0 or feature_dim <= 0:
            logger_manager.warning(f"æ— æ•ˆçš„å‚æ•°: count={count}, feature_dim={feature_dim}")
            return np.array([])
        
        if method == 'random':
            # ç”Ÿæˆéšæœºæ•°æ®
            synthetic_data = np.random.random((count, feature_dim))
        elif method == 'gaussian':
            # ç”Ÿæˆé«˜æ–¯åˆ†å¸ƒæ•°æ®
            synthetic_data = np.random.normal(0.5, 0.15, (count, feature_dim))
            # è£å‰ªåˆ°[0, 1]èŒƒå›´
            synthetic_data = np.clip(synthetic_data, 0, 1)
        elif method == 'uniform':
            # ç”Ÿæˆå‡åŒ€åˆ†å¸ƒæ•°æ®
            synthetic_data = np.random.uniform(0, 1, (count, feature_dim))
        else:
            logger_manager.warning(f"æœªçŸ¥çš„ç”Ÿæˆæ–¹æ³•: {method}ï¼Œä½¿ç”¨éšæœºç”Ÿæˆä»£æ›¿")
            synthetic_data = np.random.random((count, feature_dim))
        
        logger_manager.info(f"åˆæˆæ•°æ®ç”Ÿæˆå®Œæˆï¼Œæ–¹æ³•: {method}ï¼Œæ•°æ®å½¢çŠ¶: {synthetic_data.shape}")
        
        return synthetic_data
    
    def balance_data(self, data: np.ndarray, labels: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        å¹³è¡¡æ•°æ®
        
        Args:
            data: è¾“å…¥æ•°æ®
            labels: æ ‡ç­¾
            
        Returns:
            å¹³è¡¡åçš„æ•°æ®å’Œæ ‡ç­¾
        """
        if data is None or len(data) == 0 or labels is None or len(labels) == 0:
            logger_manager.warning("è¾“å…¥æ•°æ®æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•å¹³è¡¡")
            return data, labels
        
        if len(data) != len(labels):
            logger_manager.warning(f"æ•°æ®å’Œæ ‡ç­¾é•¿åº¦ä¸ä¸€è‡´: {len(data)} vs {len(labels)}")
            return data, labels
        
        try:
            # ç»Ÿè®¡å„ç±»åˆ«æ ·æœ¬æ•°é‡
            unique_labels, counts = np.unique(labels, return_counts=True)
            
            if len(unique_labels) <= 1:
                logger_manager.warning("åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œæ— éœ€å¹³è¡¡")
                return data, labels
            
            # æ‰¾å‡ºæ ·æœ¬æ•°é‡æœ€å¤šçš„ç±»åˆ«
            max_count = np.max(counts)
            
            # å¹³è¡¡åçš„æ•°æ®å’Œæ ‡ç­¾
            balanced_data = []
            balanced_labels = []
            
            # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œè¿‡é‡‡æ ·
            for label in unique_labels:
                # è·å–å½“å‰ç±»åˆ«çš„æ ·æœ¬
                label_mask = labels == label
                label_data = data[label_mask]
                label_count = len(label_data)
                
                # å¦‚æœæ ·æœ¬æ•°é‡ä¸è¶³ï¼Œè¿›è¡Œè¿‡é‡‡æ ·
                if label_count < max_count:
                    # è®¡ç®—éœ€è¦ç”Ÿæˆçš„æ ·æœ¬æ•°é‡
                    n_samples = max_count - label_count
                    
                    # ä½¿ç”¨è‡ªåŠ©æ³•ç”Ÿæˆæ–°æ ·æœ¬
                    bootstrap_samples = resample(label_data, n_samples=n_samples, random_state=42)
                    
                    # åˆå¹¶åŸå§‹æ ·æœ¬å’Œæ–°æ ·æœ¬
                    balanced_class_data = np.vstack([label_data, bootstrap_samples])
                    balanced_class_labels = np.array([label] * max_count)
                else:
                    # å¦‚æœæ ·æœ¬æ•°é‡è¶³å¤Ÿï¼Œç›´æ¥ä½¿ç”¨
                    balanced_class_data = label_data
                    balanced_class_labels = np.array([label] * label_count)
                
                # æ·»åŠ åˆ°å¹³è¡¡åçš„æ•°æ®å’Œæ ‡ç­¾
                balanced_data.append(balanced_class_data)
                balanced_labels.append(balanced_class_labels)
            
            # åˆå¹¶æ‰€æœ‰ç±»åˆ«çš„æ•°æ®å’Œæ ‡ç­¾
            balanced_data = np.vstack(balanced_data)
            balanced_labels = np.concatenate(balanced_labels)
            
            logger_manager.info(f"æ•°æ®å¹³è¡¡å®Œæˆï¼ŒåŸå§‹æ•°æ®é‡: {len(data)}ï¼Œå¹³è¡¡åæ•°æ®é‡: {len(balanced_data)}")
            
            return balanced_data, balanced_labels
        except Exception as e:
            logger_manager.error(f"æ•°æ®å¹³è¡¡å¤±è´¥: {e}")
            return data, labels
    
    def mix_data(self, data1: np.ndarray, data2: np.ndarray, ratio: float = 0.5) -> np.ndarray:
        """
        æ··åˆæ•°æ®
        
        Args:
            data1: ç¬¬ä¸€ç»„æ•°æ®
            data2: ç¬¬äºŒç»„æ•°æ®
            ratio: æ··åˆæ¯”ä¾‹ï¼Œè¡¨ç¤ºdata1çš„æ¯”ä¾‹
            
        Returns:
            æ··åˆåçš„æ•°æ®
        """
        if data1 is None or len(data1) == 0:
            logger_manager.warning("ç¬¬ä¸€ç»„æ•°æ®ä¸ºç©ºï¼Œè¿”å›ç¬¬äºŒç»„æ•°æ®")
            return data2
        
        if data2 is None or len(data2) == 0:
            logger_manager.warning("ç¬¬äºŒç»„æ•°æ®ä¸ºç©ºï¼Œè¿”å›ç¬¬ä¸€ç»„æ•°æ®")
            return data1
        
        if data1.shape[1] != data2.shape[1]:
            logger_manager.warning(f"ä¸¤ç»„æ•°æ®ç»´åº¦ä¸ä¸€è‡´: {data1.shape[1]} vs {data2.shape[1]}")
            return data1
        
        # è®¡ç®—æ··åˆåçš„æ•°æ®é‡
        mixed_size = len(data1) + len(data2)
        
        # è®¡ç®—å„ç»„æ•°æ®çš„æ ·æœ¬æ•°é‡
        data1_count = int(mixed_size * ratio)
        data2_count = mixed_size - data1_count
        
        # å¦‚æœæŸç»„æ•°æ®æ ·æœ¬ä¸è¶³ï¼Œä½¿ç”¨é‡é‡‡æ ·
        if data1_count > len(data1):
            data1_extra = resample(data1, n_samples=data1_count-len(data1), random_state=42)
            data1_samples = np.vstack([data1, data1_extra])
        else:
            # éšæœºé€‰æ‹©æ ·æœ¬
            indices = np.random.choice(len(data1), data1_count, replace=False)
            data1_samples = data1[indices]
        
        if data2_count > len(data2):
            data2_extra = resample(data2, n_samples=data2_count-len(data2), random_state=42)
            data2_samples = np.vstack([data2, data2_extra])
        else:
            # éšæœºé€‰æ‹©æ ·æœ¬
            indices = np.random.choice(len(data2), data2_count, replace=False)
            data2_samples = data2[indices]
        
        # åˆå¹¶ä¸¤ç»„æ•°æ®
        mixed_data = np.vstack([data1_samples, data2_samples])
        
        # éšæœºæ‰“ä¹±
        np.random.shuffle(mixed_data)
        
        logger_manager.info(f"æ•°æ®æ··åˆå®Œæˆï¼Œæ··åˆæ¯”ä¾‹: {ratio}ï¼Œæ··åˆåæ•°æ®é‡: {len(mixed_data)}")
        
        return mixed_data


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®å¢å¼ºå™¨
    print("ğŸ“Š æµ‹è¯•æ•°æ®å¢å¼ºå™¨...")
    
    # åˆ›å»ºæ•°æ®å¢å¼ºå™¨
    augmentor = DataAugmentor()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = np.random.random((100, 10))
    
    # æµ‹è¯•æ•°æ®å¢å¼º
    augmented_data = augmentor.augment_data(test_data, factor=1.5)
    print(f"å¢å¼ºåæ•°æ®å½¢çŠ¶: {augmented_data.shape}")
    
    # æµ‹è¯•åˆæˆæ•°æ®ç”Ÿæˆ
    synthetic_data = augmentor.generate_synthetic_data(50, 10)
    print(f"åˆæˆæ•°æ®å½¢çŠ¶: {synthetic_data.shape}")
    
    # æµ‹è¯•æ•°æ®å¹³è¡¡
    labels = np.random.randint(0, 3, 100)
    balanced_data, balanced_labels = augmentor.balance_data(test_data, labels)
    print(f"å¹³è¡¡åæ•°æ®å½¢çŠ¶: {balanced_data.shape}")
    
    # æµ‹è¯•æ•°æ®æ··åˆ
    mixed_data = augmentor.mix_data(test_data, synthetic_data, ratio=0.7)
    print(f"æ··åˆåæ•°æ®å½¢çŠ¶: {mixed_data.shape}")
    
    print("æ•°æ®å¢å¼ºå™¨æµ‹è¯•å®Œæˆ")