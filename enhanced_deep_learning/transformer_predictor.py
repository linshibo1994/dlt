#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Transformeré¢„æµ‹å™¨
åŸºäºTransformeræ¶æ„çš„æ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹
"""

import os
import numpy as np
import tensorflow as tf
from typing import List, Tuple, Dict, Any
from tensorflow.keras import layers, Model, optimizers
from datetime import datetime

from .base import BaseDeepPredictor
from .config import DEFAULT_TRANSFORMER_CONFIG
from .exceptions import ModelInitializationError, handle_model_error
from core_modules import logger_manager


class TransformerPredictor(BaseDeepPredictor):
    """åŸºäºTransformerçš„å½©ç¥¨é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–Transformeré¢„æµ‹å™¨
        
        Args:
            config: é…ç½®å‚æ•°å­—å…¸
        """
        # åˆå¹¶é»˜è®¤é…ç½®å’Œç”¨æˆ·é…ç½®
        merged_config = DEFAULT_TRANSFORMER_CONFIG.copy()
        if config:
            merged_config.update(config)
        
        super().__init__(name="Transformer", config=merged_config)
        
        # ä»é…ç½®ä¸­æå–å‚æ•°
        self.d_model = self.config.get('d_model', 128)
        self.num_heads = self.config.get('num_heads', 8)
        self.num_layers = self.config.get('num_layers', 4)
        self.dff = self.config.get('dff', 512)
        self.dropout_rate = self.config.get('dropout_rate', 0.1)
        
        logger_manager.info(f"åˆå§‹åŒ–Transformeré¢„æµ‹å™¨: d_model={self.d_model}, heads={self.num_heads}, layers={self.num_layers}")
    
    def _build_model(self):
        """æ„å»ºTransformeræ¨¡å‹"""
        try:
            # è¾“å…¥å±‚
            inputs = layers.Input(shape=(self.sequence_length, self.feature_dim))
            
            # ä½ç½®ç¼–ç 
            positions = tf.range(start=0, limit=self.sequence_length, delta=1)
            positions = layers.Embedding(self.sequence_length, self.d_model)(positions)
            
            # è¾“å…¥åµŒå…¥
            x = layers.Dense(self.d_model)(inputs)
            x = x + positions
            
            # Transformerå±‚
            for i in range(self.num_layers):
                # å¤šå¤´æ³¨æ„åŠ›
                attention_output = layers.MultiHeadAttention(
                    num_heads=self.num_heads, 
                    key_dim=self.d_model // self.num_heads
                )(x, x)
                x = layers.Add()([x, attention_output])
                x = layers.LayerNormalization(epsilon=1e-6)(x)
                
                # å‰é¦ˆç½‘ç»œ
                ffn_output = self._point_wise_feed_forward_network(x)
                x = layers.Add()([x, ffn_output])
                x = layers.LayerNormalization(epsilon=1e-6)(x)
            
            # å…¨å±€å¹³å‡æ± åŒ–
            x = layers.GlobalAveragePooling1D()(x)
            
            # å…¨è¿æ¥å±‚
            x = layers.Dense(64, activation='relu')(x)
            x = layers.Dropout(self.dropout_rate)(x)
            
            # è¾“å‡ºå±‚ - ä½¿ç”¨å•ä¸€è¾“å‡ºï¼Œå‰5ä¸ªå€¼ä¸ºå‰åŒºï¼Œå2ä¸ªå€¼ä¸ºååŒº
            outputs = layers.Dense(7, activation='sigmoid')(x)
            
            # æ„å»ºæ¨¡å‹
            model = Model(inputs=inputs, outputs=outputs)
            
            # ç¼–è¯‘æ¨¡å‹
            model.compile(
                optimizer=optimizers.Adam(learning_rate=self.config.get('learning_rate', 0.001)),
                loss='mse',
                metrics=['mae']
            )
            
            # æ‰“å°æ¨¡å‹æ‘˜è¦
            model.summary()
            
            return model
        except Exception as e:
            raise ModelInitializationError("Transformer", str(e))
    
    def _point_wise_feed_forward_network(self, x):
        """å®ç°Transformerçš„å‰é¦ˆç½‘ç»œ"""
        x = layers.Dense(self.dff, activation='relu')(x)
        x = layers.Dropout(self.dropout_rate)(x)
        x = layers.Dense(self.d_model)(x)
        return x
    
    @handle_model_error
    def train(self, epochs=None, validation_split=0.2, batch_size=None):
        """
        è®­ç»ƒTransformeræ¨¡å‹
        
        Args:
            epochs: è®­ç»ƒè½®æ•°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„å€¼
            validation_split: éªŒè¯é›†æ¯”ä¾‹
            batch_size: æ‰¹å¤„ç†å¤§å°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„å€¼
            
        Returns:
            è®­ç»ƒæ˜¯å¦æˆåŠŸ
        """
        from .data_manager import DeepLearningDataManager
        from .training_utils import get_callbacks, TrainingVisualizer
        
        if epochs is None:
            epochs = self.config.get('epochs', 100)
        
        if batch_size is None:
            batch_size = self.config.get('batch_size', 64)
        
        logger_manager.info(f"å¼€å§‹è®­ç»ƒTransformeræ¨¡å‹: epochs={epochs}, batch_size={batch_size}")
        
        try:
            # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
            data_manager = DeepLearningDataManager()
            
            # å‡†å¤‡æ‰¹å¤„ç†æ•°æ®
            batch_data = data_manager.prepare_batch_data(
                sequence_length=self.sequence_length,
                batch_size=batch_size,
                validation_split=validation_split
            )
            
            # æ›´æ–°ç‰¹å¾ç»´åº¦
            self.feature_dim = batch_data['feature_dim']
            
            # æ„å»ºæ¨¡å‹
            if self.model is None:
                self.model = self._build_model()
            
            # è·å–å›è°ƒå‡½æ•°
            callbacks = get_callbacks(self.name, epochs)
            
            # è®­ç»ƒæ¨¡å‹
            history = self.model.fit(
                batch_data['train_dataset'],
                epochs=epochs,
                validation_data=batch_data['val_dataset'],
                callbacks=callbacks,
                verbose=0  # ä½¿ç”¨è‡ªå®šä¹‰è¿›åº¦æ¡ï¼Œç¦ç”¨TensorFlowçš„è¿›åº¦æ¡
            )
            
            self.is_trained = True
            
            # ä¿å­˜æ¨¡å‹
            self._save_model()
            
            # å¯è§†åŒ–è®­ç»ƒå†å²
            visualizer = TrainingVisualizer(self.name)
            visualizer.plot_training_history(history.history)
            
            logger_manager.info(f"{self.name}æ¨¡å‹è®­ç»ƒå®Œæˆ")
            
            return True
        
        except Exception as e:
            logger_manager.error(f"{self.name}æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    @handle_model_error
    def predict(self, count=1, verbose=True) -> List[Tuple[List[int], List[int]]]:
        """
        ç”Ÿæˆé¢„æµ‹ç»“æœ
        
        Args:
            count: é¢„æµ‹æ³¨æ•°
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            
        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(å‰åŒºå·ç åˆ—è¡¨, ååŒºå·ç åˆ—è¡¨)
        """
        from .prediction_utils import PredictionProcessor
        
        # å°è¯•åŠ è½½å·²æœ‰æ¨¡å‹
        if not self.is_trained:
            if not self._load_model():
                logger_manager.info(f"{self.name}æ¨¡å‹æœªè®­ç»ƒï¼Œå¼€å§‹è®­ç»ƒ...")
                if not self.train():
                    logger_manager.error(f"{self.name}æ¨¡å‹è®­ç»ƒå¤±è´¥")
                    return []
        
        # è·å–æœ€è¿‘çš„åºåˆ—æ•°æ®
        recent_features = self._extract_features(self.df.head(self.sequence_length))
        recent_scaled = self.scaler.transform(recent_features)
        
        # å‡†å¤‡è¾“å…¥åºåˆ—
        input_sequence = recent_scaled.reshape(1, self.sequence_length, self.feature_dim)
        
        # åˆ›å»ºé¢„æµ‹å¤„ç†å™¨
        processor = PredictionProcessor()
        
        predictions = []
        raw_predictions = []
        
        if verbose:
            logger_manager.info(f"ä½¿ç”¨{self.name}æ¨¡å‹ç”Ÿæˆ{count}æ³¨é¢„æµ‹...")
        
        for i in range(count):
            # é¢„æµ‹
            pred_scaled = self.model.predict(input_sequence, verbose=0)
            
            # åæ ‡å‡†åŒ–
            # åˆ›å»ºå®Œæ•´ç‰¹å¾å‘é‡ç”¨äºåæ ‡å‡†åŒ–
            full_pred = np.zeros((1, self.feature_dim))
            full_pred[0, :7] = pred_scaled[0]
            pred_original = self.scaler.inverse_transform(full_pred)[0, :7]
            
            # ä¿å­˜åŸå§‹é¢„æµ‹ç»“æœ
            raw_predictions.append(pred_original)
            
            # å¤„ç†é¢„æµ‹ç»“æœ
            front_balls, back_balls = processor.process_raw_prediction(pred_original)
            predictions.append((front_balls, back_balls))
            
            # æ›´æ–°è¾“å…¥åºåˆ—ç”¨äºä¸‹ä¸€æ¬¡é¢„æµ‹
            new_feature = np.concatenate([pred_original, recent_scaled[-1, 7:]])
            input_sequence = np.roll(input_sequence, -1, axis=1)
            input_sequence[0, -1] = new_feature
            
            if verbose:
                formatted = processor.format_prediction((front_balls, back_balls))
                logger_manager.info(f"é¢„æµ‹ {i+1}/{count}: {formatted}")
        
        # è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦
        confidence = processor.calculate_confidence(predictions)
        
        if verbose:
            logger_manager.info(f"{self.name}é¢„æµ‹å®Œæˆï¼Œç½®ä¿¡åº¦: {confidence:.2f}")
        
        return predictions
    
    def predict_with_details(self, count=1) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¸¦è¯¦ç»†ä¿¡æ¯çš„é¢„æµ‹ç»“æœ
        
        Args:
            count: é¢„æµ‹æ³¨æ•°
            
        Returns:
            åŒ…å«é¢„æµ‹ç»“æœå’Œè¯¦ç»†ä¿¡æ¯çš„å­—å…¸
        """
        from .prediction_utils import PredictionProcessor
        
        # æ‰§è¡Œé¢„æµ‹
        predictions = self.predict(count, verbose=False)
        
        # åˆ›å»ºé¢„æµ‹å¤„ç†å™¨
        processor = PredictionProcessor()
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = processor.calculate_confidence(predictions)
        
        # æ ¼å¼åŒ–é¢„æµ‹ç»“æœ
        formatted_predictions = []
        for i, pred in enumerate(predictions):
            formatted = processor.format_prediction(pred)
            formatted_predictions.append({
                'index': i + 1,
                'front_balls': pred[0],
                'back_balls': pred[1],
                'formatted': formatted
            })
        
        # è¿”å›è¯¦ç»†ç»“æœ
        return {
            'model_name': self.name,
            'count': count,
            'predictions': formatted_predictions,
            'confidence': confidence,
            'model_config': {
                'd_model': self.d_model,
                'num_heads': self.num_heads,
                'num_layers': self.num_layers
            },
            'timestamp': datetime.now().isoformat()
        }
    
    def evaluate_predictions(self, predictions: List[Tuple[List[int], List[int]]], 
                           actuals: List[Tuple[List[int], List[int]]]) -> Dict[str, Any]:
        """
        è¯„ä¼°é¢„æµ‹ç»“æœ
        
        Args:
            predictions: é¢„æµ‹ç»“æœåˆ—è¡¨
            actuals: å®é™…ç»“æœåˆ—è¡¨
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        from .prediction_utils import PredictionEvaluator
        
        evaluator = PredictionEvaluator()
        return evaluator.evaluate_multiple_predictions(predictions, actuals)
    
    def get_confidence(self) -> float:
        """
        è·å–é¢„æµ‹ç½®ä¿¡åº¦
        
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•° (0.0-1.0)
        """
        if not self.is_trained:
            return 0.0
        
        # åŸºäºæ¨¡å‹éªŒè¯æ€§èƒ½è®¡ç®—ç½®ä¿¡åº¦
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„å¯å‘å¼æ–¹æ³•ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥åŸºäºéªŒè¯é›†æ€§èƒ½
        base_confidence = 0.7
        
        # æ ¹æ®æ¨¡å‹å¤æ‚åº¦è°ƒæ•´
        complexity_factor = min(1.0, (self.num_layers * self.num_heads) / 40)
        
        # æ ¹æ®è®­ç»ƒæ•°æ®é‡è°ƒæ•´
        data_factor = min(1.0, len(self.df) / 1000)
        
        confidence = base_confidence * complexity_factor * data_factor
        
        return min(0.95, confidence)  # æœ€é«˜ç½®ä¿¡åº¦é™åˆ¶åœ¨0.95
    
    def use_fallback_config(self):
        """ä½¿ç”¨å¤‡ç”¨é…ç½®"""
        logger_manager.info("ä½¿ç”¨Transformerå¤‡ç”¨é…ç½®")
        
        # ç®€åŒ–æ¨¡å‹é…ç½®
        self.d_model = 64
        self.num_heads = 4
        self.num_layers = 2
        self.dff = 256
        self.dropout_rate = 0.2
        
        # æ›´æ–°é…ç½®å­—å…¸
        self.config.update({
            'd_model': self.d_model,
            'num_heads': self.num_heads,
            'num_layers': self.num_layers,
            'dff': self.dff,
            'dropout_rate': self.dropout_rate
        })
    
    def use_simple_model(self):
        """ä½¿ç”¨ç®€å•æ¨¡å‹"""
        logger_manager.info("ä½¿ç”¨ç®€å•Transformeræ¨¡å‹")
        
        # æç®€é…ç½®
        self.d_model = 32
        self.num_heads = 2
        self.num_layers = 1
        self.dff = 128
        self.dropout_rate = 0.1
        
        # æ›´æ–°é…ç½®å­—å…¸
        self.config.update({
            'd_model': self.d_model,
            'num_heads': self.num_heads,
            'num_layers': self.num_layers,
            'dff': self.dff,
            'dropout_rate': self.dropout_rate
        })


if __name__ == "__main__":
    # æµ‹è¯•Transformeré¢„æµ‹å™¨
    print("ğŸ§  æµ‹è¯•Transformeré¢„æµ‹å™¨...")
    
    # åˆ›å»ºé¢„æµ‹å™¨
    transformer = TransformerPredictor()
    
    # è®­ç»ƒæ¨¡å‹
    transformer.train(epochs=10)
    
    # è¿›è¡Œé¢„æµ‹
    predictions = transformer.predict(3)
    
    print("Transformeré¢„æµ‹ç»“æœ:")
    for i, (front, back) in enumerate(predictions):
        front_str = ' '.join([str(b).zfill(2) for b in front])
        back_str = ' '.join([str(b).zfill(2) for b in back])
        print(f"ç¬¬ {i+1} æ³¨: {front_str} + {back_str}")