#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç½®ä¿¡åº¦è®¡ç®—å™¨æ¨¡å—
Confidence Calculator Module

æä¾›å¤šç§ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•å’Œä¸ç¡®å®šæ€§é‡åŒ–åŠŸèƒ½ã€‚
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
import warnings
warnings.filterwarnings('ignore')

from core_modules import logger_manager
from ..utils.exceptions import PredictionException


class ConfidenceMethod(Enum):
    """ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•æšä¸¾"""
    ENTROPY = "entropy"
    VARIANCE = "variance"
    ENSEMBLE_AGREEMENT = "ensemble_agreement"
    PREDICTION_INTERVAL = "prediction_interval"
    BAYESIAN = "bayesian"
    MONTE_CARLO = "monte_carlo"
    TEMPERATURE_SCALING = "temperature_scaling"


@dataclass
class ConfidenceScore:
    """ç½®ä¿¡åº¦åˆ†æ•°"""
    method: ConfidenceMethod
    score: float
    uncertainty: float
    details: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


class BaseConfidenceCalculator(ABC):
    """ç½®ä¿¡åº¦è®¡ç®—å™¨åŸºç±»"""
    
    def __init__(self, method: ConfidenceMethod):
        """
        åˆå§‹åŒ–ç½®ä¿¡åº¦è®¡ç®—å™¨
        
        Args:
            method: ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•
        """
        self.method = method
        
    @abstractmethod
    def calculate(self, predictions: np.ndarray, **kwargs) -> np.ndarray:
        """
        è®¡ç®—ç½®ä¿¡åº¦
        
        Args:
            predictions: é¢„æµ‹ç»“æœ
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•°æ•°ç»„
        """
        pass
    
    def validate_input(self, predictions: np.ndarray) -> bool:
        """éªŒè¯è¾“å…¥æ•°æ®"""
        try:
            if not isinstance(predictions, np.ndarray):
                raise PredictionException("é¢„æµ‹ç»“æœå¿…é¡»æ˜¯numpyæ•°ç»„")
            
            if len(predictions) == 0:
                raise PredictionException("é¢„æµ‹ç»“æœä¸èƒ½ä¸ºç©º")
            
            if np.any(np.isnan(predictions)) or np.any(np.isinf(predictions)):
                raise PredictionException("é¢„æµ‹ç»“æœåŒ…å«æ— æ•ˆå€¼")
            
            return True
            
        except Exception as e:
            logger_manager.error(f"è¾“å…¥éªŒè¯å¤±è´¥: {e}")
            return False


class EntropyConfidenceCalculator(BaseConfidenceCalculator):
    """åŸºäºç†µçš„ç½®ä¿¡åº¦è®¡ç®—å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç†µç½®ä¿¡åº¦è®¡ç®—å™¨"""
        super().__init__(ConfidenceMethod.ENTROPY)
        logger_manager.debug("ç†µç½®ä¿¡åº¦è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate(self, predictions: np.ndarray, **kwargs) -> np.ndarray:
        """
        åŸºäºç†µè®¡ç®—ç½®ä¿¡åº¦
        
        Args:
            predictions: é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ (N, C) å…¶ä¸­Næ˜¯æ ·æœ¬æ•°ï¼ŒCæ˜¯ç±»åˆ«æ•°
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•°æ•°ç»„
        """
        try:
            if not self.validate_input(predictions):
                raise PredictionException("è¾“å…¥éªŒè¯å¤±è´¥")
            
            # ç¡®ä¿æ˜¯æ¦‚ç‡åˆ†å¸ƒ
            if predictions.ndim == 1:
                # å•ä¸€é¢„æµ‹å€¼ï¼Œè½¬æ¢ä¸ºäºŒåˆ†ç±»æ¦‚ç‡
                probs = np.column_stack([1 - predictions, predictions])
            else:
                probs = predictions
            
            # å½’ä¸€åŒ–ç¡®ä¿æ˜¯æ¦‚ç‡åˆ†å¸ƒ
            probs = probs / np.sum(probs, axis=1, keepdims=True)
            
            # é¿å…log(0)
            probs = np.clip(probs, 1e-10, 1.0)
            
            # è®¡ç®—ç†µ
            entropy = -np.sum(probs * np.log(probs), axis=1)
            
            # å½’ä¸€åŒ–ç†µåˆ°[0,1]èŒƒå›´ï¼Œç†µè¶Šå°ç½®ä¿¡åº¦è¶Šé«˜
            max_entropy = np.log(probs.shape[1])
            normalized_entropy = entropy / max_entropy
            
            # ç½®ä¿¡åº¦ = 1 - å½’ä¸€åŒ–ç†µ
            confidence = 1.0 - normalized_entropy
            
            logger_manager.debug(f"ç†µç½®ä¿¡åº¦è®¡ç®—å®Œæˆï¼Œå¹³å‡ç½®ä¿¡åº¦: {np.mean(confidence):.4f}")
            return confidence
            
        except Exception as e:
            logger_manager.error(f"ç†µç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            raise PredictionException(f"ç†µç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")


class VarianceConfidenceCalculator(BaseConfidenceCalculator):
    """åŸºäºæ–¹å·®çš„ç½®ä¿¡åº¦è®¡ç®—å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ–¹å·®ç½®ä¿¡åº¦è®¡ç®—å™¨"""
        super().__init__(ConfidenceMethod.VARIANCE)
        logger_manager.debug("æ–¹å·®ç½®ä¿¡åº¦è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate(self, predictions: np.ndarray, **kwargs) -> np.ndarray:
        """
        åŸºäºæ–¹å·®è®¡ç®—ç½®ä¿¡åº¦
        
        Args:
            predictions: é¢„æµ‹ç»“æœ (N, M) å…¶ä¸­Næ˜¯æ ·æœ¬æ•°ï¼ŒMæ˜¯é¢„æµ‹æ¬¡æ•°æˆ–ç‰¹å¾æ•°
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•°æ•°ç»„
        """
        try:
            if not self.validate_input(predictions):
                raise PredictionException("è¾“å…¥éªŒè¯å¤±è´¥")
            
            if predictions.ndim == 1:
                # å•ä¸€é¢„æµ‹ï¼Œæ— æ³•è®¡ç®—æ–¹å·®
                return np.ones(len(predictions))
            
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æ–¹å·®
            variances = np.var(predictions, axis=1)
            
            # å½’ä¸€åŒ–æ–¹å·®åˆ°[0,1]èŒƒå›´
            if np.max(variances) > 0:
                normalized_variance = variances / np.max(variances)
            else:
                normalized_variance = variances
            
            # ç½®ä¿¡åº¦ = 1 - å½’ä¸€åŒ–æ–¹å·®
            confidence = 1.0 - normalized_variance
            
            logger_manager.debug(f"æ–¹å·®ç½®ä¿¡åº¦è®¡ç®—å®Œæˆï¼Œå¹³å‡ç½®ä¿¡åº¦: {np.mean(confidence):.4f}")
            return confidence
            
        except Exception as e:
            logger_manager.error(f"æ–¹å·®ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            raise PredictionException(f"æ–¹å·®ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")


class EnsembleAgreementCalculator(BaseConfidenceCalculator):
    """åŸºäºé›†æˆä¸€è‡´æ€§çš„ç½®ä¿¡åº¦è®¡ç®—å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é›†æˆä¸€è‡´æ€§ç½®ä¿¡åº¦è®¡ç®—å™¨"""
        super().__init__(ConfidenceMethod.ENSEMBLE_AGREEMENT)
        logger_manager.debug("é›†æˆä¸€è‡´æ€§ç½®ä¿¡åº¦è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate(self, predictions: np.ndarray, **kwargs) -> np.ndarray:
        """
        åŸºäºé›†æˆæ¨¡å‹ä¸€è‡´æ€§è®¡ç®—ç½®ä¿¡åº¦
        
        Args:
            predictions: é›†æˆé¢„æµ‹ç»“æœ (N, M) å…¶ä¸­Næ˜¯æ ·æœ¬æ•°ï¼ŒMæ˜¯æ¨¡å‹æ•°
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•°æ•°ç»„
        """
        try:
            if not self.validate_input(predictions):
                raise PredictionException("è¾“å…¥éªŒè¯å¤±è´¥")
            
            if predictions.ndim == 1:
                # å•ä¸€é¢„æµ‹ï¼Œæ— æ³•è®¡ç®—ä¸€è‡´æ€§
                return np.ones(len(predictions))
            
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æ ‡å‡†å·®ï¼ˆä¸ä¸€è‡´æ€§ï¼‰
            std_devs = np.std(predictions, axis=1)
            
            # è®¡ç®—ç›¸å¯¹æ ‡å‡†å·®
            means = np.mean(predictions, axis=1)
            relative_std = np.where(means != 0, std_devs / np.abs(means), std_devs)
            
            # å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´
            if np.max(relative_std) > 0:
                normalized_std = relative_std / np.max(relative_std)
            else:
                normalized_std = relative_std
            
            # ç½®ä¿¡åº¦ = 1 - å½’ä¸€åŒ–æ ‡å‡†å·®
            confidence = 1.0 - normalized_std
            
            logger_manager.debug(f"é›†æˆä¸€è‡´æ€§ç½®ä¿¡åº¦è®¡ç®—å®Œæˆï¼Œå¹³å‡ç½®ä¿¡åº¦: {np.mean(confidence):.4f}")
            return confidence
            
        except Exception as e:
            logger_manager.error(f"é›†æˆä¸€è‡´æ€§ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            raise PredictionException(f"é›†æˆä¸€è‡´æ€§ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")


class PredictionIntervalCalculator(BaseConfidenceCalculator):
    """åŸºäºé¢„æµ‹åŒºé—´çš„ç½®ä¿¡åº¦è®¡ç®—å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é¢„æµ‹åŒºé—´ç½®ä¿¡åº¦è®¡ç®—å™¨"""
        super().__init__(ConfidenceMethod.PREDICTION_INTERVAL)
        logger_manager.debug("é¢„æµ‹åŒºé—´ç½®ä¿¡åº¦è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate(self, predictions: np.ndarray, **kwargs) -> np.ndarray:
        """
        åŸºäºé¢„æµ‹åŒºé—´è®¡ç®—ç½®ä¿¡åº¦
        
        Args:
            predictions: é¢„æµ‹ç»“æœ
            **kwargs: å…¶ä»–å‚æ•°ï¼ŒåŒ…æ‹¬confidence_level
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•°æ•°ç»„
        """
        try:
            if not self.validate_input(predictions):
                raise PredictionException("è¾“å…¥éªŒè¯å¤±è´¥")
            
            confidence_level = kwargs.get('confidence_level', 0.95)
            
            if predictions.ndim == 1:
                # å•ä¸€é¢„æµ‹ï¼Œä½¿ç”¨ç®€å•çš„ç½®ä¿¡åº¦ä¼°è®¡
                return np.full(len(predictions), confidence_level)
            
            # è®¡ç®—é¢„æµ‹åŒºé—´
            alpha = 1 - confidence_level
            lower_percentile = (alpha / 2) * 100
            upper_percentile = (1 - alpha / 2) * 100
            
            lower_bounds = np.percentile(predictions, lower_percentile, axis=1)
            upper_bounds = np.percentile(predictions, upper_percentile, axis=1)
            
            # è®¡ç®—åŒºé—´å®½åº¦
            interval_widths = upper_bounds - lower_bounds
            
            # å½’ä¸€åŒ–åŒºé—´å®½åº¦
            if np.max(interval_widths) > 0:
                normalized_widths = interval_widths / np.max(interval_widths)
            else:
                normalized_widths = interval_widths
            
            # ç½®ä¿¡åº¦ä¸åŒºé—´å®½åº¦æˆåæ¯”
            confidence = 1.0 - normalized_widths
            
            logger_manager.debug(f"é¢„æµ‹åŒºé—´ç½®ä¿¡åº¦è®¡ç®—å®Œæˆï¼Œå¹³å‡ç½®ä¿¡åº¦: {np.mean(confidence):.4f}")
            return confidence
            
        except Exception as e:
            logger_manager.error(f"é¢„æµ‹åŒºé—´ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            raise PredictionException(f"é¢„æµ‹åŒºé—´ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")


class MonteCarloConfidenceCalculator(BaseConfidenceCalculator):
    """åŸºäºè’™ç‰¹å¡æ´›çš„ç½®ä¿¡åº¦è®¡ç®—å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è’™ç‰¹å¡æ´›ç½®ä¿¡åº¦è®¡ç®—å™¨"""
        super().__init__(ConfidenceMethod.MONTE_CARLO)
        logger_manager.debug("è’™ç‰¹å¡æ´›ç½®ä¿¡åº¦è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate(self, predictions: np.ndarray, **kwargs) -> np.ndarray:
        """
        åŸºäºè’™ç‰¹å¡æ´›é‡‡æ ·è®¡ç®—ç½®ä¿¡åº¦
        
        Args:
            predictions: è’™ç‰¹å¡æ´›é‡‡æ ·é¢„æµ‹ç»“æœ (N, M) å…¶ä¸­Næ˜¯æ ·æœ¬æ•°ï¼ŒMæ˜¯é‡‡æ ·æ¬¡æ•°
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•°æ•°ç»„
        """
        try:
            if not self.validate_input(predictions):
                raise PredictionException("è¾“å…¥éªŒè¯å¤±è´¥")
            
            if predictions.ndim == 1:
                # å•ä¸€é¢„æµ‹ï¼Œæ— æ³•è¿›è¡Œè’™ç‰¹å¡æ´›åˆ†æ
                return np.ones(len(predictions))
            
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ç»Ÿè®¡é‡
            means = np.mean(predictions, axis=1)
            stds = np.std(predictions, axis=1)
            
            # è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆç›¸å¯¹æ ‡å‡†å·®ï¼‰
            cv = np.where(means != 0, stds / np.abs(means), stds)
            
            # å½’ä¸€åŒ–å˜å¼‚ç³»æ•°
            if np.max(cv) > 0:
                normalized_cv = cv / np.max(cv)
            else:
                normalized_cv = cv
            
            # ç½®ä¿¡åº¦ä¸å˜å¼‚ç³»æ•°æˆåæ¯”
            confidence = 1.0 - normalized_cv
            
            # ç¡®ä¿ç½®ä¿¡åº¦åœ¨[0,1]èŒƒå›´å†…
            confidence = np.clip(confidence, 0.0, 1.0)
            
            logger_manager.debug(f"è’™ç‰¹å¡æ´›ç½®ä¿¡åº¦è®¡ç®—å®Œæˆï¼Œå¹³å‡ç½®ä¿¡åº¦: {np.mean(confidence):.4f}")
            return confidence
            
        except Exception as e:
            logger_manager.error(f"è’™ç‰¹å¡æ´›ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            raise PredictionException(f"è’™ç‰¹å¡æ´›ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")


class ConfidenceCalculator:
    """ç½®ä¿¡åº¦è®¡ç®—å™¨ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç½®ä¿¡åº¦è®¡ç®—å™¨"""
        self.calculators = {
            ConfidenceMethod.ENTROPY: EntropyConfidenceCalculator(),
            ConfidenceMethod.VARIANCE: VarianceConfidenceCalculator(),
            ConfidenceMethod.ENSEMBLE_AGREEMENT: EnsembleAgreementCalculator(),
            ConfidenceMethod.PREDICTION_INTERVAL: PredictionIntervalCalculator(),
            ConfidenceMethod.MONTE_CARLO: MonteCarloConfidenceCalculator()
        }
        
        logger_manager.info("ç½®ä¿¡åº¦è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate_confidence(self, predictions: np.ndarray, 
                           method: ConfidenceMethod = ConfidenceMethod.ENTROPY,
                           **kwargs) -> ConfidenceScore:
        """
        è®¡ç®—ç½®ä¿¡åº¦
        
        Args:
            predictions: é¢„æµ‹ç»“æœ
            method: ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•°å¯¹è±¡
        """
        try:
            if method not in self.calculators:
                raise PredictionException(f"ä¸æ”¯æŒçš„ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•: {method}")
            
            calculator = self.calculators[method]
            confidence_scores = calculator.calculate(predictions, **kwargs)
            
            # è®¡ç®—æ•´ä½“ç»Ÿè®¡é‡
            mean_confidence = float(np.mean(confidence_scores))
            uncertainty = float(np.std(confidence_scores))
            
            # åˆ›å»ºç½®ä¿¡åº¦åˆ†æ•°å¯¹è±¡
            confidence_score = ConfidenceScore(
                method=method,
                score=mean_confidence,
                uncertainty=uncertainty,
                details={
                    'individual_scores': confidence_scores.tolist(),
                    'min_confidence': float(np.min(confidence_scores)),
                    'max_confidence': float(np.max(confidence_scores)),
                    'median_confidence': float(np.median(confidence_scores)),
                    'confidence_distribution': self._analyze_confidence_distribution(confidence_scores)
                },
                metadata={
                    'sample_count': len(confidence_scores),
                    'method_parameters': kwargs
                }
            )
            
            logger_manager.info(f"ç½®ä¿¡åº¦è®¡ç®—å®Œæˆï¼Œæ–¹æ³•: {method.value}, å¹³å‡ç½®ä¿¡åº¦: {mean_confidence:.4f}")
            return confidence_score
            
        except Exception as e:
            logger_manager.error(f"ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            raise PredictionException(f"ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
    
    def calculate_multiple_confidence(self, predictions: np.ndarray,
                                    methods: List[ConfidenceMethod] = None,
                                    **kwargs) -> Dict[ConfidenceMethod, ConfidenceScore]:
        """
        ä½¿ç”¨å¤šç§æ–¹æ³•è®¡ç®—ç½®ä¿¡åº¦
        
        Args:
            predictions: é¢„æµ‹ç»“æœ
            methods: ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•°å­—å…¸
        """
        try:
            if methods is None:
                methods = [ConfidenceMethod.ENTROPY, ConfidenceMethod.VARIANCE]
            
            confidence_scores = {}
            
            for method in methods:
                try:
                    score = self.calculate_confidence(predictions, method, **kwargs)
                    confidence_scores[method] = score
                except Exception as e:
                    logger_manager.warning(f"æ–¹æ³• {method.value} è®¡ç®—å¤±è´¥: {e}")
                    continue
            
            logger_manager.info(f"å¤šæ–¹æ³•ç½®ä¿¡åº¦è®¡ç®—å®Œæˆï¼ŒæˆåŠŸæ–¹æ³•æ•°: {len(confidence_scores)}")
            return confidence_scores
            
        except Exception as e:
            logger_manager.error(f"å¤šæ–¹æ³•ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            raise PredictionException(f"å¤šæ–¹æ³•ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
    
    def ensemble_confidence(self, confidence_scores: Dict[ConfidenceMethod, ConfidenceScore],
                          weights: Dict[ConfidenceMethod, float] = None) -> ConfidenceScore:
        """
        é›†æˆå¤šç§ç½®ä¿¡åº¦è®¡ç®—ç»“æœ
        
        Args:
            confidence_scores: ç½®ä¿¡åº¦åˆ†æ•°å­—å…¸
            weights: æƒé‡å­—å…¸
            
        Returns:
            é›†æˆç½®ä¿¡åº¦åˆ†æ•°
        """
        try:
            if not confidence_scores:
                raise PredictionException("ç½®ä¿¡åº¦åˆ†æ•°å­—å…¸ä¸ºç©º")
            
            # é»˜è®¤ç­‰æƒé‡
            if weights is None:
                weights = {method: 1.0 for method in confidence_scores.keys()}
            
            # å½’ä¸€åŒ–æƒé‡
            total_weight = sum(weights.values())
            normalized_weights = {k: v / total_weight for k, v in weights.items()}
            
            # è®¡ç®—åŠ æƒå¹³å‡ç½®ä¿¡åº¦
            weighted_score = 0.0
            weighted_uncertainty = 0.0
            
            for method, score in confidence_scores.items():
                weight = normalized_weights.get(method, 0.0)
                weighted_score += score.score * weight
                weighted_uncertainty += score.uncertainty * weight
            
            # åˆ›å»ºé›†æˆç½®ä¿¡åº¦åˆ†æ•°
            ensemble_score = ConfidenceScore(
                method=ConfidenceMethod.ENSEMBLE_AGREEMENT,  # ä½¿ç”¨é›†æˆæ ‡è¯†
                score=weighted_score,
                uncertainty=weighted_uncertainty,
                details={
                    'individual_methods': {method.value: score.score for method, score in confidence_scores.items()},
                    'weights': {method.value: weight for method, weight in normalized_weights.items()},
                    'method_count': len(confidence_scores)
                },
                metadata={
                    'ensemble_type': 'weighted_average',
                    'component_methods': [method.value for method in confidence_scores.keys()]
                }
            )
            
            logger_manager.info(f"é›†æˆç½®ä¿¡åº¦è®¡ç®—å®Œæˆï¼Œæœ€ç»ˆç½®ä¿¡åº¦: {weighted_score:.4f}")
            return ensemble_score
            
        except Exception as e:
            logger_manager.error(f"é›†æˆç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            raise PredictionException(f"é›†æˆç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
    
    def _analyze_confidence_distribution(self, confidence_scores: np.ndarray) -> Dict[str, float]:
        """åˆ†æç½®ä¿¡åº¦åˆ†å¸ƒ"""
        try:
            return {
                'very_high': float(np.sum(confidence_scores > 0.9) / len(confidence_scores)),
                'high': float(np.sum((confidence_scores > 0.7) & (confidence_scores <= 0.9)) / len(confidence_scores)),
                'medium': float(np.sum((confidence_scores > 0.5) & (confidence_scores <= 0.7)) / len(confidence_scores)),
                'low': float(np.sum(confidence_scores <= 0.5) / len(confidence_scores))
            }
        except Exception:
            return {}
    
    def get_available_methods(self) -> List[ConfidenceMethod]:
        """è·å–å¯ç”¨çš„ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•"""
        return list(self.calculators.keys())


# å…¨å±€ç½®ä¿¡åº¦è®¡ç®—å™¨å®ä¾‹
confidence_calculator = ConfidenceCalculator()


if __name__ == "__main__":
    # æµ‹è¯•ç½®ä¿¡åº¦è®¡ç®—å™¨åŠŸèƒ½
    print("ğŸ¯ æµ‹è¯•ç½®ä¿¡åº¦è®¡ç®—å™¨åŠŸèƒ½...")
    
    try:
        import numpy as np
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        # æ¨¡æ‹Ÿé›†æˆé¢„æµ‹ç»“æœ
        ensemble_predictions = np.random.random((100, 5))  # 100ä¸ªæ ·æœ¬ï¼Œ5ä¸ªæ¨¡å‹
        
        # æ¨¡æ‹Ÿæ¦‚ç‡åˆ†å¸ƒ
        prob_predictions = np.random.dirichlet([1, 1, 1], 100)  # 100ä¸ªæ ·æœ¬ï¼Œ3ä¸ªç±»åˆ«
        
        calculator = ConfidenceCalculator()
        
        # æµ‹è¯•ç†µç½®ä¿¡åº¦
        entropy_score = calculator.calculate_confidence(
            prob_predictions, 
            ConfidenceMethod.ENTROPY
        )
        print(f"âœ… ç†µç½®ä¿¡åº¦è®¡ç®—æˆåŠŸï¼Œå¹³å‡ç½®ä¿¡åº¦: {entropy_score.score:.4f}")
        
        # æµ‹è¯•æ–¹å·®ç½®ä¿¡åº¦
        variance_score = calculator.calculate_confidence(
            ensemble_predictions, 
            ConfidenceMethod.VARIANCE
        )
        print(f"âœ… æ–¹å·®ç½®ä¿¡åº¦è®¡ç®—æˆåŠŸï¼Œå¹³å‡ç½®ä¿¡åº¦: {variance_score.score:.4f}")
        
        # æµ‹è¯•é›†æˆä¸€è‡´æ€§ç½®ä¿¡åº¦
        agreement_score = calculator.calculate_confidence(
            ensemble_predictions, 
            ConfidenceMethod.ENSEMBLE_AGREEMENT
        )
        print(f"âœ… é›†æˆä¸€è‡´æ€§ç½®ä¿¡åº¦è®¡ç®—æˆåŠŸï¼Œå¹³å‡ç½®ä¿¡åº¦: {agreement_score.score:.4f}")
        
        # æµ‹è¯•å¤šæ–¹æ³•ç½®ä¿¡åº¦è®¡ç®—
        multi_scores = calculator.calculate_multiple_confidence(
            ensemble_predictions,
            methods=[ConfidenceMethod.VARIANCE, ConfidenceMethod.ENSEMBLE_AGREEMENT]
        )
        print(f"âœ… å¤šæ–¹æ³•ç½®ä¿¡åº¦è®¡ç®—æˆåŠŸï¼Œæ–¹æ³•æ•°: {len(multi_scores)}")
        
        # æµ‹è¯•é›†æˆç½®ä¿¡åº¦
        ensemble_confidence = calculator.ensemble_confidence(multi_scores)
        print(f"âœ… é›†æˆç½®ä¿¡åº¦è®¡ç®—æˆåŠŸï¼Œæœ€ç»ˆç½®ä¿¡åº¦: {ensemble_confidence.score:.4f}")
        
        # æµ‹è¯•å¯ç”¨æ–¹æ³•
        available_methods = calculator.get_available_methods()
        print(f"âœ… å¯ç”¨æ–¹æ³•è·å–æˆåŠŸï¼Œæ–¹æ³•æ•°: {len(available_methods)}")
        
        print("âœ… ç½®ä¿¡åº¦è®¡ç®—å™¨åŠŸèƒ½æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("ç½®ä¿¡åº¦è®¡ç®—å™¨åŠŸèƒ½æµ‹è¯•å®Œæˆ")
