#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è¶…å‚æ•°ä¼˜åŒ–æ¨¡å—
Hyperparameter Optimization Module

æä¾›è´å¶æ–¯ä¼˜åŒ–ã€ç½‘æ ¼æœç´¢ã€éšæœºæœç´¢ã€é—ä¼ ç®—æ³•ç­‰è¶…å‚æ•°ä¼˜åŒ–æ–¹æ³•ã€‚
"""

import os
import time
import random
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Callable, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import json
import pickle
from concurrent.futures import ThreadPoolExecutor, as_completed
import itertools
import math

from core_modules import logger_manager
from ..utils.exceptions import DeepLearningException


class OptimizationMethod(Enum):
    """ä¼˜åŒ–æ–¹æ³•æšä¸¾"""
    GRID_SEARCH = "grid_search"
    RANDOM_SEARCH = "random_search"
    BAYESIAN = "bayesian"
    GENETIC = "genetic"
    PARTICLE_SWARM = "particle_swarm"
    HYPERBAND = "hyperband"


@dataclass
class HyperParameter:
    """è¶…å‚æ•°å®šä¹‰"""
    name: str
    param_type: str  # 'int', 'float', 'categorical', 'bool'
    min_value: Optional[Union[int, float]] = None
    max_value: Optional[Union[int, float]] = None
    choices: Optional[List[Any]] = None
    log_scale: bool = False
    default_value: Any = None


@dataclass
class OptimizationConfig:
    """ä¼˜åŒ–é…ç½®"""
    method: OptimizationMethod
    max_trials: int = 100
    max_time: Optional[float] = None  # æœ€å¤§ä¼˜åŒ–æ—¶é—´ï¼ˆç§’ï¼‰
    n_jobs: int = 1
    cv_folds: int = 5
    scoring_metric: str = 'accuracy'
    early_stopping: bool = True
    patience: int = 10
    random_state: Optional[int] = None


@dataclass
class Trial:
    """è¯•éªŒè®°å½•"""
    trial_id: int
    parameters: Dict[str, Any]
    score: float
    duration: float
    status: str = 'completed'  # 'completed', 'failed', 'pruned'
    metadata: Dict[str, Any] = field(default_factory=dict)


class GridSearchOptimizer:
    """ç½‘æ ¼æœç´¢ä¼˜åŒ–å™¨"""
    
    def __init__(self, parameters: List[HyperParameter], config: OptimizationConfig):
        """
        åˆå§‹åŒ–ç½‘æ ¼æœç´¢ä¼˜åŒ–å™¨
        
        Args:
            parameters: è¶…å‚æ•°åˆ—è¡¨
            config: ä¼˜åŒ–é…ç½®
        """
        self.parameters = parameters
        self.config = config
        self.param_grid = self._build_param_grid()
        
        logger_manager.info(f"ç½‘æ ¼æœç´¢ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œå‚æ•°ç»„åˆæ•°: {len(self.param_grid)}")
    
    def _build_param_grid(self) -> List[Dict[str, Any]]:
        """æ„å»ºå‚æ•°ç½‘æ ¼"""
        try:
            param_values = {}
            
            for param in self.parameters:
                if param.param_type == 'categorical':
                    param_values[param.name] = param.choices
                elif param.param_type == 'bool':
                    param_values[param.name] = [True, False]
                elif param.param_type in ['int', 'float']:
                    # ä¸ºæ•°å€¼å‚æ•°åˆ›å»ºç½‘æ ¼
                    if param.log_scale:
                        values = np.logspace(
                            np.log10(param.min_value),
                            np.log10(param.max_value),
                            num=10
                        )
                    else:
                        values = np.linspace(param.min_value, param.max_value, num=10)
                    
                    if param.param_type == 'int':
                        values = [int(v) for v in values]
                    
                    param_values[param.name] = values
            
            # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
            keys = param_values.keys()
            combinations = itertools.product(*param_values.values())
            param_grid = [dict(zip(keys, combo)) for combo in combinations]
            
            # é™åˆ¶ç»„åˆæ•°é‡
            if len(param_grid) > self.config.max_trials:
                random.shuffle(param_grid)
                param_grid = param_grid[:self.config.max_trials]
            
            return param_grid
            
        except Exception as e:
            logger_manager.error(f"æ„å»ºå‚æ•°ç½‘æ ¼å¤±è´¥: {e}")
            return [{}]
    
    def optimize(self, objective_function: Callable) -> List[Trial]:
        """
        æ‰§è¡Œç½‘æ ¼æœç´¢ä¼˜åŒ–
        
        Args:
            objective_function: ç›®æ ‡å‡½æ•°
            
        Returns:
            è¯•éªŒç»“æœåˆ—è¡¨
        """
        try:
            trials = []
            start_time = time.time()
            
            for i, params in enumerate(self.param_grid):
                # æ£€æŸ¥æ—¶é—´é™åˆ¶
                if self.config.max_time and (time.time() - start_time) > self.config.max_time:
                    logger_manager.info(f"è¾¾åˆ°æ—¶é—´é™åˆ¶ï¼Œåœæ­¢ä¼˜åŒ–")
                    break
                
                # æ‰§è¡Œè¯•éªŒ
                trial_start = time.time()
                try:
                    score = objective_function(params)
                    status = 'completed'
                except Exception as e:
                    logger_manager.error(f"è¯•éªŒ {i} å¤±è´¥: {e}")
                    score = float('-inf')
                    status = 'failed'
                
                trial_duration = time.time() - trial_start
                
                trial = Trial(
                    trial_id=i,
                    parameters=params,
                    score=score,
                    duration=trial_duration,
                    status=status
                )
                
                trials.append(trial)
                
                logger_manager.debug(f"è¯•éªŒ {i}: åˆ†æ•°={score:.4f}, å‚æ•°={params}")
            
            # æŒ‰åˆ†æ•°æ’åº
            trials.sort(key=lambda x: x.score, reverse=True)
            
            logger_manager.info(f"ç½‘æ ¼æœç´¢å®Œæˆï¼Œæœ€ä½³åˆ†æ•°: {trials[0].score:.4f}")
            return trials
            
        except Exception as e:
            logger_manager.error(f"ç½‘æ ¼æœç´¢ä¼˜åŒ–å¤±è´¥: {e}")
            return []


class RandomSearchOptimizer:
    """éšæœºæœç´¢ä¼˜åŒ–å™¨"""
    
    def __init__(self, parameters: List[HyperParameter], config: OptimizationConfig):
        """
        åˆå§‹åŒ–éšæœºæœç´¢ä¼˜åŒ–å™¨
        
        Args:
            parameters: è¶…å‚æ•°åˆ—è¡¨
            config: ä¼˜åŒ–é…ç½®
        """
        self.parameters = parameters
        self.config = config
        
        if config.random_state:
            random.seed(config.random_state)
            np.random.seed(config.random_state)
        
        logger_manager.info("éšæœºæœç´¢ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _sample_parameter(self, param: HyperParameter) -> Any:
        """é‡‡æ ·å•ä¸ªå‚æ•°"""
        try:
            if param.param_type == 'categorical':
                return random.choice(param.choices)
            elif param.param_type == 'bool':
                return random.choice([True, False])
            elif param.param_type == 'int':
                if param.log_scale:
                    log_min = np.log10(param.min_value)
                    log_max = np.log10(param.max_value)
                    log_value = random.uniform(log_min, log_max)
                    return int(10 ** log_value)
                else:
                    return random.randint(param.min_value, param.max_value)
            elif param.param_type == 'float':
                if param.log_scale:
                    log_min = np.log10(param.min_value)
                    log_max = np.log10(param.max_value)
                    log_value = random.uniform(log_min, log_max)
                    return 10 ** log_value
                else:
                    return random.uniform(param.min_value, param.max_value)
            else:
                return param.default_value
                
        except Exception as e:
            logger_manager.error(f"å‚æ•°é‡‡æ ·å¤±è´¥: {e}")
            return param.default_value
    
    def _sample_parameters(self) -> Dict[str, Any]:
        """é‡‡æ ·å‚æ•°ç»„åˆ"""
        return {param.name: self._sample_parameter(param) for param in self.parameters}
    
    def optimize(self, objective_function: Callable) -> List[Trial]:
        """
        æ‰§è¡Œéšæœºæœç´¢ä¼˜åŒ–
        
        Args:
            objective_function: ç›®æ ‡å‡½æ•°
            
        Returns:
            è¯•éªŒç»“æœåˆ—è¡¨
        """
        try:
            trials = []
            start_time = time.time()
            
            for i in range(self.config.max_trials):
                # æ£€æŸ¥æ—¶é—´é™åˆ¶
                if self.config.max_time and (time.time() - start_time) > self.config.max_time:
                    logger_manager.info(f"è¾¾åˆ°æ—¶é—´é™åˆ¶ï¼Œåœæ­¢ä¼˜åŒ–")
                    break
                
                # é‡‡æ ·å‚æ•°
                params = self._sample_parameters()
                
                # æ‰§è¡Œè¯•éªŒ
                trial_start = time.time()
                try:
                    score = objective_function(params)
                    status = 'completed'
                except Exception as e:
                    logger_manager.error(f"è¯•éªŒ {i} å¤±è´¥: {e}")
                    score = float('-inf')
                    status = 'failed'
                
                trial_duration = time.time() - trial_start
                
                trial = Trial(
                    trial_id=i,
                    parameters=params,
                    score=score,
                    duration=trial_duration,
                    status=status
                )
                
                trials.append(trial)
                
                logger_manager.debug(f"è¯•éªŒ {i}: åˆ†æ•°={score:.4f}, å‚æ•°={params}")
            
            # æŒ‰åˆ†æ•°æ’åº
            trials.sort(key=lambda x: x.score, reverse=True)
            
            logger_manager.info(f"éšæœºæœç´¢å®Œæˆï¼Œæœ€ä½³åˆ†æ•°: {trials[0].score:.4f}")
            return trials
            
        except Exception as e:
            logger_manager.error(f"éšæœºæœç´¢ä¼˜åŒ–å¤±è´¥: {e}")
            return []


class BayesianOptimizer:
    """è´å¶æ–¯ä¼˜åŒ–å™¨ï¼ˆç®€åŒ–å®ç°ï¼‰"""
    
    def __init__(self, parameters: List[HyperParameter], config: OptimizationConfig):
        """
        åˆå§‹åŒ–è´å¶æ–¯ä¼˜åŒ–å™¨
        
        Args:
            parameters: è¶…å‚æ•°åˆ—è¡¨
            config: ä¼˜åŒ–é…ç½®
        """
        self.parameters = parameters
        self.config = config
        self.trials_history = []
        
        logger_manager.info("è´å¶æ–¯ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _acquisition_function(self, params: Dict[str, Any]) -> float:
        """
        è·å–å‡½æ•°ï¼ˆç®€åŒ–å®ç°ï¼‰
        
        Args:
            params: å‚æ•°ç»„åˆ
            
        Returns:
            è·å–å€¼
        """
        try:
            if not self.trials_history:
                return random.random()
            
            # ç®€åŒ–çš„æœŸæœ›æ”¹è¿›è®¡ç®—
            best_score = max(trial.score for trial in self.trials_history if trial.status == 'completed')
            
            # è®¡ç®—ä¸å†å²å‚æ•°çš„è·ç¦»
            distances = []
            for trial in self.trials_history:
                distance = 0
                for param_name, param_value in params.items():
                    if param_name in trial.parameters:
                        if isinstance(param_value, (int, float)):
                            distance += abs(param_value - trial.parameters[param_name])
                        else:
                            distance += 0 if param_value == trial.parameters[param_name] else 1
                distances.append(distance)
            
            # ç®€åŒ–çš„è·å–å‡½æ•°ï¼šè·ç¦»è¶Šè¿œï¼Œè·å–å€¼è¶Šé«˜
            min_distance = min(distances) if distances else 1
            acquisition_value = min_distance + random.random() * 0.1
            
            return acquisition_value
            
        except Exception as e:
            logger_manager.error(f"è®¡ç®—è·å–å‡½æ•°å¤±è´¥: {e}")
            return random.random()
    
    def _suggest_next_parameters(self) -> Dict[str, Any]:
        """å»ºè®®ä¸‹ä¸€ç»„å‚æ•°"""
        try:
            # ç”Ÿæˆå€™é€‰å‚æ•°
            candidates = []
            for _ in range(100):  # ç”Ÿæˆ100ä¸ªå€™é€‰
                candidate = {}
                for param in self.parameters:
                    if param.param_type == 'categorical':
                        candidate[param.name] = random.choice(param.choices)
                    elif param.param_type == 'bool':
                        candidate[param.name] = random.choice([True, False])
                    elif param.param_type == 'int':
                        if param.log_scale:
                            log_min = np.log10(param.min_value)
                            log_max = np.log10(param.max_value)
                            log_value = random.uniform(log_min, log_max)
                            candidate[param.name] = int(10 ** log_value)
                        else:
                            candidate[param.name] = random.randint(param.min_value, param.max_value)
                    elif param.param_type == 'float':
                        if param.log_scale:
                            log_min = np.log10(param.min_value)
                            log_max = np.log10(param.max_value)
                            log_value = random.uniform(log_min, log_max)
                            candidate[param.name] = 10 ** log_value
                        else:
                            candidate[param.name] = random.uniform(param.min_value, param.max_value)
                
                candidates.append(candidate)
            
            # é€‰æ‹©è·å–å€¼æœ€é«˜çš„å€™é€‰
            best_candidate = max(candidates, key=self._acquisition_function)
            return best_candidate
            
        except Exception as e:
            logger_manager.error(f"å»ºè®®å‚æ•°å¤±è´¥: {e}")
            # å›é€€åˆ°éšæœºé‡‡æ ·
            return {param.name: param.default_value for param in self.parameters}
    
    def optimize(self, objective_function: Callable) -> List[Trial]:
        """
        æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–
        
        Args:
            objective_function: ç›®æ ‡å‡½æ•°
            
        Returns:
            è¯•éªŒç»“æœåˆ—è¡¨
        """
        try:
            start_time = time.time()
            
            for i in range(self.config.max_trials):
                # æ£€æŸ¥æ—¶é—´é™åˆ¶
                if self.config.max_time and (time.time() - start_time) > self.config.max_time:
                    logger_manager.info(f"è¾¾åˆ°æ—¶é—´é™åˆ¶ï¼Œåœæ­¢ä¼˜åŒ–")
                    break
                
                # å»ºè®®å‚æ•°
                params = self._suggest_next_parameters()
                
                # æ‰§è¡Œè¯•éªŒ
                trial_start = time.time()
                try:
                    score = objective_function(params)
                    status = 'completed'
                except Exception as e:
                    logger_manager.error(f"è¯•éªŒ {i} å¤±è´¥: {e}")
                    score = float('-inf')
                    status = 'failed'
                
                trial_duration = time.time() - trial_start
                
                trial = Trial(
                    trial_id=i,
                    parameters=params,
                    score=score,
                    duration=trial_duration,
                    status=status
                )
                
                self.trials_history.append(trial)
                
                logger_manager.debug(f"è¯•éªŒ {i}: åˆ†æ•°={score:.4f}, å‚æ•°={params}")
            
            # æŒ‰åˆ†æ•°æ’åº
            self.trials_history.sort(key=lambda x: x.score, reverse=True)
            
            logger_manager.info(f"è´å¶æ–¯ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³åˆ†æ•°: {self.trials_history[0].score:.4f}")
            return self.trials_history
            
        except Exception as e:
            logger_manager.error(f"è´å¶æ–¯ä¼˜åŒ–å¤±è´¥: {e}")
            return []


class GeneticOptimizer:
    """é—ä¼ ç®—æ³•ä¼˜åŒ–å™¨"""
    
    def __init__(self, parameters: List[HyperParameter], config: OptimizationConfig):
        """
        åˆå§‹åŒ–é—ä¼ ç®—æ³•ä¼˜åŒ–å™¨
        
        Args:
            parameters: è¶…å‚æ•°åˆ—è¡¨
            config: ä¼˜åŒ–é…ç½®
        """
        self.parameters = parameters
        self.config = config
        self.population_size = min(50, config.max_trials // 2)
        self.mutation_rate = 0.1
        self.crossover_rate = 0.8
        
        logger_manager.info(f"é—ä¼ ç®—æ³•ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œç§ç¾¤å¤§å°: {self.population_size}")
    
    def _create_individual(self) -> Dict[str, Any]:
        """åˆ›å»ºä¸ªä½“"""
        individual = {}
        for param in self.parameters:
            if param.param_type == 'categorical':
                individual[param.name] = random.choice(param.choices)
            elif param.param_type == 'bool':
                individual[param.name] = random.choice([True, False])
            elif param.param_type == 'int':
                individual[param.name] = random.randint(param.min_value, param.max_value)
            elif param.param_type == 'float':
                individual[param.name] = random.uniform(param.min_value, param.max_value)
        
        return individual
    
    def _mutate(self, individual: Dict[str, Any]) -> Dict[str, Any]:
        """å˜å¼‚æ“ä½œ"""
        mutated = individual.copy()
        
        for param in self.parameters:
            if random.random() < self.mutation_rate:
                if param.param_type == 'categorical':
                    mutated[param.name] = random.choice(param.choices)
                elif param.param_type == 'bool':
                    mutated[param.name] = not mutated[param.name]
                elif param.param_type == 'int':
                    # é«˜æ–¯å˜å¼‚
                    current_value = mutated[param.name]
                    mutation = int(random.gauss(0, (param.max_value - param.min_value) * 0.1))
                    new_value = current_value + mutation
                    mutated[param.name] = max(param.min_value, min(param.max_value, new_value))
                elif param.param_type == 'float':
                    # é«˜æ–¯å˜å¼‚
                    current_value = mutated[param.name]
                    mutation = random.gauss(0, (param.max_value - param.min_value) * 0.1)
                    new_value = current_value + mutation
                    mutated[param.name] = max(param.min_value, min(param.max_value, new_value))
        
        return mutated
    
    def _crossover(self, parent1: Dict[str, Any], parent2: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """äº¤å‰æ“ä½œ"""
        if random.random() > self.crossover_rate:
            return parent1.copy(), parent2.copy()
        
        child1, child2 = parent1.copy(), parent2.copy()
        
        # éšæœºé€‰æ‹©äº¤å‰ç‚¹
        param_names = list(parent1.keys())
        crossover_point = random.randint(1, len(param_names) - 1)
        
        for i in range(crossover_point, len(param_names)):
            param_name = param_names[i]
            child1[param_name], child2[param_name] = child2[param_name], child1[param_name]
        
        return child1, child2
    
    def optimize(self, objective_function: Callable) -> List[Trial]:
        """
        æ‰§è¡Œé—ä¼ ç®—æ³•ä¼˜åŒ–
        
        Args:
            objective_function: ç›®æ ‡å‡½æ•°
            
        Returns:
            è¯•éªŒç»“æœåˆ—è¡¨
        """
        try:
            # åˆå§‹åŒ–ç§ç¾¤
            population = [self._create_individual() for _ in range(self.population_size)]
            all_trials = []
            trial_id = 0
            
            generations = self.config.max_trials // self.population_size
            
            for generation in range(generations):
                # è¯„ä¼°ç§ç¾¤
                generation_trials = []
                for individual in population:
                    try:
                        score = objective_function(individual)
                        status = 'completed'
                    except Exception as e:
                        logger_manager.error(f"ä¸ªä½“è¯„ä¼°å¤±è´¥: {e}")
                        score = float('-inf')
                        status = 'failed'
                    
                    trial = Trial(
                        trial_id=trial_id,
                        parameters=individual,
                        score=score,
                        duration=0.0,
                        status=status,
                        metadata={'generation': generation}
                    )
                    
                    generation_trials.append(trial)
                    all_trials.append(trial)
                    trial_id += 1
                
                # é€‰æ‹©
                generation_trials.sort(key=lambda x: x.score, reverse=True)
                elite_size = self.population_size // 4
                elite = [trial.parameters for trial in generation_trials[:elite_size]]
                
                # ç”Ÿæˆæ–°ç§ç¾¤
                new_population = elite.copy()
                
                while len(new_population) < self.population_size:
                    # é”¦æ ‡èµ›é€‰æ‹©
                    tournament_size = 3
                    tournament = random.sample(generation_trials[:self.population_size//2], tournament_size)
                    parent1 = max(tournament, key=lambda x: x.score).parameters
                    
                    tournament = random.sample(generation_trials[:self.population_size//2], tournament_size)
                    parent2 = max(tournament, key=lambda x: x.score).parameters
                    
                    # äº¤å‰å’Œå˜å¼‚
                    child1, child2 = self._crossover(parent1, parent2)
                    child1 = self._mutate(child1)
                    child2 = self._mutate(child2)
                    
                    new_population.extend([child1, child2])
                
                population = new_population[:self.population_size]
                
                best_score = generation_trials[0].score
                logger_manager.debug(f"ç¬¬ {generation} ä»£ï¼Œæœ€ä½³åˆ†æ•°: {best_score:.4f}")
            
            # æŒ‰åˆ†æ•°æ’åº
            all_trials.sort(key=lambda x: x.score, reverse=True)
            
            logger_manager.info(f"é—ä¼ ç®—æ³•ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³åˆ†æ•°: {all_trials[0].score:.4f}")
            return all_trials
            
        except Exception as e:
            logger_manager.error(f"é—ä¼ ç®—æ³•ä¼˜åŒ–å¤±è´¥: {e}")
            return []


class HyperparameterOptimizer:
    """è¶…å‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self, parameters: List[HyperParameter], config: OptimizationConfig):
        """
        åˆå§‹åŒ–è¶…å‚æ•°ä¼˜åŒ–å™¨
        
        Args:
            parameters: è¶…å‚æ•°åˆ—è¡¨
            config: ä¼˜åŒ–é…ç½®
        """
        self.parameters = parameters
        self.config = config
        self.optimizer = self._create_optimizer()
        self.optimization_history = []
        
        logger_manager.info(f"è¶…å‚æ•°ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ–¹æ³•: {config.method.value}")
    
    def _create_optimizer(self):
        """åˆ›å»ºå…·ä½“çš„ä¼˜åŒ–å™¨"""
        if self.config.method == OptimizationMethod.GRID_SEARCH:
            return GridSearchOptimizer(self.parameters, self.config)
        elif self.config.method == OptimizationMethod.RANDOM_SEARCH:
            return RandomSearchOptimizer(self.parameters, self.config)
        elif self.config.method == OptimizationMethod.BAYESIAN:
            return BayesianOptimizer(self.parameters, self.config)
        elif self.config.method == OptimizationMethod.GENETIC:
            return GeneticOptimizer(self.parameters, self.config)
        else:
            logger_manager.warning(f"ä¸æ”¯æŒçš„ä¼˜åŒ–æ–¹æ³•: {self.config.method}")
            return RandomSearchOptimizer(self.parameters, self.config)
    
    def optimize(self, objective_function: Callable) -> List[Trial]:
        """
        æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–
        
        Args:
            objective_function: ç›®æ ‡å‡½æ•°
            
        Returns:
            è¯•éªŒç»“æœåˆ—è¡¨
        """
        try:
            start_time = time.time()
            
            trials = self.optimizer.optimize(objective_function)
            
            total_time = time.time() - start_time
            
            # è®°å½•ä¼˜åŒ–å†å²
            self.optimization_history.append({
                'method': self.config.method.value,
                'total_trials': len(trials),
                'best_score': trials[0].score if trials else 0.0,
                'total_time': total_time,
                'timestamp': time.time()
            })
            
            logger_manager.info(f"è¶…å‚æ•°ä¼˜åŒ–å®Œæˆï¼Œæ€»æ—¶é—´: {total_time:.2f}ç§’")
            return trials
            
        except Exception as e:
            logger_manager.error(f"è¶…å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
            return []
    
    def get_best_parameters(self, trials: List[Trial]) -> Dict[str, Any]:
        """è·å–æœ€ä½³å‚æ•°"""
        if not trials:
            return {}
        
        best_trial = max(trials, key=lambda x: x.score)
        return best_trial.parameters
    
    def save_results(self, trials: List[Trial], file_path: str):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        try:
            results = {
                'config': {
                    'method': self.config.method.value,
                    'max_trials': self.config.max_trials,
                    'scoring_metric': self.config.scoring_metric
                },
                'parameters': [
                    {
                        'name': p.name,
                        'type': p.param_type,
                        'min_value': p.min_value,
                        'max_value': p.max_value,
                        'choices': p.choices
                    } for p in self.parameters
                ],
                'trials': [
                    {
                        'trial_id': t.trial_id,
                        'parameters': t.parameters,
                        'score': t.score,
                        'duration': t.duration,
                        'status': t.status
                    } for t in trials
                ],
                'optimization_history': self.optimization_history
            }
            
            with open(file_path, 'w') as f:
                json.dump(results, f, indent=2)
            
            logger_manager.info(f"ä¼˜åŒ–ç»“æœå·²ä¿å­˜åˆ°: {file_path}")
            
        except Exception as e:
            logger_manager.error(f"ä¿å­˜ä¼˜åŒ–ç»“æœå¤±è´¥: {e}")
    
    def load_results(self, file_path: str) -> List[Trial]:
        """åŠ è½½ä¼˜åŒ–ç»“æœ"""
        try:
            with open(file_path, 'r') as f:
                results = json.load(f)
            
            trials = []
            for trial_data in results['trials']:
                trial = Trial(
                    trial_id=trial_data['trial_id'],
                    parameters=trial_data['parameters'],
                    score=trial_data['score'],
                    duration=trial_data['duration'],
                    status=trial_data['status']
                )
                trials.append(trial)
            
            logger_manager.info(f"ä¼˜åŒ–ç»“æœå·²ä» {file_path} åŠ è½½")
            return trials
            
        except Exception as e:
            logger_manager.error(f"åŠ è½½ä¼˜åŒ–ç»“æœå¤±è´¥: {e}")
            return []


# å…¨å±€è¶…å‚æ•°ä¼˜åŒ–å™¨å®ä¾‹
default_parameters = [
    HyperParameter('learning_rate', 'float', 0.0001, 0.1, log_scale=True),
    HyperParameter('batch_size', 'int', 16, 128),
    HyperParameter('epochs', 'int', 10, 100),
    HyperParameter('optimizer', 'categorical', choices=['adam', 'sgd', 'rmsprop'])
]

default_config = OptimizationConfig(
    method=OptimizationMethod.RANDOM_SEARCH,
    max_trials=50,
    scoring_metric='accuracy'
)

hyperparameter_optimizer = HyperparameterOptimizer(default_parameters, default_config)


if __name__ == "__main__":
    # æµ‹è¯•è¶…å‚æ•°ä¼˜åŒ–åŠŸèƒ½
    print("ğŸ¯ æµ‹è¯•è¶…å‚æ•°ä¼˜åŒ–åŠŸèƒ½...")
    
    # å®šä¹‰æµ‹è¯•ç›®æ ‡å‡½æ•°
    def test_objective(params):
        """æµ‹è¯•ç›®æ ‡å‡½æ•°"""
        # æ¨¡æ‹Ÿæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
        score = random.random()
        
        # æ·»åŠ ä¸€äº›é€»è¾‘ä½¿æŸäº›å‚æ•°ç»„åˆæ›´å¥½
        if params.get('learning_rate', 0.01) < 0.01:
            score += 0.1
        if params.get('batch_size', 32) == 32:
            score += 0.05
        
        return score
    
    # æµ‹è¯•ä¸åŒçš„ä¼˜åŒ–æ–¹æ³•
    methods = [OptimizationMethod.RANDOM_SEARCH, OptimizationMethod.GRID_SEARCH, OptimizationMethod.GENETIC]
    
    for method in methods:
        print(f"\næµ‹è¯• {method.value} ä¼˜åŒ–...")
        
        config = OptimizationConfig(method=method, max_trials=20)
        optimizer = HyperparameterOptimizer(default_parameters, config)
        
        trials = optimizer.optimize(test_objective)
        
        if trials:
            best_params = optimizer.get_best_parameters(trials)
            print(f"æœ€ä½³å‚æ•°: {best_params}")
            print(f"æœ€ä½³åˆ†æ•°: {trials[0].score:.4f}")
    
    print("è¶…å‚æ•°ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•å®Œæˆ")
