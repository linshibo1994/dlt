#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨æ¨¡å—
Distributed Computing Manager Module

æä¾›åˆ†å¸ƒå¼è®¡ç®—ã€èŠ‚ç‚¹ç®¡ç†ã€ä»»åŠ¡è°ƒåº¦ç­‰åŠŸèƒ½ã€‚
"""

import os
import time
import threading
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from enum import Enum
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed

from core_modules import logger_manager
from ..utils.exceptions import DeepLearningException


class ComputingStrategy(Enum):
    """è®¡ç®—ç­–ç•¥æšä¸¾"""
    SINGLE_THREAD = "single_thread"
    MULTI_THREAD = "multi_thread"
    MULTI_PROCESS = "multi_process"
    DISTRIBUTED = "distributed"


@dataclass
class ComputingNode:
    """è®¡ç®—èŠ‚ç‚¹"""
    node_id: str
    host: str
    port: int
    cpu_count: int
    memory_gb: float
    gpu_count: int = 0
    status: str = "idle"
    last_heartbeat: float = 0.0


@dataclass
class ComputingTask:
    """è®¡ç®—ä»»åŠ¡"""
    task_id: str
    function: Callable
    args: tuple = field(default_factory=tuple)
    kwargs: dict = field(default_factory=dict)
    priority: int = 0
    timeout: Optional[float] = None
    retry_count: int = 0
    max_retries: int = 3


class NodeManager:
    """èŠ‚ç‚¹ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–èŠ‚ç‚¹ç®¡ç†å™¨"""
        self.nodes: Dict[str, ComputingNode] = {}
        self._lock = threading.RLock()
        
        logger_manager.debug("èŠ‚ç‚¹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def register_node(self, node: ComputingNode) -> bool:
        """
        æ³¨å†Œè®¡ç®—èŠ‚ç‚¹
        
        Args:
            node: è®¡ç®—èŠ‚ç‚¹
            
        Returns:
            æ˜¯å¦æ³¨å†ŒæˆåŠŸ
        """
        try:
            with self._lock:
                self.nodes[node.node_id] = node
                node.last_heartbeat = time.time()
                
                logger_manager.info(f"è®¡ç®—èŠ‚ç‚¹æ³¨å†ŒæˆåŠŸ: {node.node_id} ({node.host}:{node.port})")
                return True
                
        except Exception as e:
            logger_manager.error(f"æ³¨å†Œè®¡ç®—èŠ‚ç‚¹å¤±è´¥: {e}")
            return False
    
    def unregister_node(self, node_id: str) -> bool:
        """
        æ³¨é”€è®¡ç®—èŠ‚ç‚¹
        
        Args:
            node_id: èŠ‚ç‚¹ID
            
        Returns:
            æ˜¯å¦æ³¨é”€æˆåŠŸ
        """
        try:
            with self._lock:
                if node_id in self.nodes:
                    del self.nodes[node_id]
                    logger_manager.info(f"è®¡ç®—èŠ‚ç‚¹æ³¨é”€æˆåŠŸ: {node_id}")
                    return True
                return False
                
        except Exception as e:
            logger_manager.error(f"æ³¨é”€è®¡ç®—èŠ‚ç‚¹å¤±è´¥: {e}")
            return False
    
    def update_heartbeat(self, node_id: str) -> bool:
        """
        æ›´æ–°èŠ‚ç‚¹å¿ƒè·³
        
        Args:
            node_id: èŠ‚ç‚¹ID
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            with self._lock:
                if node_id in self.nodes:
                    self.nodes[node_id].last_heartbeat = time.time()
                    return True
                return False
                
        except Exception as e:
            logger_manager.error(f"æ›´æ–°èŠ‚ç‚¹å¿ƒè·³å¤±è´¥: {e}")
            return False
    
    def get_available_nodes(self) -> List[ComputingNode]:
        """è·å–å¯ç”¨èŠ‚ç‚¹åˆ—è¡¨"""
        try:
            with self._lock:
                current_time = time.time()
                available_nodes = []
                
                for node in self.nodes.values():
                    # æ£€æŸ¥å¿ƒè·³è¶…æ—¶ï¼ˆ30ç§’ï¼‰
                    if current_time - node.last_heartbeat < 30:
                        if node.status in ["idle", "running"]:
                            available_nodes.append(node)
                
                return available_nodes
                
        except Exception as e:
            logger_manager.error(f"è·å–å¯ç”¨èŠ‚ç‚¹å¤±è´¥: {e}")
            return []
    
    def get_node_statistics(self) -> Dict[str, Any]:
        """è·å–èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with self._lock:
                total_nodes = len(self.nodes)
                available_nodes = len(self.get_available_nodes())
                
                total_cpu = sum(node.cpu_count for node in self.nodes.values())
                total_memory = sum(node.memory_gb for node in self.nodes.values())
                total_gpu = sum(node.gpu_count for node in self.nodes.values())
                
                return {
                    "total_nodes": total_nodes,
                    "available_nodes": available_nodes,
                    "total_cpu_cores": total_cpu,
                    "total_memory_gb": total_memory,
                    "total_gpu_count": total_gpu
                }
                
        except Exception as e:
            logger_manager.error(f"è·å–èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}


class DistributedComputingManager:
    """åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨"""
    
    def __init__(self, max_workers: int = None):
        """
        åˆå§‹åŒ–åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨
        
        Args:
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        """
        self.max_workers = max_workers or mp.cpu_count()
        self.node_manager = NodeManager()
        self.task_queue: List[ComputingTask] = []
        self.running_tasks: Dict[str, ComputingTask] = {}
        self._lock = threading.RLock()
        
        # æ‰§è¡Œå™¨
        self.thread_executor = None
        self.process_executor = None
        
        # æ³¨å†Œæœ¬åœ°èŠ‚ç‚¹
        self._register_local_node()
        
        logger_manager.info("åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _register_local_node(self):
        """æ³¨å†Œæœ¬åœ°èŠ‚ç‚¹"""
        try:
            import psutil
            
            local_node = ComputingNode(
                node_id="local",
                host="localhost",
                port=0,
                cpu_count=mp.cpu_count(),
                memory_gb=psutil.virtual_memory().total / (1024**3),
                gpu_count=self._get_gpu_count()
            )
            
            self.node_manager.register_node(local_node)
            
        except Exception as e:
            logger_manager.error(f"æ³¨å†Œæœ¬åœ°èŠ‚ç‚¹å¤±è´¥: {e}")
    
    def _get_gpu_count(self) -> int:
        """è·å–GPUæ•°é‡"""
        try:
            import torch
            if torch.cuda.is_available():
                return torch.cuda.device_count()
        except ImportError:
            pass
        
        return 0
    
    def submit_task(self, task: ComputingTask) -> str:
        """
        æäº¤è®¡ç®—ä»»åŠ¡
        
        Args:
            task: è®¡ç®—ä»»åŠ¡
            
        Returns:
            ä»»åŠ¡ID
        """
        try:
            with self._lock:
                self.task_queue.append(task)
                # æŒ‰ä¼˜å…ˆçº§æ’åº
                self.task_queue.sort(key=lambda t: t.priority, reverse=True)
                
                logger_manager.debug(f"è®¡ç®—ä»»åŠ¡æäº¤æˆåŠŸ: {task.task_id}")
                return task.task_id
                
        except Exception as e:
            logger_manager.error(f"æäº¤è®¡ç®—ä»»åŠ¡å¤±è´¥: {e}")
            raise DeepLearningException(f"æäº¤è®¡ç®—ä»»åŠ¡å¤±è´¥: {e}")
    
    def execute_parallel(self, function: Callable, args_list: List[tuple], 
                         strategy: ComputingStrategy = ComputingStrategy.MULTI_THREAD) -> List[Any]:
        """
        å¹¶è¡Œæ‰§è¡Œå‡½æ•°
        
        Args:
            function: è¦æ‰§è¡Œçš„å‡½æ•°
            args_list: å‚æ•°åˆ—è¡¨
            strategy: è®¡ç®—ç­–ç•¥
            
        Returns:
            æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        try:
            if strategy == ComputingStrategy.SINGLE_THREAD:
                return self._execute_single_thread(function, args_list)
            elif strategy == ComputingStrategy.MULTI_THREAD:
                return self._execute_multi_thread(function, args_list)
            elif strategy == ComputingStrategy.MULTI_PROCESS:
                return self._execute_multi_process(function, args_list)
            elif strategy == ComputingStrategy.DISTRIBUTED:
                return self._execute_distributed(function, args_list)
            else:
                raise DeepLearningException(f"ä¸æ”¯æŒçš„è®¡ç®—ç­–ç•¥: {strategy}")
                
        except Exception as e:
            logger_manager.error(f"å¹¶è¡Œæ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    def _execute_single_thread(self, function: Callable, args_list: List[tuple]) -> List[Any]:
        """å•çº¿ç¨‹æ‰§è¡Œ"""
        results = []
        
        for args in args_list:
            try:
                result = function(*args)
                results.append(result)
            except Exception as e:
                logger_manager.error(f"å•çº¿ç¨‹æ‰§è¡Œå¤±è´¥: {e}")
                results.append(None)
        
        return results
    
    def _execute_multi_thread(self, function: Callable, args_list: List[tuple]) -> List[Any]:
        """å¤šçº¿ç¨‹æ‰§è¡Œ"""
        results = [None] * len(args_list)
        
        if not self.thread_executor:
            self.thread_executor = ThreadPoolExecutor(max_workers=self.max_workers)
        
        try:
            # æäº¤ä»»åŠ¡
            future_to_index = {}
            for i, args in enumerate(args_list):
                future = self.thread_executor.submit(function, *args)
                future_to_index[future] = i
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    results[index] = future.result()
                except Exception as e:
                    logger_manager.error(f"å¤šçº¿ç¨‹ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                    results[index] = None
            
            return results
            
        except Exception as e:
            logger_manager.error(f"å¤šçº¿ç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            return results
    
    def _execute_multi_process(self, function: Callable, args_list: List[tuple]) -> List[Any]:
        """å¤šè¿›ç¨‹æ‰§è¡Œ"""
        results = [None] * len(args_list)
        
        if not self.process_executor:
            self.process_executor = ProcessPoolExecutor(max_workers=self.max_workers)
        
        try:
            # æäº¤ä»»åŠ¡
            future_to_index = {}
            for i, args in enumerate(args_list):
                future = self.process_executor.submit(function, *args)
                future_to_index[future] = i
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    results[index] = future.result()
                except Exception as e:
                    logger_manager.error(f"å¤šè¿›ç¨‹ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                    results[index] = None
            
            return results
            
        except Exception as e:
            logger_manager.error(f"å¤šè¿›ç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            return results
    
    def _execute_distributed(self, function: Callable, args_list: List[tuple]) -> List[Any]:
        """åˆ†å¸ƒå¼æ‰§è¡Œ"""
        # ç®€åŒ–çš„åˆ†å¸ƒå¼æ‰§è¡Œï¼Œå®é™…åº”è¯¥ä½¿ç”¨å¦‚Rayã€Daskç­‰æ¡†æ¶
        logger_manager.warning("åˆ†å¸ƒå¼æ‰§è¡Œæš‚æœªå®Œå…¨å®ç°ï¼Œå›é€€åˆ°å¤šè¿›ç¨‹æ‰§è¡Œ")
        return self._execute_multi_process(function, args_list)
    
    def map_reduce(self, map_function: Callable, reduce_function: Callable, 
                   data_list: List[Any], strategy: ComputingStrategy = ComputingStrategy.MULTI_THREAD) -> Any:
        """
        MapReduceæ“ä½œ
        
        Args:
            map_function: Mapå‡½æ•°
            reduce_function: Reduceå‡½æ•°
            data_list: æ•°æ®åˆ—è¡¨
            strategy: è®¡ç®—ç­–ç•¥
            
        Returns:
            æœ€ç»ˆç»“æœ
        """
        try:
            # Mapé˜¶æ®µ
            args_list = [(item,) for item in data_list]
            map_results = self.execute_parallel(map_function, args_list, strategy)
            
            # è¿‡æ»¤Noneç»“æœ
            valid_results = [result for result in map_results if result is not None]
            
            # Reduceé˜¶æ®µ
            if not valid_results:
                return None
            
            result = valid_results[0]
            for item in valid_results[1:]:
                result = reduce_function(result, item)
            
            return result
            
        except Exception as e:
            logger_manager.error(f"MapReduceæ“ä½œå¤±è´¥: {e}")
            raise
    
    def get_computing_statistics(self) -> Dict[str, Any]:
        """è·å–è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with self._lock:
                node_stats = self.node_manager.get_node_statistics()
                
                stats = {
                    "max_workers": self.max_workers,
                    "queued_tasks": len(self.task_queue),
                    "running_tasks": len(self.running_tasks),
                    "thread_executor_active": self.thread_executor is not None,
                    "process_executor_active": self.process_executor is not None
                }
                
                stats.update(node_stats)
                return stats
                
        except Exception as e:
            logger_manager.error(f"è·å–è®¡ç®—ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def shutdown(self):
        """å…³é—­è®¡ç®—ç®¡ç†å™¨"""
        try:
            if self.thread_executor:
                self.thread_executor.shutdown(wait=True)
                self.thread_executor = None
            
            if self.process_executor:
                self.process_executor.shutdown(wait=True)
                self.process_executor = None
            
            logger_manager.info("åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨å·²å…³é—­")
            
        except Exception as e:
            logger_manager.error(f"å…³é—­è®¡ç®—ç®¡ç†å™¨å¤±è´¥: {e}")


# å…¨å±€åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨å®ä¾‹
distributed_computing_manager = DistributedComputingManager()


if __name__ == "__main__":
    # æµ‹è¯•åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨åŠŸèƒ½
    print("ğŸ–¥ï¸ æµ‹è¯•åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨åŠŸèƒ½...")
    
    try:
        manager = DistributedComputingManager()
        
        # æµ‹è¯•å‡½æ•°
        def square(x):
            return x * x
        
        def add(a, b):
            return a + b
        
        # æµ‹è¯•å¹¶è¡Œæ‰§è¡Œ
        args_list = [(i,) for i in range(10)]
        
        # å¤šçº¿ç¨‹æ‰§è¡Œ
        results_thread = manager.execute_parallel(square, args_list, ComputingStrategy.MULTI_THREAD)
        print(f"âœ… å¤šçº¿ç¨‹æ‰§è¡Œ: {len(results_thread)} ä¸ªç»“æœ")
        
        # å¤šè¿›ç¨‹æ‰§è¡Œ
        results_process = manager.execute_parallel(square, args_list, ComputingStrategy.MULTI_PROCESS)
        print(f"âœ… å¤šè¿›ç¨‹æ‰§è¡Œ: {len(results_process)} ä¸ªç»“æœ")
        
        # MapReduceæµ‹è¯•
        data_list = list(range(1, 11))
        sum_result = manager.map_reduce(square, add, data_list)
        print(f"âœ… MapReduceç»“æœ: {sum_result}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = manager.get_computing_statistics()
        print(f"âœ… è®¡ç®—ç»Ÿè®¡: {stats}")
        
        # å…³é—­ç®¡ç†å™¨
        manager.shutdown()
        
        print("âœ… åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨åŠŸèƒ½æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("åˆ†å¸ƒå¼è®¡ç®—ç®¡ç†å™¨åŠŸèƒ½æµ‹è¯•å®Œæˆ")
