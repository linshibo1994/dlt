#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤§ä¹é€æ•°æ®åˆ†æä¸é¢„æµ‹ç³»ç»Ÿ
æ•´åˆäº†æ•°æ®çˆ¬å–ã€é©¬å°”å¯å¤«é“¾åˆ†æã€é¢„æµ‹ç­‰æ‰€æœ‰åŠŸèƒ½
"""

import argparse
import csv
import json
import os
import random
from collections import defaultdict
from datetime import datetime

# å¯è§†åŒ–åº“
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pandas as pd
import requests
import seaborn as sns
from bs4 import BeautifulSoup

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class DLTCrawler:
    """å¤§ä¹é€æ•°æ®çˆ¬è™« - ä»500å½©ç¥¨ç½‘è·å–æ•°æ®"""
    
    def __init__(self, data_dir="data"):
        self.data_dir = data_dir
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
        
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                         "(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2",
            "Accept-Encoding": "gzip, deflate",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
        }
        
        self.api_url = "https://datachart.500.com/dlt/history/newinc/history.php"
    
    def get_history_data(self, count=50, get_all=False):
        """è·å–å†å²æ•°æ®"""
        results = []
        
        try:
            if get_all:
                print("å¼€å§‹ä»500å½©ç¥¨ç½‘è·å–æ‰€æœ‰å†å²å¤§ä¹é€æ•°æ®...")
                results = self._fetch_all_data()
                print(f"å…¨é‡è·å–å®Œæˆï¼Œå…±è·å– {len(results)} æœŸå¤§ä¹é€å¼€å¥–æ•°æ®")
            else:
                print(f"å¼€å§‹ä»500å½©ç¥¨ç½‘è·å–æœ€è¿‘{count}æœŸå¤§ä¹é€æ•°æ®...")
                results = self._fetch_limited_data(count)
                print(f"æˆåŠŸè·å– {len(results)} æœŸå¤§ä¹é€å¼€å¥–æ•°æ®")
            
        except Exception as e:
            print(f"è·å–æ•°æ®å¤±è´¥: {e}")
        
        return results
    
    def _fetch_all_data(self):
        """è·å–æ‰€æœ‰å†å²æ•°æ®"""
        results = []
        
        try:
            params = {'limit': 2000, 'sort': 0}
            response = requests.get(self.api_url, headers=self.headers, params=params, timeout=60)
            response.encoding = 'gb2312'
            
            if response.status_code != 200:
                print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return results
            
            soup = BeautifulSoup(response.text, 'html.parser')
            table = soup.find('div', {'class': 'chart'})
            if not table:
                print("æœªæ‰¾åˆ°å¼€å¥–æ•°æ®è¡¨æ ¼")
                return results
            
            rows = table.find_all('tr')
            print(f"æ‰¾åˆ° {len(rows)} è¡Œæ•°æ®ï¼Œå¼€å§‹è§£æ...")
            
            for i, row in enumerate(rows):
                try:
                    cells = row.find_all('td')
                    if len(cells) != 15:
                        continue
                    
                    issue = cells[0].get_text().strip()
                    date = cells[14].get_text().strip()
                    
                    front_balls = []
                    for j in range(1, 6):
                        ball = cells[j].get_text().strip()
                        if ball.isdigit():
                            front_balls.append(ball.zfill(2))
                    
                    back_balls = []
                    for j in range(6, 8):
                        ball = cells[j].get_text().strip()
                        if ball.isdigit():
                            back_balls.append(ball.zfill(2))
                    
                    if len(front_balls) == 5 and len(back_balls) == 2 and issue.isdigit():
                        result = {
                            "issue": issue,
                            "date": date,
                            "front_balls": ",".join(front_balls),
                            "back_balls": ",".join(back_balls)
                        }
                        results.append(result)
                        
                        if len(results) % 100 == 0:
                            print(f"å·²è§£æ {len(results)} æœŸæ•°æ®...")
                    
                except Exception as e:
                    print(f"è§£æç¬¬{i+1}è¡Œæ•°æ®å¤±è´¥: {e}")
                    continue
            
        except Exception as e:
            print(f"è·å–å…¨é‡æ•°æ®å¤±è´¥: {e}")
        
        return results
    
    def _fetch_limited_data(self, count):
        """è·å–æŒ‡å®šæ•°é‡çš„æ•°æ®"""
        results = []
        
        try:
            params = {'limit': count, 'sort': 0}
            response = requests.get(self.api_url, headers=self.headers, params=params, timeout=30)
            response.encoding = 'gb2312'
            
            if response.status_code != 200:
                print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return results
            
            soup = BeautifulSoup(response.text, 'html.parser')
            table = soup.find('div', {'class': 'chart'})
            if not table:
                print("æœªæ‰¾åˆ°å¼€å¥–æ•°æ®è¡¨æ ¼")
                return results
            
            rows = table.find_all('tr')
            
            for i, row in enumerate(rows):
                if len(results) >= count:
                    break
                    
                try:
                    cells = row.find_all('td')
                    if len(cells) != 15:
                        continue
                    
                    issue = cells[0].get_text().strip()
                    date = cells[14].get_text().strip()
                    
                    front_balls = []
                    for j in range(1, 6):
                        ball = cells[j].get_text().strip()
                        if ball.isdigit():
                            front_balls.append(ball.zfill(2))
                    
                    back_balls = []
                    for j in range(6, 8):
                        ball = cells[j].get_text().strip()
                        if ball.isdigit():
                            back_balls.append(ball.zfill(2))
                    
                    if len(front_balls) == 5 and len(back_balls) == 2 and issue.isdigit():
                        result = {
                            "issue": issue,
                            "date": date,
                            "front_balls": ",".join(front_balls),
                            "back_balls": ",".join(back_balls)
                        }
                        results.append(result)
                        print(f"è·å–ç¬¬{issue}æœŸæ•°æ®: å‰åŒº {','.join(front_balls)}, ååŒº {','.join(back_balls)}")
                    
                except Exception as e:
                    print(f"è§£æç¬¬{i+1}è¡Œæ•°æ®å¤±è´¥: {e}")
                    continue
            
        except Exception as e:
            print(f"è·å–é™é‡æ•°æ®å¤±è´¥: {e}")
        
        return results
    
    def save_to_csv(self, results, filename="dlt_data.csv"):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        if not results:
            print("æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return None
        
        try:
            if os.path.dirname(filename):
                file_path = filename
            else:
                file_path = os.path.join(self.data_dir, filename)
            
            with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['issue', 'date', 'front_balls', 'back_balls']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for result in results:
                    writer.writerow(result)
            
            print(f"æ•°æ®å·²ä¿å­˜åˆ°: {file_path}")
            print(f"å…±ä¿å­˜ {len(results)} æ¡è®°å½•")
            
            return file_path
            
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return None


class DLTAnalyzer:
    """å¤§ä¹é€åˆ†æå™¨ - æ•´åˆäº†æ‰€æœ‰åˆ†æåŠŸèƒ½"""
    
    def __init__(self, data_file):
        self.data_file = data_file
        self.df = None
        self.analysis_data = None
        self.load_data()
    
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        try:
            self.df = pd.read_csv(self.data_file)
            self.df = self.df.sort_values('issue', ascending=False)
            print(f"æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(self.df)} æ¡è®°å½•")
            print(f"æ•°æ®èŒƒå›´: {self.df.iloc[-1]['issue']} - {self.df.iloc[0]['issue']}")
            return True
        except Exception as e:
            print(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return False
    
    def parse_balls(self, balls_str):
        """è§£æå·ç å­—ç¬¦ä¸²"""
        return [int(ball.strip()) for ball in str(balls_str).split(",")]
    
    def check_duplicates(self, quiet=False):
        """æ£€æŸ¥é‡å¤æ•°æ®"""
        if not quiet:
            print("æ£€æŸ¥æ•°æ®é‡å¤...")
        
        duplicates = self.df[self.df.duplicated(subset=['issue'], keep=False)]
        
        if len(duplicates) > 0:
            print(f"å‘ç° {len(duplicates)} æ¡é‡å¤è®°å½•:")
            for _, row in duplicates.iterrows():
                print(f"  æœŸå·: {row['issue']}, æ—¥æœŸ: {row['date']}")
            return True
        else:
            if not quiet:
                print("æœªå‘ç°é‡å¤æ•°æ®")
            return False
    
    def remove_duplicates(self):
        """å»é™¤é‡å¤æ•°æ®"""
        original_count = len(self.df)
        self.df = self.df.drop_duplicates(subset=['issue'], keep='first')
        removed_count = original_count - len(self.df)
        
        if removed_count > 0:
            print(f"å·²å»é™¤ {removed_count} æ¡é‡å¤è®°å½•")
            # ä¿å­˜å»é‡åçš„æ•°æ®
            self.df.to_csv(self.data_file, index=False)
            print(f"å»é‡åçš„æ•°æ®å·²ä¿å­˜åˆ°: {self.data_file}")
        else:
            print("æ²¡æœ‰é‡å¤æ•°æ®éœ€è¦å»é™¤")
        
        return removed_count

    def analyze_periods(self, num_periods=300, verbose=True):
        """åˆ†ææŒ‡å®šæœŸæ•°çš„æ•°æ®"""
        if num_periods > len(self.df):
            print(f"è­¦å‘Š: è¯·æ±‚åˆ†æ {num_periods} æœŸï¼Œä½†åªæœ‰ {len(self.df)} æœŸæ•°æ®ï¼Œå°†ä½¿ç”¨å…¨éƒ¨æ•°æ®")
            num_periods = len(self.df)

        analysis_df = self.df.head(num_periods)

        if verbose:
            print(f"\nå¼€å§‹åˆ†ææœ€æ–° {num_periods} æœŸæ•°æ®...")
            print(f"åˆ†æèŒƒå›´: {analysis_df.iloc[-1]['issue']} - {analysis_df.iloc[0]['issue']}")

        # æ„å»ºè½¬ç§»çŸ©é˜µ
        front_transitions = defaultdict(lambda: defaultdict(int))
        back_transitions = defaultdict(lambda: defaultdict(int))

        # ç»Ÿè®¡å·ç å‡ºç°é¢‘ç‡
        front_frequency = defaultdict(int)
        back_frequency = defaultdict(int)

        # è§£ææ•°æ®å¹¶æ„å»ºè½¬ç§»å…³ç³»
        for i in range(len(analysis_df) - 1):
            current_row = analysis_df.iloc[i]
            next_row = analysis_df.iloc[i + 1]

            current_front = self.parse_balls(current_row['front_balls'])
            current_back = self.parse_balls(current_row['back_balls'])
            next_front = self.parse_balls(next_row['front_balls'])
            next_back = self.parse_balls(next_row['back_balls'])

            # ç»Ÿè®¡é¢‘ç‡
            for ball in current_front:
                front_frequency[ball] += 1
            for ball in current_back:
                back_frequency[ball] += 1

            # æ„å»ºè½¬ç§»å…³ç³»
            for curr_ball in current_front:
                for next_ball in next_front:
                    front_transitions[curr_ball][next_ball] += 1

            for curr_ball in current_back:
                for next_ball in next_back:
                    back_transitions[curr_ball][next_ball] += 1

        # è®¡ç®—è½¬ç§»æ¦‚ç‡
        front_probabilities = self._calculate_probabilities(front_transitions)
        back_probabilities = self._calculate_probabilities(back_transitions)

        # è®¡ç®—ç¨³å®šæ€§å¾—åˆ†
        front_stability = self._calculate_stability_scores(front_probabilities, front_frequency)
        back_stability = self._calculate_stability_scores(back_probabilities, back_frequency)

        self.analysis_data = {
            'num_periods': num_periods,
            'data_range': {
                'start': analysis_df.iloc[-1]['issue'],
                'end': analysis_df.iloc[0]['issue']
            },
            'latest_draw': {
                'issue': analysis_df.iloc[0]['issue'],
                'date': analysis_df.iloc[0]['date'],
                'front_balls': self.parse_balls(analysis_df.iloc[0]['front_balls']),
                'back_balls': self.parse_balls(analysis_df.iloc[0]['back_balls'])
            },
            'front_transitions': front_transitions,
            'back_transitions': back_transitions,
            'front_probabilities': front_probabilities,
            'back_probabilities': back_probabilities,
            'front_frequency': front_frequency,
            'back_frequency': back_frequency,
            'front_stability': front_stability,
            'back_stability': back_stability
        }

        if verbose:
            self._print_analysis_summary()

        # ä¿å­˜é©¬å°”å¯å¤«é“¾åˆ†æç»“æœ
        self._save_markov_analysis(self.analysis_data)

        return self.analysis_data

    def _calculate_probabilities(self, transitions):
        """è®¡ç®—è½¬ç§»æ¦‚ç‡"""
        probabilities = {}
        for from_ball in transitions:
            total = sum(transitions[from_ball].values())
            if total > 0:
                probabilities[from_ball] = {}
                for to_ball, count in transitions[from_ball].items():
                    probabilities[from_ball][to_ball] = count / total
        return probabilities

    def _calculate_stability_scores(self, probabilities, frequency):
        """è®¡ç®—ç¨³å®šæ€§å¾—åˆ†"""
        stability = {}
        max_ball = 35 if len(frequency) > 12 else 12

        for ball in range(1, max_ball + 1):
            freq_score = frequency.get(ball, 0) / max(frequency.values()) if frequency else 0

            if ball in probabilities:
                probs = list(probabilities[ball].values())
                variance = np.var(probs) if probs else 1.0
                prob_stability = 1.0 / (variance + 0.001)
            else:
                prob_stability = 0.1

            stability[ball] = freq_score * 0.6 + prob_stability * 0.4

        return stability

    def _print_analysis_summary(self):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        data = self.analysis_data
        print(f"\nåˆ†ææ‘˜è¦:")
        print(f"åˆ†ææœŸæ•°: {data['num_periods']} æœŸ")
        print(f"æ•°æ®èŒƒå›´: {data['data_range']['start']} - {data['data_range']['end']}")
        print(f"æœ€æ–°ä¸€æœŸ: {data['latest_draw']['issue']} ({data['latest_draw']['date']})")

        latest_front = data['latest_draw']['front_balls']
        latest_back = data['latest_draw']['back_balls']
        print(f"æœ€æ–°å·ç : å‰åŒº {' '.join([str(b).zfill(2) for b in latest_front])}, ååŒº {' '.join([str(b).zfill(2) for b in latest_back])}")

        sorted_front = sorted(data['front_stability'].items(), key=lambda x: x[1], reverse=True)
        sorted_back = sorted(data['back_stability'].items(), key=lambda x: x[1], reverse=True)

        print(f"\nå‰åŒºæœ€ç¨³å®šå·ç  (å‰5): {', '.join([f'{ball:02d}' for ball, _ in sorted_front[:5]])}")
        print(f"ååŒºæœ€ç¨³å®šå·ç  (å‰3): {', '.join([f'{ball:02d}' for ball, _ in sorted_back[:3]])}")

    def predict_numbers(self, num_predictions=1, explain=False):
        """é¢„æµ‹å·ç """
        if not self.analysis_data:
            print("è¯·å…ˆè¿è¡Œ analyze_periods() è¿›è¡Œåˆ†æ")
            return []

        print(f"\nåŸºäº {self.analysis_data['num_periods']} æœŸæ•°æ®ç”Ÿæˆ {num_predictions} æ³¨é¢„æµ‹...")

        predictions = []
        used_combinations = set()

        for i in range(num_predictions):
            if explain and i == 0:
                print(f"\nç¬¬ {i+1} æ³¨é¢„æµ‹è¿‡ç¨‹:")
                print("-" * 40)

            front_balls, back_balls = self._generate_single_prediction(i, explain and i == 0)

            combination = (tuple(sorted(front_balls)), tuple(sorted(back_balls)))
            attempts = 0
            while combination in used_combinations and attempts < 50:
                front_balls, back_balls = self._generate_single_prediction(i + attempts, False)
                combination = (tuple(sorted(front_balls)), tuple(sorted(back_balls)))
                attempts += 1

            used_combinations.add(combination)

            stability_score = self._calculate_prediction_stability(front_balls, back_balls)

            predictions.append({
                'front': sorted(front_balls),
                'back': sorted(back_balls),
                'stability_score': stability_score
            })

        predictions.sort(key=lambda x: x['stability_score'], reverse=True)

        print(f"\né¢„æµ‹ç»“æœ (æŒ‰ç¨³å®šæ€§æ’åº):")
        print("=" * 60)

        for i, pred in enumerate(predictions, 1):
            front_str = ' '.join([str(b).zfill(2) for b in pred['front']])
            back_str = ' '.join([str(b).zfill(2) for b in pred['back']])
            print(f"ç¬¬ {i} æ³¨: å‰åŒº {front_str} | ååŒº {back_str} (ç¨³å®šæ€§: {pred['stability_score']:.4f})")

        print(f"\nğŸ¯ æœ€ç¨³å®šé¢„æµ‹: å‰åŒº {' '.join([str(b).zfill(2) for b in predictions[0]['front']])} | ååŒº {' '.join([str(b).zfill(2) for b in predictions[0]['back']])}")

        return predictions

    def _generate_single_prediction(self, variation_level, explain=False):
        """ç”Ÿæˆå•æ³¨é¢„æµ‹"""
        data = self.analysis_data
        latest_front = data['latest_draw']['front_balls']
        latest_back = data['latest_draw']['back_balls']

        if explain:
            print(f"åŸºäºæœ€æ–°ä¸€æœŸå·ç : å‰åŒº {' '.join([str(b).zfill(2) for b in latest_front])}, ååŒº {' '.join([str(b).zfill(2) for b in latest_back])}")

        # é¢„æµ‹å‰åŒºå·ç 
        front_candidates = defaultdict(float)

        for current_ball in latest_front:
            if current_ball in data['front_probabilities']:
                for next_ball, prob in data['front_probabilities'][current_ball].items():
                    front_candidates[next_ball] += prob * 0.7

        for ball, stability in data['front_stability'].items():
            front_candidates[ball] += stability * 0.3

        sorted_front = sorted(front_candidates.items(), key=lambda x: x[1], reverse=True)

        if explain:
            print("\nå‰åŒºå€™é€‰å·ç  (å‰10):")
            for i, (ball, score) in enumerate(sorted_front[:10], 1):
                print(f"  {i:2d}. {ball:02d}å· (å¾—åˆ†: {score:.4f})")

        if variation_level == 0:
            selected_front = [ball for ball, _ in sorted_front[:5]]
        else:
            high_score = [ball for ball, _ in sorted_front[:8]]
            random.shuffle(high_score)
            selected_front = high_score[:5]

        # é¢„æµ‹ååŒºå·ç 
        back_candidates = defaultdict(float)

        for current_ball in latest_back:
            if current_ball in data['back_probabilities']:
                for next_ball, prob in data['back_probabilities'][current_ball].items():
                    back_candidates[next_ball] += prob * 0.7

        for ball, stability in data['back_stability'].items():
            back_candidates[ball] += stability * 0.3

        sorted_back = sorted(back_candidates.items(), key=lambda x: x[1], reverse=True)

        if explain:
            print("\nååŒºå€™é€‰å·ç :")
            for i, (ball, score) in enumerate(sorted_back, 1):
                print(f"  {i:2d}. {ball:02d}å· (å¾—åˆ†: {score:.4f})")

        if variation_level == 0:
            selected_back = [ball for ball, _ in sorted_back[:2]]
        else:
            high_score_back = [ball for ball, _ in sorted_back[:4]]
            random.shuffle(high_score_back)
            selected_back = high_score_back[:2]

        return selected_front, selected_back

    def _calculate_prediction_stability(self, front_balls, back_balls):
        """è®¡ç®—é¢„æµ‹çš„ç¨³å®šæ€§å¾—åˆ†"""
        data = self.analysis_data

        front_score = sum(data['front_stability'].get(ball, 0) for ball in front_balls) / len(front_balls)
        back_score = sum(data['back_stability'].get(ball, 0) for ball in back_balls) / len(back_balls)

        return (front_score + back_score) / 2

    def basic_analysis(self, save_results=True):
        """åŸºç¡€ç»Ÿè®¡åˆ†æ"""
        print("\nå¼€å§‹åŸºç¡€ç»Ÿè®¡åˆ†æ...")

        # å·ç é¢‘ç‡åˆ†æ
        front_frequency = defaultdict(int)
        back_frequency = defaultdict(int)

        for _, row in self.df.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            for ball in front_balls:
                front_frequency[ball] += 1
            for ball in back_balls:
                back_frequency[ball] += 1

        # è®¡ç®—é—æ¼å€¼
        front_missing = self._calculate_missing_values('front')
        back_missing = self._calculate_missing_values('back')

        # çƒ­é—¨å·åˆ†æ
        front_hot = sorted(front_frequency.items(), key=lambda x: x[1], reverse=True)[:10]
        back_hot = sorted(back_frequency.items(), key=lambda x: x[1], reverse=True)[:5]

        # å†·é—¨å·åˆ†æ
        front_cold = sorted(front_frequency.items(), key=lambda x: x[1])[:10]
        back_cold = sorted(back_frequency.items(), key=lambda x: x[1])[:5]

        results = {
            'total_periods': len(self.df),
            'front_frequency': dict(front_frequency),
            'back_frequency': dict(back_frequency),
            'front_missing': front_missing,
            'back_missing': back_missing,
            'front_hot_numbers': front_hot,
            'back_hot_numbers': back_hot,
            'front_cold_numbers': front_cold,
            'back_cold_numbers': back_cold
        }

        # æ‰“å°ç»“æœ
        print(f"\nåŸºç¡€åˆ†æç»“æœ (å…±{len(self.df)}æœŸæ•°æ®):")
        print("=" * 50)

        print("\nå‰åŒºçƒ­é—¨å·ç  (å‰10):")
        for i, (ball, count) in enumerate(front_hot, 1):
            freq = count / len(self.df) * 100
            print(f"  {i:2d}. {ball:02d}å·: å‡ºç°{count:3d}æ¬¡ (é¢‘ç‡{freq:.1f}%)")

        print("\nååŒºçƒ­é—¨å·ç :")
        for i, (ball, count) in enumerate(back_hot, 1):
            freq = count / len(self.df) * 100
            print(f"  {i:2d}. {ball:02d}å·: å‡ºç°{count:3d}æ¬¡ (é¢‘ç‡{freq:.1f}%)")

        print(f"\nå‰åŒºé—æ¼å€¼æœ€å¤§çš„å·ç : {max(front_missing.items(), key=lambda x: x[1])}")
        print(f"ååŒºé—æ¼å€¼æœ€å¤§çš„å·ç : {max(back_missing.items(), key=lambda x: x[1])}")

        if save_results:
            self._save_basic_results(results)

        return results

    def _calculate_missing_values(self, ball_type):
        """è®¡ç®—é—æ¼å€¼"""
        missing = {}
        max_ball = 35 if ball_type == 'front' else 12

        for ball in range(1, max_ball + 1):
            missing[ball] = 0

            for i, (_, row) in enumerate(self.df.iterrows()):
                balls = self.parse_balls(row[f'{ball_type}_balls'])
                if ball in balls:
                    missing[ball] = 0
                else:
                    missing[ball] += 1

                if i == 0:  # åªè®¡ç®—åˆ°æœ€æ–°ä¸€æœŸ
                    break

        return missing

    def _save_basic_results(self, results):
        """ä¿å­˜åŸºç¡€åˆ†æç»“æœ"""
        output_dir = "output/basic"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # ä¿å­˜JSONç»“æœ
        with open(f"{output_dir}/basic_analysis.json", 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"åŸºç¡€åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}/basic_analysis.json")

    def bayesian_analysis(self, save_results=True):
        """è´å¶æ–¯åˆ†æ"""
        print("\nå¼€å§‹è´å¶æ–¯åˆ†æ...")

        # è®¡ç®—å…ˆéªŒæ¦‚ç‡
        front_prior = self._calculate_prior_probability('front')
        back_prior = self._calculate_prior_probability('back')

        # è®¡ç®—æ¡ä»¶æ¦‚ç‡
        front_conditional = self._calculate_conditional_probability('front')
        back_conditional = self._calculate_conditional_probability('back')

        # è®¡ç®—åéªŒæ¦‚ç‡
        front_posterior = self._calculate_posterior_probability(front_prior, front_conditional)
        back_posterior = self._calculate_posterior_probability(back_prior, back_conditional)

        results = {
            'front_prior': front_prior,
            'back_prior': back_prior,
            'front_conditional': front_conditional,
            'back_conditional': back_conditional,
            'front_posterior': front_posterior,
            'back_posterior': back_posterior
        }

        # æ‰“å°ç»“æœ
        print("\nè´å¶æ–¯åˆ†æç»“æœ:")
        print("=" * 50)

        # æ˜¾ç¤ºå‰åŒºæœ€é«˜æ¦‚ç‡å·ç 
        sorted_front = sorted(front_posterior.items(), key=lambda x: x[1], reverse=True)
        print("\nå‰åŒºåéªŒæ¦‚ç‡æœ€é«˜çš„å·ç  (å‰10):")
        for i, (ball, prob) in enumerate(sorted_front[:10], 1):
            print(f"  {i:2d}. {ball:02d}å·: æ¦‚ç‡ {prob:.4f}")

        # æ˜¾ç¤ºååŒºæœ€é«˜æ¦‚ç‡å·ç 
        sorted_back = sorted(back_posterior.items(), key=lambda x: x[1], reverse=True)
        print("\nååŒºåéªŒæ¦‚ç‡æœ€é«˜çš„å·ç :")
        for i, (ball, prob) in enumerate(sorted_back, 1):
            print(f"  {i:2d}. {ball:02d}å·: æ¦‚ç‡ {prob:.4f}")

        if save_results:
            self._save_bayesian_results(results)

        return results

    def _calculate_prior_probability(self, ball_type):
        """è®¡ç®—å…ˆéªŒæ¦‚ç‡"""
        frequency = defaultdict(int)
        total_count = 0

        for _, row in self.df.iterrows():
            balls = self.parse_balls(row[f'{ball_type}_balls'])
            for ball in balls:
                frequency[ball] += 1
                total_count += 1

        prior = {}
        max_ball = 35 if ball_type == 'front' else 12
        for ball in range(1, max_ball + 1):
            prior[ball] = frequency[ball] / total_count if total_count > 0 else 0

        return prior

    def _calculate_conditional_probability(self, ball_type):
        """è®¡ç®—æ¡ä»¶æ¦‚ç‡"""
        conditional = defaultdict(lambda: defaultdict(int))
        ball_counts = defaultdict(int)

        for i in range(len(self.df) - 1):
            current_balls = self.parse_balls(self.df.iloc[i][f'{ball_type}_balls'])
            next_balls = self.parse_balls(self.df.iloc[i + 1][f'{ball_type}_balls'])

            for curr_ball in current_balls:
                ball_counts[curr_ball] += 1
                for next_ball in next_balls:
                    conditional[curr_ball][next_ball] += 1

        # å½’ä¸€åŒ–
        normalized_conditional = {}
        for curr_ball in conditional:
            total = ball_counts[curr_ball]
            normalized_conditional[curr_ball] = {}
            max_ball = 35 if ball_type == 'front' else 12
            for next_ball in range(1, max_ball + 1):
                normalized_conditional[curr_ball][next_ball] = conditional[curr_ball][next_ball] / total if total > 0 else 0

        return normalized_conditional

    def _calculate_posterior_probability(self, prior, conditional):
        """è®¡ç®—åéªŒæ¦‚ç‡"""
        # è·å–æœ€æ–°ä¸€æœŸå·ç 
        latest_balls = self.parse_balls(self.df.iloc[0]['front_balls']) if 'front' in str(conditional) else self.parse_balls(self.df.iloc[0]['back_balls'])

        posterior = {}
        max_ball = 35 if len(prior) > 12 else 12

        for ball in range(1, max_ball + 1):
            # è´å¶æ–¯å…¬å¼: P(ball|evidence) = P(evidence|ball) * P(ball) / P(evidence)
            likelihood = 1.0
            for latest_ball in latest_balls:
                if latest_ball in conditional:
                    likelihood *= conditional[latest_ball].get(ball, 0.001)

            posterior[ball] = likelihood * prior.get(ball, 0.001)

        # å½’ä¸€åŒ–
        total_posterior = sum(posterior.values())
        if total_posterior > 0:
            for ball in posterior:
                posterior[ball] /= total_posterior

        return posterior

    def _save_bayesian_results(self, results):
        """ä¿å­˜è´å¶æ–¯åˆ†æç»“æœ"""
        output_dir = "output/advanced"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # ä¿å­˜JSONç»“æœ
        with open(f"{output_dir}/bayesian_analysis.json", 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"è´å¶æ–¯åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}/bayesian_analysis.json")

    def _save_markov_analysis(self, analysis_data):
        """ä¿å­˜é©¬å°”å¯å¤«é“¾åˆ†æç»“æœ"""
        output_dir = "output/advanced"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        markov_results = {
            'analysis_info': {
                'num_periods': analysis_data['num_periods'],
                'data_range': analysis_data['data_range'],
                'latest_draw': analysis_data['latest_draw'],
                'analysis_date': datetime.now().isoformat()
            },
            'front_transition_probs': {},
            'back_transition_probs': {},
            'front_stability_scores': {str(k): float(v) for k, v in analysis_data['front_stability'].items()},
            'back_stability_scores': {str(k): float(v) for k, v in analysis_data['back_stability'].items()},
            'front_frequency': {str(k): int(v) for k, v in analysis_data['front_frequency'].items()},
            'back_frequency': {str(k): int(v) for k, v in analysis_data['back_frequency'].items()}
        }

        # è½¬æ¢è½¬ç§»æ¦‚ç‡ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        for from_ball, to_balls in analysis_data['front_probabilities'].items():
            markov_results['front_transition_probs'][str(from_ball)] = {}
            for to_ball in range(1, 36):
                markov_results['front_transition_probs'][str(from_ball)][str(to_ball)] = to_balls.get(to_ball, 0.0)

        for from_ball, to_balls in analysis_data['back_probabilities'].items():
            markov_results['back_transition_probs'][str(from_ball)] = {}
            for to_ball in range(1, 13):
                markov_results['back_transition_probs'][str(from_ball)][str(to_ball)] = to_balls.get(to_ball, 0.0)

        # ä¿å­˜JSONç»“æœ
        with open(f"{output_dir}/markov_chain_analysis.json", 'w', encoding='utf-8') as f:
            json.dump(markov_results, f, ensure_ascii=False, indent=2, default=str)

        print(f"é©¬å°”å¯å¤«é“¾åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}/markov_chain_analysis.json")

    def probability_analysis(self, save_results=True):
        """æ¦‚ç‡åˆ†æ"""
        print("\nå¼€å§‹æ¦‚ç‡åˆ†æ...")

        # è®¡ç®—å„ç§æ¦‚ç‡
        single_ball_probs = self._calculate_single_ball_probabilities()
        combination_probs = self._calculate_combination_probabilities()
        pattern_probs = self._calculate_pattern_probabilities()

        results = {
            'single_ball_probabilities': single_ball_probs,
            'combination_probabilities': combination_probs,
            'pattern_probabilities': pattern_probs
        }

        # æ‰“å°ç»“æœ
        print("\næ¦‚ç‡åˆ†æç»“æœ:")
        print("=" * 50)

        print("\nå•çƒå‡ºç°æ¦‚ç‡ (å‰åŒºå‰10):")
        sorted_front = sorted(single_ball_probs['front'].items(), key=lambda x: x[1], reverse=True)
        for i, (ball, prob) in enumerate(sorted_front[:10], 1):
            print(f"  {i:2d}. {ball:02d}å·: {prob:.4f} ({prob*100:.2f}%)")

        print("\nå•çƒå‡ºç°æ¦‚ç‡ (ååŒº):")
        sorted_back = sorted(single_ball_probs['back'].items(), key=lambda x: x[1], reverse=True)
        for i, (ball, prob) in enumerate(sorted_back, 1):
            print(f"  {i:2d}. {ball:02d}å·: {prob:.4f} ({prob*100:.2f}%)")

        if save_results:
            self._save_probability_results(results)

        return results

    def _calculate_single_ball_probabilities(self):
        """è®¡ç®—å•çƒå‡ºç°æ¦‚ç‡"""
        front_count = defaultdict(int)
        back_count = defaultdict(int)
        total_draws = len(self.df)

        for _, row in self.df.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            for ball in front_balls:
                front_count[ball] += 1
            for ball in back_balls:
                back_count[ball] += 1

        # è®¡ç®—æ¦‚ç‡
        front_probs = {}
        back_probs = {}

        for ball in range(1, 36):
            front_probs[ball] = front_count[ball] / total_draws

        for ball in range(1, 13):
            back_probs[ball] = back_count[ball] / total_draws

        return {'front': front_probs, 'back': back_probs}

    def _calculate_combination_probabilities(self):
        """è®¡ç®—ç»„åˆå‡ºç°æ¦‚ç‡"""
        # è®¡ç®—å¸¸è§ç»„åˆçš„æ¦‚ç‡
        front_pairs = defaultdict(int)
        back_pairs = defaultdict(int)
        total_draws = len(self.df)

        for _, row in self.df.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            # å‰åŒºä¸¤ä¸¤ç»„åˆ
            for i in range(len(front_balls)):
                for j in range(i+1, len(front_balls)):
                    pair = tuple(sorted([front_balls[i], front_balls[j]]))
                    front_pairs[pair] += 1

            # ååŒºç»„åˆ
            if len(back_balls) == 2:
                pair = tuple(sorted(back_balls))
                back_pairs[pair] += 1

        # è½¬æ¢ä¸ºæ¦‚ç‡
        front_pair_probs = {pair: count/total_draws for pair, count in front_pairs.items()}
        back_pair_probs = {pair: count/total_draws for pair, count in back_pairs.items()}

        return {
            'front_pairs': front_pair_probs,
            'back_pairs': back_pair_probs
        }

    def _calculate_pattern_probabilities(self):
        """è®¡ç®—æ¨¡å¼æ¦‚ç‡"""
        odd_even_patterns = defaultdict(int)
        size_patterns = defaultdict(int)
        sum_ranges = defaultdict(int)
        total_draws = len(self.df)

        for _, row in self.df.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            # å¥‡å¶æ¨¡å¼
            front_odd = sum(1 for ball in front_balls if ball % 2 == 1)
            back_odd = sum(1 for ball in back_balls if ball % 2 == 1)
            odd_even_patterns[f"å‰åŒº{front_odd}å¥‡{5-front_odd}å¶_ååŒº{back_odd}å¥‡{2-back_odd}å¶"] += 1

            # å¤§å°æ¨¡å¼
            front_small = sum(1 for ball in front_balls if ball <= 17)
            back_small = sum(1 for ball in back_balls if ball <= 6)
            size_patterns[f"å‰åŒº{front_small}å°{5-front_small}å¤§_ååŒº{back_small}å°{2-back_small}å¤§"] += 1

            # å’Œå€¼èŒƒå›´
            front_sum = sum(front_balls)
            if front_sum <= 70:
                sum_range = "å°å’Œå€¼(â‰¤70)"
            elif front_sum <= 110:
                sum_range = "ä¸­å’Œå€¼(71-110)"
            else:
                sum_range = "å¤§å’Œå€¼(â‰¥111)"
            sum_ranges[sum_range] += 1

        # è½¬æ¢ä¸ºæ¦‚ç‡
        pattern_probs = {
            'odd_even': {pattern: count/total_draws for pattern, count in odd_even_patterns.items()},
            'size': {pattern: count/total_draws for pattern, count in size_patterns.items()},
            'sum_ranges': {range_name: count/total_draws for range_name, count in sum_ranges.items()}
        }

        return pattern_probs

    def _save_probability_results(self, results):
        """ä¿å­˜æ¦‚ç‡åˆ†æç»“æœ"""
        output_dir = "output/advanced"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # è½¬æ¢tupleé”®ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
        serializable_results = {
            'single_ball_probabilities': results['single_ball_probabilities'],
            'combination_probabilities': {
                'front_pairs': {str(k): v for k, v in results['combination_probabilities']['front_pairs'].items()},
                'back_pairs': {str(k): v for k, v in results['combination_probabilities']['back_pairs'].items()}
            },
            'pattern_probabilities': results['pattern_probabilities']
        }

        # ä¿å­˜JSONç»“æœ
        with open(f"{output_dir}/probability_analysis.json", 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)

        print(f"æ¦‚ç‡åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}/probability_analysis.json")

    def frequency_pattern_analysis(self, save_results=True):
        """é¢‘ç‡æ¨¡å¼åˆ†æ"""
        print("\nå¼€å§‹é¢‘ç‡æ¨¡å¼åˆ†æ...")

        # åˆ†æå·ç ç»„åˆæ¨¡å¼
        combination_patterns = self._analyze_combination_patterns()

        # åˆ†æå¥‡å¶æ¨¡å¼
        odd_even_patterns = self._analyze_odd_even_patterns()

        # åˆ†æå¤§å°æ¨¡å¼
        size_patterns = self._analyze_size_patterns()

        # åˆ†æè¿å·æ¨¡å¼
        consecutive_patterns = self._analyze_consecutive_patterns()

        results = {
            'combination_patterns': combination_patterns,
            'odd_even_patterns': odd_even_patterns,
            'size_patterns': size_patterns,
            'consecutive_patterns': consecutive_patterns
        }

        # æ‰“å°ç»“æœ
        print("\né¢‘ç‡æ¨¡å¼åˆ†æç»“æœ:")
        print("=" * 50)

        print("\nå¥‡å¶æ¨¡å¼åˆ†å¸ƒ:")
        for pattern, count in sorted(odd_even_patterns['front'].items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"  å‰åŒº{pattern}: {count}æ¬¡")

        print("\nå¤§å°æ¨¡å¼åˆ†å¸ƒ:")
        for pattern, count in sorted(size_patterns['front'].items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"  å‰åŒº{pattern}: {count}æ¬¡")

        if save_results:
            self._save_frequency_results(results)

        return results

    def _analyze_combination_patterns(self):
        """åˆ†æå·ç ç»„åˆæ¨¡å¼"""
        patterns = {'front': defaultdict(int), 'back': defaultdict(int)}

        for _, row in self.df.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            # å‰åŒºæ¨¡å¼
            front_pattern = tuple(sorted(front_balls))
            patterns['front'][front_pattern] += 1

            # ååŒºæ¨¡å¼
            back_pattern = tuple(sorted(back_balls))
            patterns['back'][back_pattern] += 1

        return patterns

    def _analyze_odd_even_patterns(self):
        """åˆ†æå¥‡å¶æ¨¡å¼"""
        patterns = {'front': defaultdict(int), 'back': defaultdict(int)}

        for _, row in self.df.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            # å‰åŒºå¥‡å¶
            odd_count = sum(1 for ball in front_balls if ball % 2 == 1)
            even_count = 5 - odd_count
            front_pattern = f"{odd_count}å¥‡{even_count}å¶"
            patterns['front'][front_pattern] += 1

            # ååŒºå¥‡å¶
            odd_count = sum(1 for ball in back_balls if ball % 2 == 1)
            even_count = 2 - odd_count
            back_pattern = f"{odd_count}å¥‡{even_count}å¶"
            patterns['back'][back_pattern] += 1

        return patterns

    def _analyze_size_patterns(self):
        """åˆ†æå¤§å°æ¨¡å¼"""
        patterns = {'front': defaultdict(int), 'back': defaultdict(int)}

        for _, row in self.df.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            # å‰åŒºå¤§å° (1-17å°ï¼Œ18-35å¤§)
            small_count = sum(1 for ball in front_balls if ball <= 17)
            big_count = 5 - small_count
            front_pattern = f"{small_count}å°{big_count}å¤§"
            patterns['front'][front_pattern] += 1

            # ååŒºå¤§å° (1-6å°ï¼Œ7-12å¤§)
            small_count = sum(1 for ball in back_balls if ball <= 6)
            big_count = 2 - small_count
            back_pattern = f"{small_count}å°{big_count}å¤§"
            patterns['back'][back_pattern] += 1

        return patterns

    def _analyze_consecutive_patterns(self):
        """åˆ†æè¿å·æ¨¡å¼"""
        patterns = {'front': defaultdict(int), 'back': defaultdict(int)}

        for _, row in self.df.iterrows():
            front_balls = sorted(self.parse_balls(row['front_balls']))
            back_balls = sorted(self.parse_balls(row['back_balls']))

            # å‰åŒºè¿å·
            consecutive_count = 0
            for i in range(len(front_balls) - 1):
                if front_balls[i + 1] - front_balls[i] == 1:
                    consecutive_count += 1
            patterns['front'][consecutive_count] += 1

            # ååŒºè¿å·
            consecutive_count = 0
            for i in range(len(back_balls) - 1):
                if back_balls[i + 1] - back_balls[i] == 1:
                    consecutive_count += 1
            patterns['back'][consecutive_count] += 1

        return patterns

    def _save_frequency_results(self, results):
        """ä¿å­˜é¢‘ç‡åˆ†æç»“æœ"""
        output_dir = "output/advanced"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # è½¬æ¢tupleé”®ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
        serializable_results = {}
        for key, value in results.items():
            if isinstance(value, dict):
                serializable_results[key] = {}
                for ball_type, patterns in value.items():
                    serializable_results[key][ball_type] = {}
                    for pattern, count in patterns.items():
                        pattern_str = str(pattern) if isinstance(pattern, tuple) else pattern
                        serializable_results[key][ball_type][pattern_str] = count
            else:
                serializable_results[key] = value

        # ä¿å­˜JSONç»“æœ
        with open(f"{output_dir}/frequency_analysis.json", 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)

        print(f"é¢‘ç‡åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}/frequency_analysis.json")

    def trend_analysis(self, periods=50):
        """èµ°åŠ¿åˆ†æ"""
        print(f"\nå¼€å§‹èµ°åŠ¿åˆ†æ (æœ€è¿‘{periods}æœŸ)...")

        recent_data = self.df.head(periods)

        # å·ç èµ°åŠ¿
        front_trends = self._calculate_number_trends(recent_data, 'front')
        back_trends = self._calculate_number_trends(recent_data, 'back')

        # å’Œå€¼èµ°åŠ¿
        sum_trends = self._calculate_sum_trends(recent_data)

        # è·¨åº¦èµ°åŠ¿
        span_trends = self._calculate_span_trends(recent_data)

        results = {
            'periods': periods,
            'front_trends': front_trends,
            'back_trends': back_trends,
            'sum_trends': sum_trends,
            'span_trends': span_trends
        }

        # æ‰“å°ç»“æœ
        print("\nèµ°åŠ¿åˆ†æç»“æœ:")
        print("=" * 50)

        print(f"\næœ€è¿‘{periods}æœŸå’Œå€¼èµ°åŠ¿:")
        print(f"  å¹³å‡å’Œå€¼: {np.mean(sum_trends['front']):.1f}")
        print(f"  æœ€å¤§å’Œå€¼: {max(sum_trends['front'])}")
        print(f"  æœ€å°å’Œå€¼: {min(sum_trends['front'])}")

        print(f"\næœ€è¿‘{periods}æœŸè·¨åº¦èµ°åŠ¿:")
        print(f"  å¹³å‡è·¨åº¦: {np.mean(span_trends['front']):.1f}")
        print(f"  æœ€å¤§è·¨åº¦: {max(span_trends['front'])}")
        print(f"  æœ€å°è·¨åº¦: {min(span_trends['front'])}")

        return results

    def _calculate_number_trends(self, data, ball_type):
        """è®¡ç®—å·ç èµ°åŠ¿"""
        trends = []
        for _, row in data.iterrows():
            balls = self.parse_balls(row[f'{ball_type}_balls'])
            trends.append(balls)
        return trends

    def _calculate_sum_trends(self, data):
        """è®¡ç®—å’Œå€¼èµ°åŠ¿"""
        trends = {'front': [], 'back': []}

        for _, row in data.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            trends['front'].append(sum(front_balls))
            trends['back'].append(sum(back_balls))

        return trends

    def _calculate_span_trends(self, data):
        """è®¡ç®—è·¨åº¦èµ°åŠ¿"""
        trends = {'front': [], 'back': []}

        for _, row in data.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            trends['front'].append(max(front_balls) - min(front_balls))
            trends['back'].append(max(back_balls) - min(back_balls))

        return trends

    def frequency_based_prediction(self, num_predictions=1):
        """åŸºäºé¢‘ç‡åˆ†æçš„é¢„æµ‹"""
        print(f"\nåŸºäºé¢‘ç‡åˆ†æç”Ÿæˆ {num_predictions} æ³¨é¢„æµ‹...")

        # è·å–é¢‘ç‡æ•°æ®
        front_frequency = defaultdict(int)
        back_frequency = defaultdict(int)

        for _, row in self.df.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            for ball in front_balls:
                front_frequency[ball] += 1
            for ball in back_balls:
                back_frequency[ball] += 1

        predictions = []
        used_combinations = set()

        for i in range(num_predictions):
            # åŸºäºé¢‘ç‡é€‰æ‹©å·ç 
            front_candidates = sorted(front_frequency.items(), key=lambda x: x[1], reverse=True)
            back_candidates = sorted(back_frequency.items(), key=lambda x: x[1], reverse=True)

            # æ·»åŠ éšæœºæ€§é¿å…é‡å¤
            front_selected = []
            back_selected = []

            # é€‰æ‹©å‰åŒºå·ç 
            available_front = [ball for ball, _ in front_candidates]
            random.shuffle(available_front)
            front_selected = available_front[:5]

            # é€‰æ‹©ååŒºå·ç 
            available_back = [ball for ball, _ in back_candidates]
            random.shuffle(available_back)
            back_selected = available_back[:2]

            # æ£€æŸ¥é‡å¤
            combination = (tuple(sorted(front_selected)), tuple(sorted(back_selected)))
            if combination not in used_combinations:
                used_combinations.add(combination)
                predictions.append({
                    'front': sorted(front_selected),
                    'back': sorted(back_selected),
                    'method': 'frequency_based'
                })

        # æ˜¾ç¤ºç»“æœ
        print("\nåŸºäºé¢‘ç‡çš„é¢„æµ‹ç»“æœ:")
        for i, pred in enumerate(predictions, 1):
            front_str = ' '.join([str(b).zfill(2) for b in pred['front']])
            back_str = ' '.join([str(b).zfill(2) for b in pred['back']])
            print(f"ç¬¬ {i} æ³¨: å‰åŒº {front_str} | ååŒº {back_str}")

        return predictions

    def mixed_strategy_prediction(self, num_predictions=1):
        """æ··åˆç­–ç•¥é¢„æµ‹"""
        print(f"\næ··åˆç­–ç•¥ç”Ÿæˆ {num_predictions} æ³¨é¢„æµ‹...")

        predictions = []

        # ç­–ç•¥1: é©¬å°”å¯å¤«é“¾é¢„æµ‹
        if hasattr(self, 'analysis_data') and self.analysis_data:
            markov_preds = self.predict_numbers(max(1, num_predictions // 3), explain=False)
            for pred in markov_preds:
                predictions.append({
                    'front': pred['front'],
                    'back': pred['back'],
                    'method': 'markov_chain',
                    'score': pred['stability_score']
                })

        # ç­–ç•¥2: é¢‘ç‡é¢„æµ‹
        freq_preds = self.frequency_based_prediction(max(1, num_predictions // 3))
        predictions.extend(freq_preds)

        # ç­–ç•¥3: éšæœºé¢„æµ‹ï¼ˆåŸºäºç»Ÿè®¡ç‰¹å¾ï¼‰
        for i in range(num_predictions - len(predictions)):
            front_balls = random.sample(range(1, 36), 5)
            back_balls = random.sample(range(1, 13), 2)
            predictions.append({
                'front': sorted(front_balls),
                'back': sorted(back_balls),
                'method': 'statistical_random'
            })

        # æ˜¾ç¤ºç»“æœ
        print("\næ··åˆç­–ç•¥é¢„æµ‹ç»“æœ:")
        for i, pred in enumerate(predictions[:num_predictions], 1):
            front_str = ' '.join([str(b).zfill(2) for b in pred['front']])
            back_str = ' '.join([str(b).zfill(2) for b in pred['back']])
            method = pred.get('method', 'unknown')
            print(f"ç¬¬ {i} æ³¨: å‰åŒº {front_str} | ååŒº {back_str} ({method})")

        return predictions[:num_predictions]

    def check_winning_comparison(self, predictions, target_issue=None):
        """ä¸­å¥–å¯¹æ¯”åˆ†æ"""
        print("\nå¼€å§‹ä¸­å¥–å¯¹æ¯”åˆ†æ...")

        if target_issue:
            # æŸ¥æ‰¾æŒ‡å®šæœŸå·
            target_row = self.df[self.df['issue'] == str(target_issue)]
            if target_row.empty:
                print(f"æœªæ‰¾åˆ°æœŸå· {target_issue} çš„å¼€å¥–æ•°æ®")
                return None
            target_row = target_row.iloc[0]
        else:
            # ä½¿ç”¨æœ€æ–°ä¸€æœŸ
            target_row = self.df.iloc[0]

        winning_front = self.parse_balls(target_row['front_balls'])
        winning_back = self.parse_balls(target_row['back_balls'])

        print(f"å¯¹æ¯”æœŸå·: {target_row['issue']}")
        print(f"å¼€å¥–å·ç : å‰åŒº {' '.join([str(b).zfill(2) for b in winning_front])}, ååŒº {' '.join([str(b).zfill(2) for b in winning_back])}")

        results = []
        for i, pred in enumerate(predictions, 1):
            front_matches = len(set(pred['front']) & set(winning_front))
            back_matches = len(set(pred['back']) & set(winning_back))

            # åˆ¤æ–­ä¸­å¥–ç­‰çº§
            prize_level = self._determine_prize_level(front_matches, back_matches)

            result = {
                'prediction_no': i,
                'front_matches': front_matches,
                'back_matches': back_matches,
                'prize_level': prize_level,
                'front_balls': pred['front'],
                'back_balls': pred['back']
            }
            results.append(result)

            print(f"ç¬¬ {i} æ³¨: å‰åŒºä¸­{front_matches}ä¸ª, ååŒºä¸­{back_matches}ä¸ª - {prize_level}")

        return results

    def _determine_prize_level(self, front_matches, back_matches):
        """åˆ¤æ–­ä¸­å¥–ç­‰çº§"""
        if front_matches == 5 and back_matches == 2:
            return "ä¸€ç­‰å¥–"
        elif front_matches == 5 and back_matches == 1:
            return "äºŒç­‰å¥–"
        elif front_matches == 5 and back_matches == 0:
            return "ä¸‰ç­‰å¥–"
        elif front_matches == 4 and back_matches == 2:
            return "å››ç­‰å¥–"
        elif front_matches == 4 and back_matches == 1:
            return "äº”ç­‰å¥–"
        elif front_matches == 3 and back_matches == 2:
            return "å…­ç­‰å¥–"
        elif front_matches == 4 and back_matches == 0:
            return "ä¸ƒç­‰å¥–"
        elif front_matches == 3 and back_matches == 1:
            return "å…«ç­‰å¥–"
        elif front_matches == 2 and back_matches == 2:
            return "ä¹ç­‰å¥–"
        else:
            return "æœªä¸­å¥–"

    def historical_comparison(self, periods=100):
        """å†å²å¯¹æ¯”åˆ†æ"""
        print(f"\nå¼€å§‹å†å²å¯¹æ¯”åˆ†æ (æœ€è¿‘{periods}æœŸ)...")

        recent_data = self.df.head(periods)

        # ç»Ÿè®¡å„ç§ç‰¹å¾
        features = {
            'sum_distribution': {'front': [], 'back': []},
            'odd_even_distribution': {'front': [], 'back': []},
            'size_distribution': {'front': [], 'back': []},
            'span_distribution': {'front': [], 'back': []}
        }

        for _, row in recent_data.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            # å’Œå€¼åˆ†å¸ƒ
            features['sum_distribution']['front'].append(sum(front_balls))
            features['sum_distribution']['back'].append(sum(back_balls))

            # å¥‡å¶åˆ†å¸ƒ
            front_odd = sum(1 for ball in front_balls if ball % 2 == 1)
            back_odd = sum(1 for ball in back_balls if ball % 2 == 1)
            features['odd_even_distribution']['front'].append(front_odd)
            features['odd_even_distribution']['back'].append(back_odd)

            # å¤§å°åˆ†å¸ƒ
            front_small = sum(1 for ball in front_balls if ball <= 17)
            back_small = sum(1 for ball in back_balls if ball <= 6)
            features['size_distribution']['front'].append(front_small)
            features['size_distribution']['back'].append(back_small)

            # è·¨åº¦åˆ†å¸ƒ
            features['span_distribution']['front'].append(max(front_balls) - min(front_balls))
            features['span_distribution']['back'].append(max(back_balls) - min(back_balls))

        # è®¡ç®—ç»Ÿè®¡ç‰¹å¾
        stats = {}
        for feature_name, feature_data in features.items():
            stats[feature_name] = {}
            for ball_type in ['front', 'back']:
                data = feature_data[ball_type]
                stats[feature_name][ball_type] = {
                    'mean': np.mean(data),
                    'std': np.std(data),
                    'min': min(data),
                    'max': max(data),
                    'median': np.median(data)
                }

        # æ‰“å°ç»“æœ
        print("\nå†å²ç‰¹å¾ç»Ÿè®¡:")
        print("=" * 50)

        print(f"\nå‰åŒºå’Œå€¼ç»Ÿè®¡ (æœ€è¿‘{periods}æœŸ):")
        front_sum_stats = stats['sum_distribution']['front']
        print(f"  å¹³å‡å€¼: {front_sum_stats['mean']:.1f}")
        print(f"  æ ‡å‡†å·®: {front_sum_stats['std']:.1f}")
        print(f"  èŒƒå›´: {front_sum_stats['min']} - {front_sum_stats['max']}")

        print(f"\nå‰åŒºè·¨åº¦ç»Ÿè®¡ (æœ€è¿‘{periods}æœŸ):")
        front_span_stats = stats['span_distribution']['front']
        print(f"  å¹³å‡å€¼: {front_span_stats['mean']:.1f}")
        print(f"  æ ‡å‡†å·®: {front_span_stats['std']:.1f}")
        print(f"  èŒƒå›´: {front_span_stats['min']} - {front_span_stats['max']}")

        return stats

    def update_data_append(self, new_periods=10):
        """è¿½åŠ æœ€æ–°æ•°æ®åˆ°CSVæ–‡ä»¶"""
        print(f"å¼€å§‹è·å–æœ€æ–° {new_periods} æœŸæ•°æ®...")

        # åˆ›å»ºçˆ¬è™«è·å–æœ€æ–°æ•°æ®
        crawler = DLTCrawler()
        new_results = crawler.get_history_data(new_periods)

        if not new_results:
            print("æœªè·å–åˆ°æ–°æ•°æ®")
            return False

        # è¯»å–ç°æœ‰æ•°æ®
        existing_data = []
        if os.path.exists(self.data_file):
            with open(self.data_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                existing_data = list(reader)

        # åˆå¹¶æ•°æ®ï¼ˆå»é‡ï¼‰
        existing_issues = {row['issue'] for row in existing_data}
        new_data = [result for result in new_results if result['issue'] not in existing_issues]

        if new_data:
            all_data = new_data + existing_data
            # æŒ‰æœŸå·æ’åº
            all_data.sort(key=lambda x: int(x['issue']), reverse=True)

            # ä¿å­˜åˆå¹¶åçš„æ•°æ®
            with open(self.data_file, 'w', newline='', encoding='utf-8') as f:
                fieldnames = ['issue', 'date', 'front_balls', 'back_balls']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(all_data)

            print(f"æˆåŠŸè¿½åŠ  {len(new_data)} æ¡æ–°æ•°æ®åˆ° {self.data_file}")
            print(f"æ€»æ•°æ®é‡: {len(all_data)} æ¡")

            # é‡æ–°åŠ è½½æ•°æ®
            self.load_data()
            return True
        else:
            print("æ²¡æœ‰æ–°æ•°æ®éœ€è¦è¿½åŠ ")
            return False

    def visualization_analysis(self, save_charts=True):
        """å¯è§†åŒ–åˆ†æ - ç”Ÿæˆå„ç§å›¾è¡¨"""
        print("\nå¼€å§‹å¯è§†åŒ–åˆ†æ...")

        output_dir = "output/advanced"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # 1. ç”Ÿæˆé¢‘ç‡åˆ†å¸ƒå›¾
        self._generate_frequency_charts(output_dir, save_charts)

        # 2. ç”Ÿæˆè½¬ç§»æ¦‚ç‡çƒ­åŠ›å›¾
        if hasattr(self, 'analysis_data') and self.analysis_data:
            self._generate_transition_heatmap(output_dir, save_charts)

        # 3. ç”Ÿæˆç½‘ç»œå›¾
        if hasattr(self, 'analysis_data') and self.analysis_data:
            self._generate_network_graph(output_dir, save_charts)

        # 4. ç”Ÿæˆé—æ¼å€¼çƒ­åŠ›å›¾
        self._generate_missing_heatmap(output_dir, save_charts)

        # 5. ç”Ÿæˆèµ°åŠ¿å›¾
        self._generate_trend_charts(output_dir, save_charts)

        print(f"å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}")

        return True

    def _generate_frequency_charts(self, output_dir, save_charts):
        """ç”Ÿæˆé¢‘ç‡åˆ†å¸ƒå›¾"""
        # è®¡ç®—é¢‘ç‡
        front_frequency = defaultdict(int)
        back_frequency = defaultdict(int)

        for _, row in self.df.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            for ball in front_balls:
                front_frequency[ball] += 1
            for ball in back_balls:
                back_frequency[ball] += 1

        # å‰åŒºé¢‘ç‡åˆ†å¸ƒå›¾
        plt.figure(figsize=(15, 8))

        plt.subplot(2, 1, 1)
        front_balls = list(range(1, 36))
        front_counts = [front_frequency[ball] for ball in front_balls]

        bars = plt.bar(front_balls, front_counts, color='skyblue', alpha=0.7)
        plt.title('å‰åŒºå·ç é¢‘ç‡åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        plt.xlabel('å·ç ', fontsize=12)
        plt.ylabel('å‡ºç°æ¬¡æ•°', fontsize=12)
        plt.grid(True, alpha=0.3)

        # æ ‡æ³¨æœ€é«˜é¢‘ç‡
        max_idx = front_counts.index(max(front_counts))
        plt.annotate(f'æœ€é«˜: {front_balls[max_idx]}å·\n{max(front_counts)}æ¬¡',
                    xy=(front_balls[max_idx], max(front_counts)),
                    xytext=(front_balls[max_idx]+3, max(front_counts)+10),
                    arrowprops=dict(arrowstyle='->', color='red'),
                    fontsize=10, color='red')

        # ååŒºé¢‘ç‡åˆ†å¸ƒå›¾
        plt.subplot(2, 1, 2)
        back_balls = list(range(1, 13))
        back_counts = [back_frequency[ball] for ball in back_balls]

        bars = plt.bar(back_balls, back_counts, color='lightcoral', alpha=0.7)
        plt.title('ååŒºå·ç é¢‘ç‡åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        plt.xlabel('å·ç ', fontsize=12)
        plt.ylabel('å‡ºç°æ¬¡æ•°', fontsize=12)
        plt.grid(True, alpha=0.3)

        # æ ‡æ³¨æœ€é«˜é¢‘ç‡
        max_idx = back_counts.index(max(back_counts))
        plt.annotate(f'æœ€é«˜: {back_balls[max_idx]}å·\n{max(back_counts)}æ¬¡',
                    xy=(back_balls[max_idx], max(back_counts)),
                    xytext=(back_balls[max_idx]+1, max(back_counts)+20),
                    arrowprops=dict(arrowstyle='->', color='red'),
                    fontsize=10, color='red')

        plt.tight_layout()

        if save_charts:
            plt.savefig(f"{output_dir}/frequency_distribution.png", dpi=300, bbox_inches='tight')
            print("é¢‘ç‡åˆ†å¸ƒå›¾å·²ä¿å­˜")

        plt.close()

    def _generate_transition_heatmap(self, output_dir, save_charts):
        """ç”Ÿæˆè½¬ç§»æ¦‚ç‡çƒ­åŠ›å›¾"""
        if not self.analysis_data:
            return

        # å‰åŒºè½¬ç§»æ¦‚ç‡çƒ­åŠ›å›¾
        front_probs = self.analysis_data['front_probabilities']

        # åˆ›å»ºè½¬ç§»çŸ©é˜µ
        matrix_size = 35
        transition_matrix = np.zeros((matrix_size, matrix_size))

        for from_ball in range(1, matrix_size + 1):
            if from_ball in front_probs:
                for to_ball in range(1, matrix_size + 1):
                    if to_ball in front_probs[from_ball]:
                        transition_matrix[from_ball-1][to_ball-1] = front_probs[from_ball][to_ball]

        plt.figure(figsize=(12, 10))
        sns.heatmap(transition_matrix,
                   xticklabels=range(1, matrix_size + 1),
                   yticklabels=range(1, matrix_size + 1),
                   cmap='YlOrRd',
                   cbar_kws={'label': 'è½¬ç§»æ¦‚ç‡'})

        plt.title('å‰åŒºå·ç è½¬ç§»æ¦‚ç‡çƒ­åŠ›å›¾', fontsize=16, fontweight='bold')
        plt.xlabel('è½¬ç§»åˆ°å·ç ', fontsize=12)
        plt.ylabel('ä»å·ç ', fontsize=12)

        if save_charts:
            plt.savefig(f"{output_dir}/front_transition_heatmap.png", dpi=300, bbox_inches='tight')
            print("å‰åŒºè½¬ç§»æ¦‚ç‡çƒ­åŠ›å›¾å·²ä¿å­˜")

        plt.close()

    def _generate_network_graph(self, output_dir, save_charts):
        """ç”Ÿæˆè½¬ç§»ç½‘ç»œå›¾"""
        if not self.analysis_data:
            return

        # åˆ›å»ºç½‘ç»œå›¾
        G = nx.DiGraph()

        # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹ï¼ˆåªæ˜¾ç¤ºæ¦‚ç‡è¾ƒé«˜çš„è½¬ç§»ï¼‰
        front_probs = self.analysis_data['front_probabilities']
        threshold = 0.1  # åªæ˜¾ç¤ºæ¦‚ç‡å¤§äº0.1çš„è½¬ç§»

        for from_ball in front_probs:
            for to_ball, prob in front_probs[from_ball].items():
                if prob > threshold:
                    G.add_edge(from_ball, to_ball, weight=prob)

        if len(G.nodes()) > 0:
            plt.figure(figsize=(12, 10))

            # è®¾ç½®å¸ƒå±€
            pos = nx.spring_layout(G, k=1, iterations=50)

            # ç»˜åˆ¶èŠ‚ç‚¹
            nx.draw_networkx_nodes(G, pos, node_color='lightblue',
                                 node_size=300, alpha=0.7)

            # ç»˜åˆ¶è¾¹
            edges = G.edges()
            weights = [G[u][v]['weight'] for u, v in edges]
            nx.draw_networkx_edges(G, pos, width=[w*5 for w in weights],
                                 alpha=0.6, edge_color='gray', arrows=True)

            # ç»˜åˆ¶æ ‡ç­¾
            nx.draw_networkx_labels(G, pos, font_size=8)

            plt.title('ååŒºå·ç è½¬ç§»ç½‘ç»œå›¾ (æ¦‚ç‡>0.1)', fontsize=16, fontweight='bold')
            plt.axis('off')

            if save_charts:
                plt.savefig(f"{output_dir}/back_transition_network.png", dpi=300, bbox_inches='tight')
                print("è½¬ç§»ç½‘ç»œå›¾å·²ä¿å­˜")

        plt.close()

    def _generate_missing_heatmap(self, output_dir, save_charts):
        """ç”Ÿæˆé—æ¼å€¼çƒ­åŠ›å›¾"""
        # è®¡ç®—æœ€è¿‘50æœŸçš„é—æ¼å€¼å˜åŒ–
        recent_data = self.df.head(50)

        front_missing_history = []
        back_missing_history = []

        for i in range(len(recent_data)):
            # è®¡ç®—åˆ°ç¬¬iæœŸä¸ºæ­¢çš„é—æ¼å€¼
            subset_data = recent_data.iloc[:i+1]
            front_missing = self._calculate_missing_values_for_data(subset_data, 'front')
            back_missing = self._calculate_missing_values_for_data(subset_data, 'back')

            front_missing_history.append([front_missing.get(j, 0) for j in range(1, 36)])
            back_missing_history.append([back_missing.get(j, 0) for j in range(1, 13)])

        # å‰åŒºé—æ¼å€¼çƒ­åŠ›å›¾
        plt.figure(figsize=(15, 8))

        plt.subplot(2, 1, 1)
        front_matrix = np.array(front_missing_history).T
        sns.heatmap(front_matrix,
                   xticklabels=range(1, len(recent_data)+1),
                   yticklabels=range(1, 36),
                   cmap='Reds',
                   cbar_kws={'label': 'é—æ¼æœŸæ•°'})

        plt.title('å‰åŒºå·ç é—æ¼å€¼çƒ­åŠ›å›¾ (æœ€è¿‘50æœŸ)', fontsize=14, fontweight='bold')
        plt.xlabel('æœŸæ•°', fontsize=12)
        plt.ylabel('å·ç ', fontsize=12)

        # ååŒºé—æ¼å€¼çƒ­åŠ›å›¾
        plt.subplot(2, 1, 2)
        back_matrix = np.array(back_missing_history).T
        sns.heatmap(back_matrix,
                   xticklabels=range(1, len(recent_data)+1),
                   yticklabels=range(1, 13),
                   cmap='Blues',
                   cbar_kws={'label': 'é—æ¼æœŸæ•°'})

        plt.title('ååŒºå·ç é—æ¼å€¼çƒ­åŠ›å›¾ (æœ€è¿‘50æœŸ)', fontsize=14, fontweight='bold')
        plt.xlabel('æœŸæ•°', fontsize=12)
        plt.ylabel('å·ç ', fontsize=12)

        plt.tight_layout()

        if save_charts:
            plt.savefig(f"{output_dir}/missing_value_heatmap.png", dpi=300, bbox_inches='tight')
            print("é—æ¼å€¼çƒ­åŠ›å›¾å·²ä¿å­˜")

        plt.close()

    def _calculate_missing_values_for_data(self, data, ball_type):
        """ä¸ºæŒ‡å®šæ•°æ®è®¡ç®—é—æ¼å€¼"""
        missing = {}
        max_ball = 35 if ball_type == 'front' else 12

        for ball in range(1, max_ball + 1):
            missing[ball] = 0

            for i, (_, row) in enumerate(data.iterrows()):
                balls = self.parse_balls(row[f'{ball_type}_balls'])
                if ball in balls:
                    missing[ball] = 0
                else:
                    missing[ball] += 1

                if i == 0:  # åªè®¡ç®—åˆ°æœ€æ–°ä¸€æœŸ
                    break

        return missing

    def _generate_trend_charts(self, output_dir, save_charts):
        """ç”Ÿæˆèµ°åŠ¿å›¾"""
        recent_data = self.df.head(100)  # æœ€è¿‘100æœŸ

        # è®¡ç®—å’Œå€¼èµ°åŠ¿
        front_sums = []
        back_sums = []
        issues = []

        for _, row in recent_data.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            back_balls = self.parse_balls(row['back_balls'])

            front_sums.append(sum(front_balls))
            back_sums.append(sum(back_balls))
            issues.append(row['issue'])

        # åè½¬åˆ—è¡¨ä»¥æŒ‰æ—¶é—´é¡ºåºæ˜¾ç¤º
        front_sums.reverse()
        back_sums.reverse()
        issues.reverse()

        plt.figure(figsize=(15, 10))

        # å‰åŒºå’Œå€¼èµ°åŠ¿
        plt.subplot(3, 1, 1)
        plt.plot(range(len(front_sums)), front_sums, 'b-o', markersize=3, linewidth=1)
        plt.title('å‰åŒºå’Œå€¼èµ°åŠ¿å›¾ (æœ€è¿‘100æœŸ)', fontsize=14, fontweight='bold')
        plt.ylabel('å’Œå€¼', fontsize=12)
        plt.grid(True, alpha=0.3)

        # æ·»åŠ å¹³å‡çº¿
        avg_front = np.mean(front_sums)
        plt.axhline(y=avg_front, color='r', linestyle='--', alpha=0.7,
                   label=f'å¹³å‡å€¼: {avg_front:.1f}')
        plt.legend()

        # ååŒºå’Œå€¼èµ°åŠ¿
        plt.subplot(3, 1, 2)
        plt.plot(range(len(back_sums)), back_sums, 'r-o', markersize=3, linewidth=1)
        plt.title('ååŒºå’Œå€¼èµ°åŠ¿å›¾ (æœ€è¿‘100æœŸ)', fontsize=14, fontweight='bold')
        plt.ylabel('å’Œå€¼', fontsize=12)
        plt.grid(True, alpha=0.3)

        # æ·»åŠ å¹³å‡çº¿
        avg_back = np.mean(back_sums)
        plt.axhline(y=avg_back, color='b', linestyle='--', alpha=0.7,
                   label=f'å¹³å‡å€¼: {avg_back:.1f}')
        plt.legend()

        # å¥‡å¶æ¯”ä¾‹èµ°åŠ¿
        plt.subplot(3, 1, 3)
        odd_ratios = []
        for _, row in recent_data.iterrows():
            front_balls = self.parse_balls(row['front_balls'])
            odd_count = sum(1 for ball in front_balls if ball % 2 == 1)
            odd_ratios.append(odd_count / 5)

        odd_ratios.reverse()
        plt.plot(range(len(odd_ratios)), odd_ratios, 'g-o', markersize=3, linewidth=1)
        plt.title('å‰åŒºå¥‡æ•°æ¯”ä¾‹èµ°åŠ¿å›¾ (æœ€è¿‘100æœŸ)', fontsize=14, fontweight='bold')
        plt.ylabel('å¥‡æ•°æ¯”ä¾‹', fontsize=12)
        plt.xlabel('æœŸæ•°', fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.ylim(0, 1)

        # æ·»åŠ ç†è®ºå¹³å‡çº¿
        plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7,
                   label='ç†è®ºå¹³å‡: 0.5')
        plt.legend()

        plt.tight_layout()

        if save_charts:
            plt.savefig(f"{output_dir}/trend_charts.png", dpi=300, bbox_inches='tight')
            print("èµ°åŠ¿å›¾å·²ä¿å­˜")

        plt.close()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¤§ä¹é€æ•°æ®åˆ†æä¸é¢„æµ‹ç³»ç»Ÿ")
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # çˆ¬å–æ•°æ®å‘½ä»¤
    crawl_parser = subparsers.add_parser("crawl", help="çˆ¬å–å¤§ä¹é€å†å²æ•°æ®")
    crawl_parser.add_argument("-c", "--count", type=int, default=50, help="è·å–çš„æœŸæ•°")
    crawl_parser.add_argument("-o", "--output", default="data/dlt_data.csv", help="è¾“å‡ºæ–‡ä»¶å")
    crawl_parser.add_argument("-a", "--all", action="store_true", help="è·å–æ‰€æœ‰å†å²æ•°æ®")

    # æ£€æŸ¥æ•°æ®å‘½ä»¤
    check_parser = subparsers.add_parser("check", help="æ£€æŸ¥æ•°æ®è´¨é‡")
    check_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    check_parser.add_argument("-q", "--quiet", action="store_true", help="é™é»˜æ¨¡å¼")
    check_parser.add_argument("--remove-duplicates", action="store_true", help="å»é™¤é‡å¤æ•°æ®")

    # æ›´æ–°æ•°æ®å‘½ä»¤
    update_parser = subparsers.add_parser("update", help="è¿½åŠ æœ€æ–°æ•°æ®åˆ°ç°æœ‰æ–‡ä»¶")
    update_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    update_parser.add_argument("-n", "--new-periods", type=int, default=10, help="è·å–æœ€æ–°æœŸæ•°")

    # åŸºç¡€åˆ†æå‘½ä»¤
    basic_parser = subparsers.add_parser("basic", help="åŸºç¡€ç»Ÿè®¡åˆ†æ")
    basic_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")

    # è´å¶æ–¯åˆ†æå‘½ä»¤
    bayesian_parser = subparsers.add_parser("bayesian", help="è´å¶æ–¯åˆ†æ")
    bayesian_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")

    # æ¦‚ç‡åˆ†æå‘½ä»¤
    prob_parser = subparsers.add_parser("probability", help="æ¦‚ç‡åˆ†æ")
    prob_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")

    # é¢‘ç‡æ¨¡å¼åˆ†æå‘½ä»¤
    frequency_parser = subparsers.add_parser("frequency", help="é¢‘ç‡æ¨¡å¼åˆ†æ")
    frequency_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")

    # èµ°åŠ¿åˆ†æå‘½ä»¤
    trend_parser = subparsers.add_parser("trend", help="èµ°åŠ¿åˆ†æ")
    trend_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    trend_parser.add_argument("-p", "--periods", type=int, default=50, help="åˆ†ææœŸæ•°")

    # å†å²å¯¹æ¯”å‘½ä»¤
    history_parser = subparsers.add_parser("history", help="å†å²å¯¹æ¯”åˆ†æ")
    history_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    history_parser.add_argument("-p", "--periods", type=int, default=100, help="å¯¹æ¯”æœŸæ•°")

    # é©¬å°”å¯å¤«é“¾åˆ†æå‘½ä»¤
    markov_parser = subparsers.add_parser("markov", help="é©¬å°”å¯å¤«é“¾åˆ†æå’Œé¢„æµ‹")
    markov_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    markov_parser.add_argument("-p", "--periods", type=int, default=300, help="åˆ†æçš„æœŸæ•°")
    markov_parser.add_argument("-n", "--num", type=int, default=1, help="é¢„æµ‹æ³¨æ•°")
    markov_parser.add_argument("--explain", action="store_true", help="æ˜¾ç¤ºé¢„æµ‹è¿‡ç¨‹")

    # é¢‘ç‡é¢„æµ‹å‘½ä»¤
    freq_predict_parser = subparsers.add_parser("freq-predict", help="åŸºäºé¢‘ç‡çš„é¢„æµ‹")
    freq_predict_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    freq_predict_parser.add_argument("-n", "--num", type=int, default=1, help="é¢„æµ‹æ³¨æ•°")

    # æ··åˆç­–ç•¥é¢„æµ‹å‘½ä»¤
    mixed_parser = subparsers.add_parser("mixed", help="æ··åˆç­–ç•¥é¢„æµ‹")
    mixed_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    mixed_parser.add_argument("-n", "--num", type=int, default=3, help="é¢„æµ‹æ³¨æ•°")

    # ä¸­å¥–å¯¹æ¯”å‘½ä»¤
    compare_parser = subparsers.add_parser("compare", help="ä¸­å¥–å¯¹æ¯”åˆ†æ")
    compare_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    compare_parser.add_argument("-i", "--issue", help="æŒ‡å®šæœŸå·è¿›è¡Œå¯¹æ¯”")
    compare_parser.add_argument("-n", "--num", type=int, default=3, help="é¢„æµ‹æ³¨æ•°")

    # å¯è§†åŒ–åˆ†æå‘½ä»¤
    visual_parser = subparsers.add_parser("visual", help="å¯è§†åŒ–åˆ†æ")
    visual_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    visual_parser.add_argument("-p", "--periods", type=int, default=300, help="é©¬å°”å¯å¤«é“¾åˆ†ææœŸæ•°")

    # å®Œæ•´åˆ†æå‘½ä»¤
    full_parser = subparsers.add_parser("full", help="è¿è¡Œå®Œæ•´åˆ†æ")
    full_parser.add_argument("-d", "--data", default="data/dlt_data.csv", help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    full_parser.add_argument("-p", "--periods", type=int, default=300, help="é©¬å°”å¯å¤«é“¾åˆ†ææœŸæ•°")
    full_parser.add_argument("-n", "--num", type=int, default=5, help="é¢„æµ‹æ³¨æ•°")

    args = parser.parse_args()

    if args.command == "crawl":
        crawler = DLTCrawler()
        if args.all:
            results = crawler.get_history_data(get_all=True)
        else:
            results = crawler.get_history_data(args.count)

        if results:
            crawler.save_to_csv(results, args.output)
        else:
            print("æœªè·å–åˆ°æ•°æ®")

    elif args.command == "check":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        has_duplicates = analyzer.check_duplicates(args.quiet)

        if has_duplicates and args.remove_duplicates:
            analyzer.remove_duplicates()

    elif args.command == "update":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.update_data_append(args.new_periods)

    elif args.command == "basic":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.basic_analysis()

    elif args.command == "bayesian":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.bayesian_analysis()

    elif args.command == "probability":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.probability_analysis()

    elif args.command == "frequency":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.frequency_pattern_analysis()

    elif args.command == "trend":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.trend_analysis(args.periods)

    elif args.command == "history":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.historical_comparison(args.periods)

    elif args.command == "markov":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.analyze_periods(args.periods, verbose=True)
        predictions = analyzer.predict_numbers(args.num, explain=args.explain)

    elif args.command == "freq-predict":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.frequency_based_prediction(args.num)

    elif args.command == "mixed":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.analyze_periods(300, verbose=False)  # ä¸ºæ··åˆç­–ç•¥å‡†å¤‡é©¬å°”å¯å¤«é“¾æ•°æ®
        analyzer.mixed_strategy_prediction(args.num)

    elif args.command == "compare":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.analyze_periods(300, verbose=False)
        predictions = analyzer.predict_numbers(args.num, explain=False)
        analyzer.check_winning_comparison(predictions, args.issue)

    elif args.command == "visual":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)
        analyzer.analyze_periods(args.periods, verbose=False)  # ä¸ºç½‘ç»œå›¾å‡†å¤‡æ•°æ®
        analyzer.visualization_analysis()

    elif args.command == "full":
        if not os.path.exists(args.data):
            print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            return

        analyzer = DLTAnalyzer(args.data)

        print("=" * 60)
        print("å¤§ä¹é€å®Œæ•´åˆ†ææŠ¥å‘Š")
        print("=" * 60)

        # è¿è¡Œæ‰€æœ‰åˆ†æ
        analyzer.basic_analysis()
        analyzer.bayesian_analysis()
        analyzer.probability_analysis()
        analyzer.frequency_pattern_analysis()
        analyzer.trend_analysis()
        analyzer.historical_comparison()

        # é©¬å°”å¯å¤«é“¾é¢„æµ‹
        analyzer.analyze_periods(args.periods, verbose=True)
        predictions = analyzer.predict_numbers(args.num, explain=True)

        # æ··åˆç­–ç•¥é¢„æµ‹
        mixed_predictions = analyzer.mixed_strategy_prediction(args.num)

        # ä¸­å¥–å¯¹æ¯”
        analyzer.check_winning_comparison(predictions)

        print("\n" + "=" * 60)
        print("å®Œæ•´åˆ†ææŠ¥å‘Šç»“æŸ")
        print("=" * 60)

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
