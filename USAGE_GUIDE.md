# ğŸ“– å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿè¯¦ç»†ä½¿ç”¨æŒ‡å—

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºPythonçš„æ™ºèƒ½å½©ç¥¨åˆ†æå’Œé¢„æµ‹å¹³å°ï¼Œé›†æˆäº†ä¼ ç»Ÿç»Ÿè®¡æ–¹æ³•ã€æœºå™¨å­¦ä¹ ç®—æ³•ã€æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œè‡ªé€‚åº”å­¦ä¹ æŠ€æœ¯ã€‚ç³»ç»Ÿæä¾›å®Œæ•´çš„æ•°æ®ç®¡ç†ã€åˆ†æã€é¢„æµ‹ã€å›æµ‹å’Œä¼˜åŒ–åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆéœ€è¦3.8+ï¼‰
python3 --version

# å®‰è£…ä¾èµ–åŒ…
pip install -r requirements.txt

# éªŒè¯å®‰è£…
python3 dlt_main.py version
```

### 2. åˆå§‹åŒ–æ•°æ®

```bash
# é¦–æ¬¡ä½¿ç”¨ï¼Œä»ä¸­å½©ç½‘è·å–å†å²æ•°æ®
python3 dlt_main.py data update --source zhcw

# æŸ¥çœ‹æ•°æ®çŠ¶æ€
python3 dlt_main.py data status
```

### 3. åŸºç¡€ä½¿ç”¨æµç¨‹

```bash
# 1. æ•°æ®åˆ†æ
python3 dlt_main.py analyze -t comprehensive -p 500 --report

# 2. å·ç é¢„æµ‹
python3 dlt_main.py predict -m ensemble -c 5

# 3. è‡ªé€‚åº”å­¦ä¹ 
python3 dlt_main.py learn -s 100 -t 500 --algorithm ucb1

# 4. æ™ºèƒ½é¢„æµ‹
python3 dlt_main.py smart -c 3 --load output/learning/learning_ucb1_*.json
```

## ğŸ“Š æ•°æ®ç®¡ç†åŠŸèƒ½

### æ•°æ®çŠ¶æ€æŸ¥çœ‹

```bash
# æŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯
python3 dlt_main.py data status
```

**è¾“å‡ºä¿¡æ¯åŒ…æ‹¬ï¼š**
- æ€»æœŸæ•°
- æ•°æ®æ—¶é—´èŒƒå›´
- æœ€æ–°æœŸå·
- ç¼“å­˜çŠ¶æ€

### è·å–æœ€æ–°å¼€å¥–ç»“æœ

```bash
# æŸ¥çœ‹æœ€æ–°å¼€å¥–ç»“æœ
python3 dlt_main.py data latest

# ä¸ç”¨æˆ·å·ç æ¯”è¾ƒä¸­å¥–æƒ…å†µ
python3 dlt_main.py data latest --compare
```

**æ¯”è¾ƒåŠŸèƒ½ï¼š**
- äº¤äº’å¼è¾“å…¥å‰åŒº5ä¸ªå·ç å’ŒååŒº2ä¸ªå·ç 
- è‡ªåŠ¨è®¡ç®—ä¸­å¥–ç­‰çº§
- æ˜¾ç¤ºå‘½ä¸­å·ç æ•°é‡

### æ•°æ®æ›´æ–°

```bash
# ä»ä¸­å½©ç½‘æ›´æ–°æ‰€æœ‰æ•°æ®ï¼ˆæ¨èï¼‰
python3 dlt_main.py data update --source zhcw

# ä»500å½©ç¥¨ç½‘æ›´æ–°
python3 dlt_main.py data update --source 500

# æ›´æ–°æŒ‡å®šæœŸæ•°
python3 dlt_main.py data update --source zhcw --periods 100

# å¢é‡æ›´æ–°ï¼ˆåªè·å–æ–°æ•°æ®ï¼‰
python3 dlt_main.py data update --source zhcw
```

**æ•°æ®æºç‰¹ç‚¹ï¼š**
- **ä¸­å½©ç½‘**ï¼šæ•°æ®å®Œæ•´ï¼Œæ›´æ–°åŠæ—¶ï¼Œæ¨èä½¿ç”¨
- **500å½©ç¥¨ç½‘**ï¼šXMLæ¥å£ï¼Œæ•°æ®æ ¼å¼æ ‡å‡†

## ğŸ” æ•°æ®åˆ†æåŠŸèƒ½

### åŸºç¡€åˆ†æ

```bash
# åˆ†ææœ€è¿‘500æœŸæ•°æ®
python3 dlt_main.py analyze -t basic -p 500
```

**åŒ…å«åˆ†æï¼š**
- **é¢‘ç‡åˆ†æ**ï¼šå„å·ç å‡ºç°é¢‘ç‡ç»Ÿè®¡
- **é—æ¼åˆ†æ**ï¼šå·ç é—æ¼æœŸæ•°åˆ†æ
- **å†·çƒ­å·åˆ†æ**ï¼šçƒ­å·ã€å†·å·è¯†åˆ«
- **å’Œå€¼åˆ†æ**ï¼šå‰åŒºã€ååŒºå’Œå€¼åˆ†å¸ƒ
- **ç»Ÿè®¡ç‰¹å¾åˆ†æ**ï¼šå¥‡å¶æ¯”ã€å¤§å°æ¯”ã€è·¨åº¦ã€è¿å·ç­‰

### é«˜çº§åˆ†æ

```bash
# é©¬å°”å¯å¤«é“¾å’Œè´å¶æ–¯åˆ†æ
python3 dlt_main.py analyze -t advanced -p 300
```

**åŒ…å«åˆ†æï¼š**
- **é©¬å°”å¯å¤«é“¾åˆ†æ**ï¼šå·ç çŠ¶æ€è½¬ç§»æ¦‚ç‡
- **è´å¶æ–¯åˆ†æ**ï¼šå…ˆéªŒæ¦‚ç‡å’ŒåéªŒæ¦‚ç‡
- **ç›¸å…³æ€§åˆ†æ**ï¼šå·ç é—´ç›¸å…³å…³ç³»
- **è¶‹åŠ¿ç”Ÿæˆåˆ†æ**ï¼šé¢‘ç‡ã€å†·çƒ­ã€å’Œå€¼è¶‹åŠ¿
- **æ··åˆç­–ç•¥åˆ†æ**ï¼šå¤šç§ç­–ç•¥ç»„åˆ

### ç»¼åˆåˆ†æ

```bash
# ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š
python3 dlt_main.py analyze -t comprehensive -p 1000 --report --save analysis_report.txt

# ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
python3 dlt_main.py analyze -t comprehensive -p 1000 --visualize

# åŒæ—¶ç”ŸæˆæŠ¥å‘Šå’Œå›¾è¡¨
python3 dlt_main.py analyze -t comprehensive -p 1000 --report --visualize --save full_analysis.txt
```

**ç»¼åˆåˆ†æåŒ…å«ï¼š**
- æ‰€æœ‰åŸºç¡€åˆ†æå’Œé«˜çº§åˆ†æ
- è¯¦ç»†çš„æ–‡å­—æŠ¥å‘Š
- å¯è§†åŒ–å›¾è¡¨ï¼ˆé¢‘ç‡åˆ†å¸ƒå›¾ã€èµ°åŠ¿å›¾ï¼‰
- åˆ†æç»“æœç¼“å­˜

## ğŸ¯ å·ç é¢„æµ‹åŠŸèƒ½

### ä¼ ç»Ÿé¢„æµ‹æ–¹æ³•

```bash
# é¢‘ç‡é¢„æµ‹ï¼ˆåŸºäºå†å²é¢‘ç‡ï¼‰
python3 dlt_main.py predict -m frequency -c 5

# å†·çƒ­å·é¢„æµ‹ï¼ˆåŸºäºè¿‘æœŸè¡¨ç°ï¼‰
python3 dlt_main.py predict -m hot_cold -c 3

# é—æ¼é¢„æµ‹ï¼ˆåŸºäºé—æ¼æœŸæ•°ï¼‰
python3 dlt_main.py predict -m missing -c 5
```

### é«˜çº§é¢„æµ‹æ–¹æ³•

```bash
# é©¬å°”å¯å¤«é“¾é¢„æµ‹
python3 dlt_main.py predict -m markov -c 3

# è´å¶æ–¯é¢„æµ‹
python3 dlt_main.py predict -m bayesian -c 5

# é›†æˆé¢„æµ‹ï¼ˆå¤šç§æ–¹æ³•èåˆï¼‰
python3 dlt_main.py predict -m ensemble -c 5

# é©¬å°”å¯å¤«è‡ªå®šä¹‰æœŸæ•°é¢„æµ‹
python3 dlt_main.py predict -m markov_custom -c 3 --analysis-periods 300 --predict-periods 2

# æ··åˆç­–ç•¥é¢„æµ‹
python3 dlt_main.py predict -m mixed_strategy -c 3 --strategy conservative
python3 dlt_main.py predict -m mixed_strategy -c 3 --strategy aggressive
python3 dlt_main.py predict -m mixed_strategy -c 3 --strategy balanced
```

**ç­–ç•¥è¯´æ˜ï¼š**
- **conservative**ï¼šä¿å®ˆç­–ç•¥ï¼ŒåŸºäºé«˜é¢‘å·ç å’Œç¨³å®šæ¨¡å¼
- **aggressive**ï¼šæ¿€è¿›ç­–ç•¥ï¼ŒåŸºäºè¶‹åŠ¿å˜åŒ–å’Œæ–°å…´æ¨¡å¼
- **balanced**ï¼šå¹³è¡¡ç­–ç•¥ï¼Œå„ç§æ–¹æ³•å‡è¡¡ç»„åˆ

### æœºå™¨å­¦ä¹ é¢„æµ‹

```bash
# è¶…çº§é¢„æµ‹å™¨ï¼ˆé›†æˆLSTMã€è’™ç‰¹å¡æ´›ã€èšç±»ç­‰ï¼‰
python3 dlt_main.py predict -m super -c 3

# è‡ªé€‚åº”é¢„æµ‹
python3 dlt_main.py predict -m adaptive -c 5
```

### å¤å¼æŠ•æ³¨é¢„æµ‹

```bash
# å¤å¼æŠ•æ³¨ï¼ˆ8+4ï¼‰
python3 dlt_main.py predict -m compound --front-count 8 --back-count 4

# å¤å¼æŠ•æ³¨ï¼ˆ10+5ï¼‰
python3 dlt_main.py predict -m compound --front-count 10 --back-count 5

# èƒ†æ‹–æŠ•æ³¨
python3 dlt_main.py predict -m duplex
```

**å¤å¼æŠ•æ³¨è¯´æ˜ï¼š**
- è‡ªåŠ¨è®¡ç®—æ€»ç»„åˆæ•°å’ŒæŠ•æ³¨é‡‘é¢
- æ”¯æŒ6-15ä¸ªå‰åŒºå·ç ï¼Œ3-12ä¸ªååŒºå·ç 
- èƒ†æ‹–æŠ•æ³¨æ”¯æŒèƒ†ç +æ‹–ç ç»„åˆ

### ä¿å­˜é¢„æµ‹ç»“æœ

```bash
# ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶
python3 dlt_main.py predict -m ensemble -c 5 --save my_predictions.json

# è‡ªåŠ¨å‘½åä¿å­˜
python3 dlt_main.py predict -m bayesian -c 3 --save
```

**ä¿å­˜ä½ç½®ï¼š** `output/predictions/`

## ğŸ§  è‡ªé€‚åº”å­¦ä¹ åŠŸèƒ½

### å­¦ä¹ è¿‡ç¨‹

```bash
# UCB1ç®—æ³•å­¦ä¹ 
python3 dlt_main.py learn -s 100 -t 1000 --algorithm ucb1 --save ucb1_results.json

# Epsilon-Greedyç®—æ³•å­¦ä¹ 
python3 dlt_main.py learn -s 100 -t 1000 --algorithm epsilon_greedy --save eg_results.json

# Thompson Samplingç®—æ³•å­¦ä¹ 
python3 dlt_main.py learn -s 100 -t 1000 --algorithm thompson_sampling --save ts_results.json
```

**å‚æ•°è¯´æ˜ï¼š**
- `-s, --start`ï¼šèµ·å§‹æœŸæ•°
- `-t, --test`ï¼šæµ‹è¯•æœŸæ•°
- `--algorithm`ï¼šå­¦ä¹ ç®—æ³•
- `--save`ï¼šä¿å­˜å­¦ä¹ ç»“æœ

**å­¦ä¹ è¿‡ç¨‹ï¼š**
1. å¤šè‡‚è€è™æœºç®—æ³•é€‰æ‹©æœ€ä¼˜é¢„æµ‹å™¨
2. å®æ—¶è®¡ç®—ä¸­å¥–ç‡å’Œå‡†ç¡®ç‡
3. åŠ¨æ€è°ƒæ•´ç®—æ³•æƒé‡
4. ä¿å­˜å­¦ä¹ å†å²å’Œæœ€ä¼˜é…ç½®

### æ™ºèƒ½é¢„æµ‹

```bash
# åŸºäºå­¦ä¹ ç»“æœçš„æ™ºèƒ½é¢„æµ‹
python3 dlt_main.py smart -c 5 --load output/learning/learning_ucb1_20250712_165747.json

# ä½¿ç”¨é»˜è®¤é…ç½®é¢„æµ‹
python3 dlt_main.py smart -c 3
```

**æ™ºèƒ½é¢„æµ‹ç‰¹ç‚¹ï¼š**
- ä½¿ç”¨å­¦ä¹ åˆ°çš„æœ€ä¼˜ç®—æ³•ç»„åˆ
- åŠ¨æ€æƒé‡åˆ†é…
- é«˜ç½®ä¿¡åº¦é¢„æµ‹

## âš™ï¸ å‚æ•°ä¼˜åŒ–åŠŸèƒ½

```bash
# åŸºç¡€å‚æ•°ä¼˜åŒ–
python3 dlt_main.py optimize -t 100 -r 10

# é«˜çº§å‚æ•°ä¼˜åŒ–å¹¶ä¿å­˜ç»“æœ
python3 dlt_main.py optimize -t 500 -r 20 --save optimization_results.json
```

**ä¼˜åŒ–è¿‡ç¨‹ï¼š**
1. éšæœºæœç´¢å‚æ•°ç©ºé—´
2. æµ‹è¯•ä¸åŒå‚æ•°ç»„åˆ
3. è¯„ä¼°é¢„æµ‹æ€§èƒ½
4. è‡ªåŠ¨åº”ç”¨æœ€ä½³å‚æ•°

**ä¿å­˜ä½ç½®ï¼š** `output/optimization/`

## ğŸ“ˆ å†å²å›æµ‹åŠŸèƒ½

```bash
# é¢‘ç‡é¢„æµ‹å›æµ‹
python3 dlt_main.py backtest -s 100 -t 500 -m frequency

# é›†æˆé¢„æµ‹å›æµ‹
python3 dlt_main.py backtest -s 100 -t 1000 -m ensemble

# é©¬å°”å¯å¤«é“¾å›æµ‹
python3 dlt_main.py backtest -s 200 -t 800 -m markov
```

**å›æµ‹ç»“æœï¼š**
- æ€»é¢„æµ‹æœŸæ•°å’Œä¸­å¥–æœŸæ•°
- å„ç­‰çº§ä¸­å¥–åˆ†å¸ƒ
- ä¸­å¥–ç‡ç»Ÿè®¡
- ç®—æ³•æ€§èƒ½è¯„ä¼°

## ğŸ› ï¸ ç³»ç»Ÿç®¡ç†åŠŸèƒ½

### ç¼“å­˜ç®¡ç†

```bash
# æŸ¥çœ‹ç¼“å­˜ä¿¡æ¯
python3 dlt_main.py system cache info

# æ¸…ç†æ‰€æœ‰ç¼“å­˜
python3 dlt_main.py system cache clear --type all

# æ¸…ç†ç‰¹å®šç±»å‹ç¼“å­˜
python3 dlt_main.py system cache clear --type models
python3 dlt_main.py system cache clear --type analysis
python3 dlt_main.py system cache clear --type data
```

### ç‰ˆæœ¬ä¿¡æ¯

```bash
# æ˜¾ç¤ºç³»ç»Ÿç‰ˆæœ¬å’Œæ¨¡å—ä¿¡æ¯
python3 dlt_main.py version
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶ç®¡ç†

ç³»ç»Ÿè‡ªåŠ¨å°†ä¸åŒç±»å‹çš„è¾“å‡ºæ–‡ä»¶ä¿å­˜åˆ°å¯¹åº”ç›®å½•ï¼š

```
output/
â”œâ”€â”€ predictions/          # é¢„æµ‹ç»“æœæ–‡ä»¶
â”œâ”€â”€ learning/            # å­¦ä¹ ç»“æœæ–‡ä»¶
â”œâ”€â”€ optimization/        # å‚æ•°ä¼˜åŒ–ç»“æœ
â”œâ”€â”€ reports/            # åˆ†ææŠ¥å‘Šæ–‡ä»¶
â”œâ”€â”€ visualization/      # å¯è§†åŒ–å›¾è¡¨
â””â”€â”€ backtest/          # å›æµ‹ç»“æœæ–‡ä»¶
```

**æ–‡ä»¶å‘½åè§„åˆ™ï¼š**
- è‡ªåŠ¨æ·»åŠ æ—¶é—´æˆ³
- åŒ…å«æ–¹æ³•å’Œå‚æ•°ä¿¡æ¯
- æ”¯æŒJSONå’ŒTXTæ ¼å¼

## ğŸ¨ å¯è§†åŒ–åŠŸèƒ½

```bash
# ç”Ÿæˆé¢‘ç‡åˆ†å¸ƒå›¾å’Œèµ°åŠ¿å›¾
python3 dlt_main.py analyze -t basic -p 500 --visualize

# ç”Ÿæˆå®Œæ•´å¯è§†åŒ–æŠ¥å‘Š
python3 dlt_main.py analyze -t comprehensive -p 1000 --visualize
```

**å›¾è¡¨ç±»å‹ï¼š**
- **é¢‘ç‡åˆ†å¸ƒå›¾**ï¼šå‰åŒºå’ŒååŒºå·ç é¢‘ç‡æŸ±çŠ¶å›¾
- **èµ°åŠ¿å›¾**ï¼šå’Œå€¼å˜åŒ–è¶‹åŠ¿çº¿å›¾
- **ç»Ÿè®¡å›¾è¡¨**ï¼šå¤šç»´åº¦æ•°æ®å¯è§†åŒ–

**ä¿å­˜ä½ç½®ï¼š** `output/visualization/`

## âš¡ æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜æœºåˆ¶

- **æ™ºèƒ½ç¼“å­˜**ï¼šè‡ªåŠ¨ç¼“å­˜åˆ†æç»“æœå’Œæ¨¡å‹
- **å¢é‡æ›´æ–°**ï¼šåªå¤„ç†æ–°å¢æ•°æ®
- **å»¶è¿ŸåŠ è½½**ï¼šæŒ‰éœ€åŠ è½½æ¨¡å—ï¼Œæå‡å¯åŠ¨é€Ÿåº¦

### å¹¶è¡Œå¤„ç†

- **å¤šçº¿ç¨‹**ï¼šæ”¯æŒå¤šçº¿ç¨‹æ•°æ®å¤„ç†
- **è¿›åº¦æ˜¾ç¤º**ï¼šå®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦
- **ä¸­æ–­æ¢å¤**ï¼šæ”¯æŒCtrl+Cä¸­æ–­å’Œæ¢å¤

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ•°æ®åŠ è½½å¤±è´¥**
   ```bash
   # æ¸…ç†ç¼“å­˜é‡æ–°åŠ è½½
   python3 dlt_main.py system cache clear --type data
   python3 dlt_main.py data update --source zhcw
   ```

2. **é¢„æµ‹å¤±è´¥**
   ```bash
   # æ£€æŸ¥æ•°æ®çŠ¶æ€
   python3 dlt_main.py data status
   
   # é‡æ–°åˆ†ææ•°æ®
   python3 dlt_main.py analyze -t basic -p 100
   ```

3. **å†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘åˆ†ææœŸæ•°
   python3 dlt_main.py analyze -t basic -p 200
   
   # æ¸…ç†ç¼“å­˜
   python3 dlt_main.py system cache clear --type all
   ```

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
tail -f logs/dlt_predictor.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/errors.log
```

## ğŸ“ æŠ€æœ¯æ”¯æŒ

- **é¡¹ç›®æ–‡æ¡£**ï¼šREADME.md
- **é¡¹ç›®ç»“æ„**ï¼šPROJECT_STRUCTURE.md
- **ä½¿ç”¨æŒ‡å—**ï¼šUSAGE_GUIDE.mdï¼ˆæœ¬æ–‡ä»¶ï¼‰
- **æ—¥å¿—æ–‡ä»¶**ï¼šlogs/ç›®å½•ä¸‹çš„æ—¥å¿—æ–‡ä»¶

## ğŸ§® ç®—æ³•è¯¦è§£

### ä¼ ç»Ÿç®—æ³•

#### é¢‘ç‡åˆ†æç®—æ³•
```python
# åŸºäºå†å²é¢‘ç‡çš„é¢„æµ‹åŸç†
frequency_score = count(number) / total_periods
prediction_probability = frequency_score / sum(all_frequency_scores)
```

**é€‚ç”¨åœºæ™¯ï¼š**
- é•¿æœŸç¨³å®šé¢„æµ‹
- åŸºç¡€å·ç ç­›é€‰
- ä¸å…¶ä»–ç®—æ³•ç»„åˆä½¿ç”¨

#### å†·çƒ­å·åˆ†æç®—æ³•
```python
# è¿‘æœŸè¡¨ç°è¯„ä¼°
recent_periods = 50  # å¯é…ç½®
hot_threshold = average_frequency * 1.2
cold_threshold = average_frequency * 0.8
```

**åˆ†ç±»æ ‡å‡†ï¼š**
- **çƒ­å·**ï¼šè¿‘æœŸå‡ºç°é¢‘ç‡é«˜äºå¹³å‡å€¼20%
- **æ¸©å·**ï¼šè¿‘æœŸå‡ºç°é¢‘ç‡æ¥è¿‘å¹³å‡å€¼
- **å†·å·**ï¼šè¿‘æœŸå‡ºç°é¢‘ç‡ä½äºå¹³å‡å€¼20%

#### é—æ¼åˆ†æç®—æ³•
```python
# é—æ¼æœŸæ•°è®¡ç®—
missing_periods = current_period - last_appearance_period
expected_appearance = total_periods / number_count
deviation = missing_periods - expected_appearance
```

### é«˜çº§ç®—æ³•

#### é©¬å°”å¯å¤«é“¾ç®—æ³•
```python
# çŠ¶æ€è½¬ç§»æ¦‚ç‡çŸ©é˜µ
P(X_t+1 = j | X_t = i) = transition_count(i->j) / total_transitions(i)
```

**æ ¸å¿ƒæ€æƒ³ï¼š**
- å·ç å‡ºç°å…·æœ‰è®°å¿†æ€§
- å½“å‰çŠ¶æ€å½±å“ä¸‹ä¸€çŠ¶æ€
- é€šè¿‡è½¬ç§»æ¦‚ç‡é¢„æµ‹

**è‡ªå®šä¹‰æœŸæ•°é¢„æµ‹ï¼š**
- æ”¯æŒæŒ‡å®šåˆ†ææœŸæ•°ï¼ˆ100-3000æœŸï¼‰
- æ”¯æŒå¤šæœŸè¿ç»­é¢„æµ‹
- åŒ…å«ç¨³å®šæ€§è¯„åˆ†

#### è´å¶æ–¯åˆ†æç®—æ³•
```python
# è´å¶æ–¯å…¬å¼åº”ç”¨
P(A|B) = P(B|A) * P(A) / P(B)
posterior = likelihood * prior / evidence
```

**åº”ç”¨åœºæ™¯ï¼š**
- æ¡ä»¶æ¦‚ç‡è®¡ç®—
- å…ˆéªŒçŸ¥è¯†èåˆ
- ä¸ç¡®å®šæ€§é‡åŒ–

#### æ··åˆç­–ç•¥ç®—æ³•
```python
# æƒé‡åˆ†é…ç­–ç•¥
conservative_weights = {
    'frequency': 0.4, 'markov': 0.3,
    'bayesian': 0.2, 'correlation': 0.1
}
aggressive_weights = {
    'frequency': 0.1, 'markov': 0.4,
    'bayesian': 0.3, 'correlation': 0.2
}
```

### æœºå™¨å­¦ä¹ ç®—æ³•

#### LSTMæ·±åº¦å­¦ä¹ 
```python
# ç½‘ç»œç»“æ„
model = Sequential([
    LSTM(50, return_sequences=True),
    LSTM(50, return_sequences=False),
    Dense(25),
    Dense(7)  # 5å‰åŒº + 2ååŒº
])
```

**ç‰¹ç‚¹ï¼š**
- é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ
- æ—¶åºæ¨¡å¼å­¦ä¹ 
- éçº¿æ€§å…³ç³»æ•è·

#### è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ
```python
# éšæœºæ¨¡æ‹Ÿè¿‡ç¨‹
for simulation in range(num_simulations):
    random_combination = generate_random_combination()
    score = evaluate_combination(random_combination)
    if score > threshold:
        candidates.append(random_combination)
```

#### èšç±»åˆ†æ
```python
# K-meansèšç±»
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=5)
clusters = kmeans.fit_predict(historical_data)
```

**èšç±»æ–¹æ³•ï¼š**
- K-meansèšç±»
- å±‚æ¬¡èšç±»
- DBSCANèšç±»
- é«˜æ–¯æ··åˆæ¨¡å‹
- è°±èšç±»

### è‡ªé€‚åº”å­¦ä¹ ç®—æ³•

#### å¤šè‡‚è€è™æœºç®—æ³•

**UCB1ç®—æ³•ï¼š**
```python
# Upper Confidence Bound
ucb_score = average_reward + sqrt(2 * log(total_trials) / arm_trials)
```

**Epsilon-Greedyç®—æ³•ï¼š**
```python
# æ¢ç´¢ä¸åˆ©ç”¨å¹³è¡¡
if random() < epsilon:
    action = random_choice()  # æ¢ç´¢
else:
    action = best_choice()    # åˆ©ç”¨
```

**Thompson Samplingç®—æ³•ï¼š**
```python
# è´å¶æ–¯æ–¹æ³•
beta_distribution = Beta(alpha + successes, beta + failures)
sample_value = beta_distribution.sample()
```

## ğŸ¯ é«˜çº§ç”¨æ³•ç¤ºä¾‹

### æ‰¹é‡é¢„æµ‹è„šæœ¬

```bash
#!/bin/bash
# æ‰¹é‡é¢„æµ‹è„šæœ¬

# ä¼ ç»Ÿæ–¹æ³•é¢„æµ‹
python3 dlt_main.py predict -m frequency -c 5 --save frequency_pred.json
python3 dlt_main.py predict -m hot_cold -c 5 --save hot_cold_pred.json
python3 dlt_main.py predict -m missing -c 5 --save missing_pred.json

# é«˜çº§æ–¹æ³•é¢„æµ‹
python3 dlt_main.py predict -m markov -c 5 --save markov_pred.json
python3 dlt_main.py predict -m bayesian -c 5 --save bayesian_pred.json
python3 dlt_main.py predict -m ensemble -c 5 --save ensemble_pred.json

# æ··åˆç­–ç•¥é¢„æµ‹
python3 dlt_main.py predict -m mixed_strategy -c 5 --strategy conservative --save conservative_pred.json
python3 dlt_main.py predict -m mixed_strategy -c 5 --strategy aggressive --save aggressive_pred.json
python3 dlt_main.py predict -m mixed_strategy -c 5 --strategy balanced --save balanced_pred.json

echo "æ‰¹é‡é¢„æµ‹å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ output/predictions/ ç›®å½•"
```

### è‡ªåŠ¨åŒ–å­¦ä¹ è„šæœ¬

```bash
#!/bin/bash
# è‡ªåŠ¨åŒ–å­¦ä¹ è„šæœ¬

# å¤šç§ç®—æ³•å­¦ä¹ 
algorithms=("ucb1" "epsilon_greedy" "thompson_sampling")

for algo in "${algorithms[@]}"; do
    echo "å¼€å§‹ $algo ç®—æ³•å­¦ä¹ ..."
    python3 dlt_main.py learn -s 100 -t 1000 --algorithm $algo --save ${algo}_results.json

    echo "åŸºäº $algo ç»“æœè¿›è¡Œæ™ºèƒ½é¢„æµ‹..."
    python3 dlt_main.py smart -c 5 --load output/learning/${algo}_results.json --save ${algo}_smart_pred.json
done

echo "è‡ªåŠ¨åŒ–å­¦ä¹ å®Œæˆ"
```

### æ€§èƒ½å¯¹æ¯”è„šæœ¬

```bash
#!/bin/bash
# ç®—æ³•æ€§èƒ½å¯¹æ¯”è„šæœ¬

methods=("frequency" "hot_cold" "missing" "markov" "bayesian" "ensemble")

echo "å¼€å§‹ç®—æ³•æ€§èƒ½å›æµ‹å¯¹æ¯”..."

for method in "${methods[@]}"; do
    echo "å›æµ‹ $method ç®—æ³•..."
    python3 dlt_main.py backtest -s 100 -t 500 -m $method > backtest_${method}.log
done

echo "æ€§èƒ½å¯¹æ¯”å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ backtest_*.log æ–‡ä»¶ä¸­"
```

### å®šæ—¶æ•°æ®æ›´æ–°

```bash
#!/bin/bash
# å®šæ—¶æ•°æ®æ›´æ–°è„šæœ¬ï¼ˆå¯é…ç½®crontabï¼‰

# æ£€æŸ¥ç½‘ç»œè¿æ¥
if ping -c 1 www.zhcw.com &> /dev/null; then
    echo "$(date): å¼€å§‹æ›´æ–°æ•°æ®..."

    # æ›´æ–°æ•°æ®
    python3 dlt_main.py data update --source zhcw

    # æ¸…ç†æ—§ç¼“å­˜
    python3 dlt_main.py system cache clear --type analysis

    # é‡æ–°åˆ†æ
    python3 dlt_main.py analyze -t comprehensive -p 500 --report --save daily_analysis.txt

    echo "$(date): æ•°æ®æ›´æ–°å®Œæˆ"
else
    echo "$(date): ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè·³è¿‡æ›´æ–°"
fi
```

### Python API ä½¿ç”¨

```python
#!/usr/bin/env python3
# Python API ä½¿ç”¨ç¤ºä¾‹

from core_modules import data_manager, cache_manager
from analyzer_modules import comprehensive_analyzer
from predictor_modules import get_advanced_predictor

# è·å–æ•°æ®
df = data_manager.get_data()
print(f"æ•°æ®æ€»æœŸæ•°: {len(df)}")

# è¿›è¡Œåˆ†æ
analysis_result = comprehensive_analyzer.comprehensive_analysis(500)
print("åˆ†æå®Œæˆ")

# è¿›è¡Œé¢„æµ‹
predictor = get_advanced_predictor()
predictions = predictor.ensemble_predict(5)
print(f"ç”Ÿæˆ {len(predictions)} æ³¨é¢„æµ‹")

# æ˜¾ç¤ºé¢„æµ‹ç»“æœ
for i, (front, back) in enumerate(predictions):
    front_str = ' '.join([str(b).zfill(2) for b in front])
    back_str = ' '.join([str(b).zfill(2) for b in back])
    print(f"ç¬¬ {i+1} æ³¨: {front_str} + {back_str}")
```

## ğŸ“Š è¾“å‡ºæ ¼å¼è¯´æ˜

### é¢„æµ‹ç»“æœæ ¼å¼

```json
{
  "index": 1,
  "front_balls": [5, 12, 18, 23, 31],
  "back_balls": [3, 8],
  "method": "ensemble",
  "confidence": 0.756,
  "timestamp": "2025-07-12T16:30:00"
}
```

### å­¦ä¹ ç»“æœæ ¼å¼

```json
{
  "algorithm": "ucb1",
  "total_periods": 1000,
  "win_rate": 0.045,
  "best_predictor": "advanced_markov",
  "predictor_weights": {
    "traditional_frequency": 0.15,
    "advanced_markov": 0.35,
    "advanced_bayesian": 0.25,
    "super_predictor": 0.25
  },
  "learning_history": [...],
  "timestamp": "2025-07-12T16:30:00"
}
```

### åˆ†ææŠ¥å‘Šæ ¼å¼

```
å¤§ä¹é€ç»¼åˆåˆ†ææŠ¥å‘Š
==================

åˆ†ææœŸæ•°: 500æœŸ
åˆ†ææ—¶é—´: 2025-07-12 16:30:00

åŸºç¡€åˆ†æ
--------
é¢‘ç‡åˆ†æ: å®Œæˆ
- å‰åŒºæœ€é«˜é¢‘å·ç : 07 (å‡ºç°32æ¬¡)
- ååŒºæœ€é«˜é¢‘å·ç : 05 (å‡ºç°28æ¬¡)

é—æ¼åˆ†æ: å®Œæˆ
- å‰åŒºæœ€å¤§é—æ¼: 23 (é—æ¼45æœŸ)
- ååŒºæœ€å¤§é—æ¼: 11 (é—æ¼38æœŸ)

ç»Ÿè®¡ç‰¹å¾åˆ†æ: å®Œæˆ
- å¥‡å¶æ¯”åˆ†å¸ƒ: 3:2 (35%), 2:3 (28%), 4:1 (20%)
- å¤§å°æ¯”åˆ†å¸ƒ: 3:2 (32%), 2:3 (30%), 4:1 (18%)
- å¹³å‡è·¨åº¦: 24.5
- å¹³å‡å’Œå€¼: 89.3

é«˜çº§åˆ†æ
--------
é©¬å°”å¯å¤«é“¾åˆ†æ: å®Œæˆ
- è½¬ç§»æ¦‚ç‡çŸ©é˜µ: 35x35 (å‰åŒº)
- æœ€é«˜è½¬ç§»æ¦‚ç‡: 07->12 (0.156)

è´å¶æ–¯åˆ†æ: å®Œæˆ
- æ¡ä»¶æ¦‚ç‡è®¡ç®—å®Œæˆ
- åéªŒæ¦‚ç‡æ›´æ–°å®Œæˆ

è¶‹åŠ¿åˆ†æ: å®Œæˆ
- é¢‘ç‡è¶‹åŠ¿: ä¸Šå‡è¶‹åŠ¿å·ç  [07, 12, 23]
- å’Œå€¼è¶‹åŠ¿: æ³¢åŠ¨ä¸Šå‡

æ··åˆç­–ç•¥åˆ†æ: å®Œæˆ
- ä¿å®ˆç­–ç•¥æ¨è: [05, 07, 12, 18, 23] + [03, 08]
- æ¿€è¿›ç­–ç•¥æ¨è: [02, 15, 28, 31, 34] + [01, 11]
- å¹³è¡¡ç­–ç•¥æ¨è: [07, 12, 18, 23, 28] + [03, 08]

åˆ†æå®Œæˆæ—¶é—´: 2025-07-12 16:35:00
```

---

**ğŸ¯ å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿ v2.0 - è®©é¢„æµ‹æ›´æ™ºèƒ½ï¼**
