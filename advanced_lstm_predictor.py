#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é«˜çº§LSTMé¢„æµ‹å™¨
åŸºäºæ·±åº¦å­¦ä¹ çš„æ—¶é—´åºåˆ—é¢„æµ‹
"""

import os
import numpy as np
import pandas as pd
from typing import List, Tuple, Dict
from datetime import datetime

# æ£€æŸ¥TensorFlowå¯ç”¨æ€§
try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential, Model
    from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Attention, MultiHeadAttention
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
    from sklearn.preprocessing import MinMaxScaler
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False

from core_modules import logger_manager, data_manager, cache_manager


class AdvancedLSTMPredictor:
    """é«˜çº§LSTMé¢„æµ‹å™¨"""
    
    def __init__(self, data_file="data/dlt_data_all.csv"):
        if not TENSORFLOW_AVAILABLE:
            raise ImportError("TensorFlowæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨LSTMé¢„æµ‹å™¨")
        
        self.data_file = data_file
        self.df = data_manager.get_data()
        self.sequence_length = 20  # æ—¶é—´åºåˆ—é•¿åº¦
        self.feature_dim = 21  # ç‰¹å¾ç»´åº¦
        
        # æ¨¡å‹ç»„ä»¶
        self.scaler = MinMaxScaler()
        self.model = None
        self.is_trained = False
        
        if self.df is None:
            logger_manager.error("æ•°æ®æœªåŠ è½½")
    
    def _extract_features(self, df_subset) -> np.ndarray:
        """æå–æ·±åº¦ç‰¹å¾"""
        features = []
        
        for _, row in df_subset.iterrows():
            front_balls, back_balls = data_manager.parse_balls(row)
            
            # åŸºç¡€ç‰¹å¾ (7ç»´)
            feature_vector = front_balls + back_balls
            
            # ç»Ÿè®¡ç‰¹å¾ (8ç»´)
            front_sum = sum(front_balls)
            back_sum = sum(back_balls)
            total_sum = front_sum + back_sum
            front_mean = np.mean(front_balls)
            back_mean = np.mean(back_balls)
            front_std = np.std(front_balls)
            back_std = np.std(back_balls)
            span = max(front_balls) - min(front_balls)
            
            # æ¨¡å¼ç‰¹å¾ (6ç»´)
            odd_count = sum(1 for x in front_balls if x % 2 == 1)
            even_count = 5 - odd_count
            big_count = sum(1 for x in front_balls if x > 17)  # å¤§å·(18-35)
            small_count = 5 - big_count  # å°å·(1-17)
            consecutive_count = self._count_consecutive(front_balls)
            prime_count = sum(1 for x in front_balls if self._is_prime(x))
            
            # ç»„åˆæ‰€æœ‰ç‰¹å¾
            all_features = (
                feature_vector +  # 7ç»´
                [front_sum, back_sum, total_sum, front_mean, back_mean, front_std, back_std, span] +  # 8ç»´
                [odd_count, even_count, big_count, small_count, consecutive_count, prime_count]  # 6ç»´
            )
            
            features.append(all_features)
        
        return np.array(features)
    
    def _count_consecutive(self, numbers):
        """è®¡ç®—è¿ç»­å·ç æ•°é‡"""
        sorted_nums = sorted(numbers)
        consecutive = 0
        for i in range(len(sorted_nums) - 1):
            if sorted_nums[i+1] - sorted_nums[i] == 1:
                consecutive += 1
        return consecutive
    
    def _is_prime(self, n):
        """åˆ¤æ–­æ˜¯å¦ä¸ºè´¨æ•°"""
        if n < 2:
            return False
        for i in range(2, int(n**0.5) + 1):
            if n % i == 0:
                return False
        return True
    
    def _prepare_sequences(self, features):
        """å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®"""
        X, y = [], []
        
        for i in range(self.sequence_length, len(features)):
            X.append(features[i-self.sequence_length:i])
            y.append(features[i][:7])  # åªé¢„æµ‹å‰5ä¸ªå‰åŒºå·ç å’Œ2ä¸ªååŒºå·ç 
        
        return np.array(X), np.array(y)
    
    def _build_model(self):
        """æ„å»ºLSTMæ¨¡å‹"""
        model = Sequential([
            # ç¬¬ä¸€å±‚LSTM
            LSTM(128, return_sequences=True, input_shape=(self.sequence_length, self.feature_dim)),
            Dropout(0.2),
            
            # ç¬¬äºŒå±‚LSTM
            LSTM(64, return_sequences=True),
            Dropout(0.2),
            
            # ç¬¬ä¸‰å±‚LSTM
            LSTM(32, return_sequences=False),
            Dropout(0.2),
            
            # å…¨è¿æ¥å±‚
            Dense(64, activation='relu'),
            Dropout(0.2),
            Dense(32, activation='relu'),
            
            # è¾“å‡ºå±‚
            Dense(7, activation='sigmoid')  # 5å‰åŒº+2ååŒºï¼Œå½’ä¸€åŒ–åˆ°0-1
        ])
        
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        
        return model
    
    def train_model(self, epochs=100, validation_split=0.2):
        """è®­ç»ƒLSTMæ¨¡å‹"""
        logger_manager.info("å¼€å§‹è®­ç»ƒLSTMæ¨¡å‹...")
        
        # æå–ç‰¹å¾
        features = self._extract_features(self.df)
        
        # æ•°æ®æ ‡å‡†åŒ–
        features_scaled = self.scaler.fit_transform(features)
        
        # å‡†å¤‡åºåˆ—æ•°æ®
        X, y = self._prepare_sequences(features_scaled)
        
        if len(X) == 0:
            logger_manager.error("åºåˆ—æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
            return False
        
        # æ„å»ºæ¨¡å‹
        self.model = self._build_model()
        
        # è®¾ç½®å›è°ƒ
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.5, patience=5, min_lr=0.0001)
        ]
        
        # è®­ç»ƒæ¨¡å‹
        history = self.model.fit(
            X, y,
            epochs=epochs,
            validation_split=validation_split,
            batch_size=32,
            callbacks=callbacks,
            verbose=1
        )
        
        self.is_trained = True
        logger_manager.info("LSTMæ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        return True
    
    def lstm_predict(self, count=1) -> List[Tuple[List[int], List[int]]]:
        """LSTMé¢„æµ‹"""
        if not self.is_trained:
            logger_manager.info("æ¨¡å‹æœªè®­ç»ƒï¼Œå¼€å§‹è®­ç»ƒ...")
            if not self.train_model():
                logger_manager.error("æ¨¡å‹è®­ç»ƒå¤±è´¥")
                return []
        
        # è·å–æœ€è¿‘çš„åºåˆ—æ•°æ®
        recent_features = self._extract_features(self.df.head(self.sequence_length))
        recent_scaled = self.scaler.transform(recent_features)
        
        # å‡†å¤‡è¾“å…¥åºåˆ—
        input_sequence = recent_scaled.reshape(1, self.sequence_length, self.feature_dim)
        
        predictions = []
        
        for _ in range(count):
            # é¢„æµ‹
            pred_scaled = self.model.predict(input_sequence, verbose=0)
            
            # åæ ‡å‡†åŒ–
            # åˆ›å»ºå®Œæ•´ç‰¹å¾å‘é‡ç”¨äºåæ ‡å‡†åŒ–
            full_pred = np.zeros((1, self.feature_dim))
            full_pred[0, :7] = pred_scaled[0]
            pred_original = self.scaler.inverse_transform(full_pred)[0, :7]
            
            # è½¬æ¢ä¸ºå½©ç¥¨å·ç 
            front_balls = [max(1, min(35, int(round(x)))) for x in pred_original[:5]]
            back_balls = [max(1, min(12, int(round(x)))) for x in pred_original[5:7]]
            
            # ç¡®ä¿å·ç å”¯ä¸€æ€§
            front_balls = self._ensure_unique_numbers(front_balls, 1, 35, 5)
            back_balls = self._ensure_unique_numbers(back_balls, 1, 12, 2)
            
            predictions.append((sorted(front_balls), sorted(back_balls)))
            
            # æ›´æ–°è¾“å…¥åºåˆ—ç”¨äºä¸‹ä¸€æ¬¡é¢„æµ‹
            new_feature = np.concatenate([pred_original, recent_scaled[-1, 7:]])
            input_sequence = np.roll(input_sequence, -1, axis=1)
            input_sequence[0, -1] = new_feature
        
        return predictions
    
    def _ensure_unique_numbers(self, numbers, min_val, max_val, target_count):
        """ç¡®ä¿å·ç å”¯ä¸€æ€§"""
        unique_numbers = list(set(numbers))
        
        # å¦‚æœæ•°é‡ä¸è¶³ï¼Œéšæœºè¡¥å……
        while len(unique_numbers) < target_count:
            candidate = np.random.randint(min_val, max_val + 1)
            if candidate not in unique_numbers:
                unique_numbers.append(candidate)
        
        return unique_numbers[:target_count]


# å…¼å®¹æ€§æ£€æŸ¥
if not TENSORFLOW_AVAILABLE:
    class AdvancedLSTMPredictor:
        def __init__(self, *args, **kwargs):
            raise ImportError("TensorFlowæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨LSTMé¢„æµ‹å™¨")
        
        def lstm_predict(self, *args, **kwargs):
            return []


if __name__ == "__main__":
    # æµ‹è¯•LSTMé¢„æµ‹å™¨
    if TENSORFLOW_AVAILABLE:
        print("ğŸ§  æµ‹è¯•LSTMé¢„æµ‹å™¨...")
        predictor = AdvancedLSTMPredictor()
        
        # è®­ç»ƒæ¨¡å‹
        predictor.train_model(epochs=50)
        
        # è¿›è¡Œé¢„æµ‹
        predictions = predictor.lstm_predict(3)
        
        print("LSTMé¢„æµ‹ç»“æœ:")
        for i, (front, back) in enumerate(predictions):
            front_str = ' '.join([str(b).zfill(2) for b in front])
            back_str = ' '.join([str(b).zfill(2) for b in back])
            print(f"ç¬¬ {i+1} æ³¨: {front_str} + {back_str}")
    else:
        print("âŒ TensorFlowæœªå®‰è£…ï¼Œæ— æ³•æµ‹è¯•LSTMé¢„æµ‹å™¨")