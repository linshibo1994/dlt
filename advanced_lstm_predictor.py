#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é«˜çº§LSTMé¢„æµ‹å™¨
åŸºäºenhanced_deep_learningæ¨¡å—çš„LSTMç¥ç»ç½‘ç»œé¢„æµ‹å™¨åŒ…è£…å™¨
æä¾›ä¸ä¸»ç¨‹åºå…¼å®¹çš„æ¥å£
"""

import os
import sys
import numpy as np
import pandas as pd
from typing import List, Tuple, Dict, Any, Optional
from datetime import datetime

# æ£€æŸ¥TensorFlowå¯ç”¨æ€§
try:
    import tensorflow as tf
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from core_modules import logger_manager, data_manager, cache_manager

# å¯¼å…¥enhanced_deep_learningæ¨¡å—
if TENSORFLOW_AVAILABLE:
    try:
        from enhanced_deep_learning.models.lstm_predictor import LSTMPredictor
        from enhanced_deep_learning.models.base_model import ModelMetadata
        ENHANCED_LSTM_AVAILABLE = True
    except ImportError:
        ENHANCED_LSTM_AVAILABLE = False
        logger_manager.warning("Enhanced LSTMæ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€åŒ–å®ç°")
else:
    ENHANCED_LSTM_AVAILABLE = False


class AdvancedLSTMPredictor:
    """é«˜çº§LSTMé¢„æµ‹å™¨
    
    åŸºäºenhanced_deep_learningæ¨¡å—çš„LSTMç¥ç»ç½‘ç»œé¢„æµ‹å™¨
    æä¾›å®Œæ•´çš„æ·±åº¦å­¦ä¹ é¢„æµ‹åŠŸèƒ½
    """
    
    def __init__(self, data_file: str = None):
        """
        åˆå§‹åŒ–é«˜çº§LSTMé¢„æµ‹å™¨
        
        Args:
            data_file: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ•°æ®
        """
        if not TENSORFLOW_AVAILABLE:
            raise ImportError("TensorFlowæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨LSTMé¢„æµ‹å™¨")
            
        self.data_file = data_file
        self.lstm_predictor = None
        self.model_cache_dir = os.path.join('cache', 'models', 'lstm')
        
        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(self.model_cache_dir, exist_ok=True)
        
        # åˆå§‹åŒ–LSTMé¢„æµ‹å™¨
        self._init_lstm_predictor()
        
        logger_manager.info("é«˜çº§LSTMé¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_lstm_predictor(self):
        """åˆå§‹åŒ–LSTMé¢„æµ‹å™¨"""
        if ENHANCED_LSTM_AVAILABLE:
            # ä½¿ç”¨enhanced_deep_learningæ¨¡å—çš„LSTMå®ç°
            config = {
                'sequence_length': 50,
                'lstm_units': [256, 128, 64],
                'dropout_rate': 0.3,
                'learning_rate': 0.0005,
                'batch_size': 64,
                'epochs': 200,
                'use_bidirectional': True,
                'use_attention': True,
                'use_residual': True,
                'attention_heads': 8,
                'l1_reg': 0.005,
                'l2_reg': 0.005,
                'gradient_clip_norm': 1.0
            }
            
            metadata = ModelMetadata(
                name="AdvancedLSTMPredictor",
                version="2.0.0",
                description="é«˜çº§LSTMç¥ç»ç½‘ç»œé¢„æµ‹å™¨",
                dependencies=["tensorflow", "scikit-learn", "numpy", "pandas"]
            )
            
            self.lstm_predictor = LSTMPredictor(config=config, metadata=metadata)
            logger_manager.info("ä½¿ç”¨Enhanced LSTMå®ç°")
        else:
            # å¦‚æœenhancedæ¨¡å—ä¸å¯ç”¨ï¼ŒæŠ›å‡ºé”™è¯¯
            raise ImportError("Enhanced LSTMæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºLSTMé¢„æµ‹å™¨")
    
    def lstm_predict(self, count: int = 3, periods: int = 500) -> List[Tuple[List[int], List[int]]]:
        """
        ä½¿ç”¨LSTMæ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        Args:
            count: é¢„æµ‹æ•°é‡
            periods: ä½¿ç”¨çš„å†å²æ•°æ®æœŸæ•°
            
        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(å‰åŒºå·ç åˆ—è¡¨, ååŒºå·ç åˆ—è¡¨)
        """
        try:
            logger_manager.info(f"å¼€å§‹LSTMé¢„æµ‹: æ³¨æ•°={count}, åˆ†ææœŸæ•°={periods}")
            
            # è·å–å†å²æ•°æ®
            historical_data = data_manager.get_data()
            if historical_data is None or len(historical_data) == 0:
                raise ValueError("æ— æ³•è·å–å†å²æ•°æ®")
            
            # ä½¿ç”¨æŒ‡å®šæœŸæ•°çš„æœ€æ–°æ•°æ®
            if len(historical_data) > periods:
                historical_data = historical_data.tail(periods)
            
            logger_manager.info(f"ä½¿ç”¨{len(historical_data)}æœŸå†å²æ•°æ®è¿›è¡ŒLSTMè®­ç»ƒå’Œé¢„æµ‹")
            
            # ä½¿ç”¨enhanced LSTMé¢„æµ‹å™¨è¿›è¡Œé¢„æµ‹
            if self.lstm_predictor is not None:
                predictions = self.lstm_predictor.predict(historical_data, count=count)
                
                # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                results = []
                for pred in predictions:
                    if isinstance(pred, tuple) and len(pred) == 2:
                        front_balls, back_balls = pred
                        results.append((list(front_balls), list(back_balls)))
                    elif isinstance(pred, dict):
                        front_balls = pred.get('front', pred.get('front_balls', []))
                        back_balls = pred.get('back', pred.get('back_balls', []))
                        results.append((list(front_balls), list(back_balls)))
                
                logger_manager.info(f"LSTMé¢„æµ‹å®Œæˆï¼Œç”Ÿæˆ{len(results)}æ³¨é¢„æµ‹")
                return results
            else:
                raise ValueError("LSTMé¢„æµ‹å™¨æœªåˆå§‹åŒ–")
                
        except Exception as e:
            logger_manager.error(f"LSTMé¢„æµ‹å¤±è´¥: {e}")
            # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ï¼Œä¿æŒç³»ç»Ÿç¨³å®šæ€§
            return []
    
    def train_model(self, periods: int = 1000) -> Dict[str, Any]:
        """
        è®­ç»ƒLSTMæ¨¡å‹
        
        Args:
            periods: è®­ç»ƒæ•°æ®æœŸæ•°
            
        Returns:
            è®­ç»ƒç»“æœä¿¡æ¯
        """
        try:
            logger_manager.info(f"å¼€å§‹LSTMæ¨¡å‹è®­ç»ƒï¼Œä½¿ç”¨{periods}æœŸæ•°æ®")
            
            # è·å–è®­ç»ƒæ•°æ®
            historical_data = data_manager.get_data()
            if historical_data is None or len(historical_data) == 0:
                raise ValueError("æ— æ³•è·å–è®­ç»ƒæ•°æ®")
            
            # ä½¿ç”¨æŒ‡å®šæœŸæ•°çš„æ•°æ®
            if len(historical_data) > periods:
                historical_data = historical_data.tail(periods)
            
            # ä½¿ç”¨enhanced LSTMé¢„æµ‹å™¨è¿›è¡Œè®­ç»ƒ
            if self.lstm_predictor is not None:
                training_result = self.lstm_predictor.train(historical_data)
                logger_manager.info("LSTMæ¨¡å‹è®­ç»ƒå®Œæˆ")
                return training_result
            else:
                raise ValueError("LSTMé¢„æµ‹å™¨æœªåˆå§‹åŒ–")
                
        except Exception as e:
            logger_manager.error(f"LSTMæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def save_model(self, model_path: str = None) -> bool:
        """
        ä¿å­˜LSTMæ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹ä¿å­˜è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            if self.lstm_predictor is not None:
                if model_path is None:
                    model_path = os.path.join(self.model_cache_dir, "advanced_lstm_model")
                
                self.lstm_predictor.save_model(model_path)
                logger_manager.info(f"LSTMæ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
                return True
            else:
                logger_manager.error("LSTMé¢„æµ‹å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜æ¨¡å‹")
                return False
                
        except Exception as e:
            logger_manager.error(f"ä¿å­˜LSTMæ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def load_model(self, model_path: str = None) -> bool:
        """
        åŠ è½½LSTMæ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            
        Returns:
            æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            if self.lstm_predictor is not None:
                if model_path is None:
                    model_path = os.path.join(self.model_cache_dir, "advanced_lstm_model")
                
                if os.path.exists(model_path):
                    self.lstm_predictor.load_model(model_path)
                    logger_manager.info(f"LSTMæ¨¡å‹å·²ä»{model_path}åŠ è½½")
                    return True
                else:
                    logger_manager.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                    return False
            else:
                logger_manager.error("LSTMé¢„æµ‹å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
                return False
                
        except Exception as e:
            logger_manager.error(f"åŠ è½½LSTMæ¨¡å‹å¤±è´¥: {e}")
            return False


# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ¨¡å—ï¼Œè¿›è¡Œæµ‹è¯•
if __name__ == "__main__":
    if TENSORFLOW_AVAILABLE and ENHANCED_LSTM_AVAILABLE:
        try:
            print("ğŸ§  æµ‹è¯•é«˜çº§LSTMé¢„æµ‹å™¨...")
            predictor = AdvancedLSTMPredictor()
            
            # æµ‹è¯•é¢„æµ‹
            results = predictor.lstm_predict(count=3, periods=100)
            
            print(f"\nâœ… LSTMé¢„æµ‹ç»“æœ (å…±{len(results)}æ³¨):")
            for i, (front, back) in enumerate(results, 1):
                print(f"é¢„æµ‹ {i}: å‰åŒº {front}, ååŒº {back}")
                
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    else:
        print("âŒ TensorFlowæˆ–Enhanced LSTMæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•æµ‹è¯•")
