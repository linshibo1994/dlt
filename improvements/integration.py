#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é›†æˆæ¨¡å—
æ•´åˆå„ç§é¢„æµ‹ç®—æ³•ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£
"""

import os
import sys
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Any, Callable, Union
from datetime import datetime
from collections import defaultdict, Counter

# å°è¯•å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from core_modules import logger_manager, data_manager, cache_manager
except ImportError:
    # å¦‚æœåœ¨ä¸åŒç›®å½•è¿è¡Œï¼Œæ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from core_modules import logger_manager, data_manager, cache_manager

# å°è¯•å¯¼å…¥é¢„æµ‹å™¨æ¨¡å—
try:
    from predictor_modules import get_traditional_predictor, get_advanced_predictor, get_super_predictor
    PREDICTORS_AVAILABLE = True
except ImportError:
    PREDICTORS_AVAILABLE = False
    logger_manager.warning("é¢„æµ‹å™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œéƒ¨åˆ†åŠŸèƒ½å°†ä¸å¯ç”¨")

# å°è¯•å¯¼å…¥å¢å¼ºé©¬å°”å¯å¤«é¢„æµ‹å™¨
try:
    from improvements.enhanced_markov import get_markov_predictor
    ENHANCED_MARKOV_AVAILABLE = True
except ImportError:
    ENHANCED_MARKOV_AVAILABLE = False
    logger_manager.warning("å¢å¼ºé©¬å°”å¯å¤«æ¨¡å—æœªæ‰¾åˆ°ï¼Œéƒ¨åˆ†åŠŸèƒ½å°†ä¸å¯ç”¨")

# å°è¯•å¯¼å…¥å¢å¼ºç‰¹æ€§é¢„æµ‹å™¨
try:
    from improvements.enhanced_features import get_enhanced_feature_predictor
    ENHANCED_FEATURES_AVAILABLE = True
except ImportError:
    ENHANCED_FEATURES_AVAILABLE = False
    logger_manager.warning("å¢å¼ºç‰¹æ€§æ¨¡å—æœªæ‰¾åˆ°ï¼Œéƒ¨åˆ†åŠŸèƒ½å°†ä¸å¯ç”¨")

# å°è¯•å¯¼å…¥LSTMé¢„æµ‹å™¨
try:
    from advanced_lstm_predictor import AdvancedLSTMPredictor, TENSORFLOW_AVAILABLE
except ImportError:
    TENSORFLOW_AVAILABLE = False
    logger_manager.warning("LSTMé¢„æµ‹å™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œéƒ¨åˆ†åŠŸèƒ½å°†ä¸å¯ç”¨")


class IntegratedPredictor:
    """é›†æˆé¢„æµ‹å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é›†æˆé¢„æµ‹å™¨"""
        self.df = data_manager.get_data()
        if self.df is None:
            logger_manager.error("æ•°æ®æœªåŠ è½½")
        
        # é¢„æµ‹å™¨å­—å…¸
        self.predictors = {}
        
        # åŠ è½½é¢„æµ‹å™¨
        self._load_predictors()
    
    def _load_predictors(self):
        """åŠ è½½é¢„æµ‹å™¨"""
        # åŠ è½½ä¼ ç»Ÿé¢„æµ‹å™¨
        if PREDICTORS_AVAILABLE:
            try:
                traditional = get_traditional_predictor()
                advanced = get_advanced_predictor()
                super_predictor = get_super_predictor()
                
                self.predictors.update({
                    'frequency': lambda data, count=3: traditional.frequency_predict(count),
                    'hot_cold': lambda data, count=3: traditional.hot_cold_predict(count),
                    'missing': lambda data, count=3: traditional.missing_predict(count),
                    'markov': lambda data, count=3: advanced.markov_predict(count),
                    'bayesian': lambda data, count=3: advanced.bayesian_predict(count),
                    'ensemble': lambda data, count=3: advanced.ensemble_predict(count),
                    'super': lambda data, count=3: super_predictor.predict_super(count)
                })
                
                logger_manager.info("å·²åŠ è½½ä¼ ç»Ÿé¢„æµ‹å™¨")
            except Exception as e:
                logger_manager.error(f"åŠ è½½ä¼ ç»Ÿé¢„æµ‹å™¨å¤±è´¥: {e}")
        
        # åŠ è½½å¢å¼ºé©¬å°”å¯å¤«é¢„æµ‹å™¨
        if ENHANCED_MARKOV_AVAILABLE:
            try:
                markov_predictor = get_markov_predictor()
                
                self.predictors.update({
                    'markov_2nd': lambda data, count=3: markov_predictor.multi_order_markov_predict(count, 300, 2),
                    'markov_3rd': lambda data, count=3: markov_predictor.multi_order_markov_predict(count, 300, 3),
                    'adaptive_markov': lambda data, count=3: [
                        (pred['front_balls'], pred['back_balls']) 
                        for pred in markov_predictor.adaptive_order_markov_predict(count, 300)
                    ]
                })
                
                logger_manager.info("å·²åŠ è½½å¢å¼ºé©¬å°”å¯å¤«é¢„æµ‹å™¨")
            except Exception as e:
                logger_manager.error(f"åŠ è½½å¢å¼ºé©¬å°”å¯å¤«é¢„æµ‹å™¨å¤±è´¥: {e}")
        
        # åŠ è½½å¢å¼ºç‰¹æ€§é¢„æµ‹å™¨
        if ENHANCED_FEATURES_AVAILABLE:
            try:
                feature_predictor = get_enhanced_feature_predictor()
                
                self.predictors.update({
                    'pattern_based': lambda data, count=3: feature_predictor.pattern_based_predict(count),
                    'cluster_based': lambda data, count=3: feature_predictor.cluster_based_predict(count)
                })
                
                logger_manager.info("å·²åŠ è½½å¢å¼ºç‰¹æ€§é¢„æµ‹å™¨")
            except Exception as e:
                logger_manager.error(f"åŠ è½½å¢å¼ºç‰¹æ€§é¢„æµ‹å™¨å¤±è´¥: {e}")
        
        # åŠ è½½LSTMé¢„æµ‹å™¨
        if TENSORFLOW_AVAILABLE:
            try:
                lstm_predictor = AdvancedLSTMPredictor()
                
                self.predictors.update({
                    'lstm': lambda data, count=3: lstm_predictor.lstm_predict(count)
                })
                
                logger_manager.info("å·²åŠ è½½LSTMé¢„æµ‹å™¨")
            except Exception as e:
                logger_manager.error(f"åŠ è½½LSTMé¢„æµ‹å™¨å¤±è´¥: {e}")
    
    def stacking_predict(self, count: int = 3) -> List[Dict]:
        """Stackingé›†æˆé¢„æµ‹
        
        Args:
            count: é¢„æµ‹æ³¨æ•°
            
        Returns:
            List[Dict]: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        if not self.predictors:
            logger_manager.error("æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹å™¨")
            return []
        
        # æ”¶é›†å„é¢„æµ‹å™¨çš„é¢„æµ‹ç»“æœ
        all_predictions = {}
        for name, predictor in self.predictors.items():
            try:
                predictions = predictor(self.df, count)
                all_predictions[name] = predictions
            except Exception as e:
                logger_manager.error(f"é¢„æµ‹å™¨ {name} é¢„æµ‹å¤±è´¥: {e}")
        
        # Stackingèåˆ
        results = []
        for i in range(count):
            # æ”¶é›†ç¬¬iæ³¨çš„æ‰€æœ‰é¢„æµ‹
            front_candidates = []
            back_candidates = []
            
            for name, predictions in all_predictions.items():
                if i < len(predictions):
                    if isinstance(predictions[i], tuple) and len(predictions[i]) == 2:
                        front, back = predictions[i]
                    elif isinstance(predictions[i], dict) and 'front_balls' in predictions[i] and 'back_balls' in predictions[i]:
                        front = predictions[i]['front_balls']
                        back = predictions[i]['back_balls']
                    else:
                        logger_manager.warning(f"æ— æ³•è§£æé¢„æµ‹ç»“æœ: {predictions[i]}")
                        continue
                    
                    front_candidates.extend(front)
                    back_candidates.extend(back)
            
            # ä½¿ç”¨æŠ•ç¥¨æœºåˆ¶é€‰æ‹©æœ€ç»ˆå·ç 
            front_counter = Counter(front_candidates)
            back_counter = Counter(back_candidates)
            
            front_balls = [ball for ball, _ in front_counter.most_common(5)]
            back_balls = [ball for ball, _ in back_counter.most_common(2)]
            
            # å¦‚æœå·ç ä¸è¶³ï¼Œéšæœºè¡¥å……
            while len(front_balls) < 5:
                ball = np.random.randint(1, 36)
                if ball not in front_balls:
                    front_balls.append(ball)
            
            while len(back_balls) < 2:
                ball = np.random.randint(1, 13)
                if ball not in back_balls:
                    back_balls.append(ball)
            
            # æ„å»ºç»“æœ
            result = {
                'front_balls': sorted(front_balls),
                'back_balls': sorted(back_balls),
                'method': 'stacking',
                'confidence': 0.85,
                'predictors_used': list(all_predictions.keys())
            }
            
            results.append(result)
        
        return results
    
    def weighted_ensemble_predict(self, count: int = 3) -> List[Dict]:
        """åŠ æƒé›†æˆé¢„æµ‹
        
        Args:
            count: é¢„æµ‹æ³¨æ•°
            
        Returns:
            List[Dict]: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        if not self.predictors:
            logger_manager.error("æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹å™¨")
            return []
        
        # é¢„æµ‹å™¨æƒé‡
        weights = {
            'frequency': 0.1,
            'hot_cold': 0.1,
            'missing': 0.1,
            'markov': 0.15,
            'bayesian': 0.15,
            'ensemble': 0.15,
            'super': 0.2,
            'markov_2nd': 0.2,
            'markov_3rd': 0.2,
            'adaptive_markov': 0.25,
            'pattern_based': 0.15,
            'cluster_based': 0.15,
            'lstm': 0.25
        }
        
        # æ”¶é›†å„é¢„æµ‹å™¨çš„é¢„æµ‹ç»“æœ
        all_predictions = {}
        for name, predictor in self.predictors.items():
            try:
                predictions = predictor(self.df, count)
                all_predictions[name] = predictions
            except Exception as e:
                logger_manager.error(f"é¢„æµ‹å™¨ {name} é¢„æµ‹å¤±è´¥: {e}")
        
        # åŠ æƒèåˆ
        results = []
        for i in range(count):
            # å‰åŒºå’ŒååŒºå·ç çš„åŠ æƒå¾—åˆ†
            front_scores = defaultdict(float)
            back_scores = defaultdict(float)
            
            # è®¡ç®—æ¯ä¸ªå·ç çš„åŠ æƒå¾—åˆ†
            for name, predictions in all_predictions.items():
                if i < len(predictions):
                    weight = weights.get(name, 0.1)
                    
                    if isinstance(predictions[i], tuple) and len(predictions[i]) == 2:
                        front, back = predictions[i]
                    elif isinstance(predictions[i], dict) and 'front_balls' in predictions[i] and 'back_balls' in predictions[i]:
                        front = predictions[i]['front_balls']
                        back = predictions[i]['back_balls']
                    else:
                        logger_manager.warning(f"æ— æ³•è§£æé¢„æµ‹ç»“æœ: {predictions[i]}")
                        continue
                    
                    for ball in front:
                        front_scores[ball] += weight
                    
                    for ball in back:
                        back_scores[ball] += weight
            
            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å·ç 
            front_balls = [ball for ball, _ in sorted(front_scores.items(), key=lambda x: x[1], reverse=True)[:5]]
            back_balls = [ball for ball, _ in sorted(back_scores.items(), key=lambda x: x[1], reverse=True)[:2]]
            
            # å¦‚æœå·ç ä¸è¶³ï¼Œéšæœºè¡¥å……
            while len(front_balls) < 5:
                ball = np.random.randint(1, 36)
                if ball not in front_balls:
                    front_balls.append(ball)
            
            while len(back_balls) < 2:
                ball = np.random.randint(1, 13)
                if ball not in back_balls:
                    back_balls.append(ball)
            
            # æ„å»ºç»“æœ
            result = {
                'front_balls': sorted(front_balls),
                'back_balls': sorted(back_balls),
                'method': 'weighted_ensemble',
                'confidence': 0.9,
                'predictors_used': list(all_predictions.keys()),
                'weights': {name: weights.get(name, 0.1) for name in all_predictions.keys()}
            }
            
            results.append(result)
        
        return results
    
    def adaptive_ensemble_predict(self, count: int = 3) -> List[Dict]:
        """è‡ªé€‚åº”é›†æˆé¢„æµ‹
        
        Args:
            count: é¢„æµ‹æ³¨æ•°
            
        Returns:
            List[Dict]: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        if not self.predictors:
            logger_manager.error("æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹å™¨")
            return []
        
        # åŠ è½½å†å²æ€§èƒ½æ•°æ®
        performance_data = self._load_performance_data()
        
        # æ ¹æ®å†å²æ€§èƒ½è®¡ç®—æƒé‡
        weights = self._calculate_adaptive_weights(performance_data)
        
        # æ”¶é›†å„é¢„æµ‹å™¨çš„é¢„æµ‹ç»“æœ
        all_predictions = {}
        for name, predictor in self.predictors.items():
            try:
                predictions = predictor(self.df, count)
                all_predictions[name] = predictions
            except Exception as e:
                logger_manager.error(f"é¢„æµ‹å™¨ {name} é¢„æµ‹å¤±è´¥: {e}")
        
        # è‡ªé€‚åº”èåˆ
        results = []
        for i in range(count):
            # å‰åŒºå’ŒååŒºå·ç çš„åŠ æƒå¾—åˆ†
            front_scores = defaultdict(float)
            back_scores = defaultdict(float)
            
            # è®¡ç®—æ¯ä¸ªå·ç çš„åŠ æƒå¾—åˆ†
            for name, predictions in all_predictions.items():
                if i < len(predictions):
                    weight = weights.get(name, 0.1)
                    
                    if isinstance(predictions[i], tuple) and len(predictions[i]) == 2:
                        front, back = predictions[i]
                    elif isinstance(predictions[i], dict) and 'front_balls' in predictions[i] and 'back_balls' in predictions[i]:
                        front = predictions[i]['front_balls']
                        back = predictions[i]['back_balls']
                    else:
                        logger_manager.warning(f"æ— æ³•è§£æé¢„æµ‹ç»“æœ: {predictions[i]}")
                        continue
                    
                    for ball in front:
                        front_scores[ball] += weight
                    
                    for ball in back:
                        back_scores[ball] += weight
            
            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å·ç 
            front_balls = [ball for ball, _ in sorted(front_scores.items(), key=lambda x: x[1], reverse=True)[:5]]
            back_balls = [ball for ball, _ in sorted(back_scores.items(), key=lambda x: x[1], reverse=True)[:2]]
            
            # å¦‚æœå·ç ä¸è¶³ï¼Œéšæœºè¡¥å……
            while len(front_balls) < 5:
                ball = np.random.randint(1, 36)
                if ball not in front_balls:
                    front_balls.append(ball)
            
            while len(back_balls) < 2:
                ball = np.random.randint(1, 13)
                if ball not in back_balls:
                    back_balls.append(ball)
            
            # æ„å»ºç»“æœ
            result = {
                'front_balls': sorted(front_balls),
                'back_balls': sorted(back_balls),
                'method': 'adaptive_ensemble',
                'confidence': 0.95,
                'predictors_used': list(all_predictions.keys()),
                'weights': weights
            }
            
            results.append(result)
        
        return results
    
    def _load_performance_data(self) -> Dict:
        """åŠ è½½å†å²æ€§èƒ½æ•°æ®"""
        # å°è¯•ä»ç¼“å­˜åŠ è½½
        cache_key = "predictor_performance_data"
        cached_data = cache_manager.load_cache("analysis", cache_key)
        if cached_data:
            return cached_data
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œä½¿ç”¨é»˜è®¤å€¼
        default_data = {
            'frequency': 0.5,
            'hot_cold': 0.5,
            'missing': 0.5,
            'markov': 0.6,
            'bayesian': 0.6,
            'ensemble': 0.7,
            'super': 0.7,
            'markov_2nd': 0.7,
            'markov_3rd': 0.7,
            'adaptive_markov': 0.8,
            'pattern_based': 0.6,
            'cluster_based': 0.6,
            'lstm': 0.8
        }
        
        return default_data
    
    def _calculate_adaptive_weights(self, performance_data: Dict) -> Dict:
        """è®¡ç®—è‡ªé€‚åº”æƒé‡"""
        weights = {}
        
        # æ ¹æ®æ€§èƒ½æ•°æ®è®¡ç®—æƒé‡
        for name, performance in performance_data.items():
            # ä½¿ç”¨æ€§èƒ½å€¼çš„å¹³æ–¹ä½œä¸ºæƒé‡ï¼Œä½¿å¾—é«˜æ€§èƒ½çš„é¢„æµ‹å™¨æƒé‡æ›´é«˜
            weights[name] = performance ** 2
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(weights.values())
        if total_weight > 0:
            weights = {name: weight / total_weight for name, weight in weights.items()}
        
        return weights
    
    def transformer_predict(self, count: int = 3) -> List[Dict]:
        """Transformeré¢„æµ‹
        
        Args:
            count: é¢„æµ‹æ³¨æ•°
            
        Returns:
            List[Dict]: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        # è¿™é‡Œåº”è¯¥å®ç°Transformeré¢„æµ‹ï¼Œä½†ç”±äºå¤æ‚åº¦è¾ƒé«˜ï¼Œæš‚æ—¶ä½¿ç”¨åŠ æƒé›†æˆé¢„æµ‹ä»£æ›¿
        logger_manager.warning("Transformeré¢„æµ‹æœªå®ç°ï¼Œä½¿ç”¨åŠ æƒé›†æˆé¢„æµ‹ä»£æ›¿")
        
        results = self.weighted_ensemble_predict(count)
        for result in results:
            result['method'] = 'transformer'
            result['confidence'] = 0.85
        
        return results
    
    def gan_predict(self, count: int = 3) -> List[Dict]:
        """GANé¢„æµ‹
        
        Args:
            count: é¢„æµ‹æ³¨æ•°
            
        Returns:
            List[Dict]: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        # è¿™é‡Œåº”è¯¥å®ç°GANé¢„æµ‹ï¼Œä½†ç”±äºå¤æ‚åº¦è¾ƒé«˜ï¼Œæš‚æ—¶ä½¿ç”¨è‡ªé€‚åº”é›†æˆé¢„æµ‹ä»£æ›¿
        logger_manager.warning("GANé¢„æµ‹æœªå®ç°ï¼Œä½¿ç”¨è‡ªé€‚åº”é›†æˆé¢„æµ‹ä»£æ›¿")
        
        results = self.adaptive_ensemble_predict(count)
        for result in results:
            result['method'] = 'gan'
            result['confidence'] = 0.85
        
        return results
    
    def ultimate_ensemble_predict(self, count: int = 3) -> List[Dict]:
        """ç»ˆæé›†æˆé¢„æµ‹
        
        ç»“åˆæ‰€æœ‰é¢„æµ‹æ–¹æ³•çš„æœ€ä½³ç»“æœ
        
        Args:
            count: é¢„æµ‹æ³¨æ•°
            
        Returns:
            List[Dict]: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        # è·å–å„ç§é›†æˆæ–¹æ³•çš„é¢„æµ‹ç»“æœ
        stacking_results = self.stacking_predict(count)
        weighted_results = self.weighted_ensemble_predict(count)
        adaptive_results = self.adaptive_ensemble_predict(count)
        
        # èåˆç»“æœ
        results = []
        for i in range(count):
            # æ”¶é›†æ‰€æœ‰é¢„æµ‹ç»“æœ
            all_front_balls = []
            all_back_balls = []
            
            if i < len(stacking_results):
                all_front_balls.extend(stacking_results[i]['front_balls'])
                all_back_balls.extend(stacking_results[i]['back_balls'])
            
            if i < len(weighted_results):
                all_front_balls.extend(weighted_results[i]['front_balls'])
                all_back_balls.extend(weighted_results[i]['back_balls'])
            
            if i < len(adaptive_results):
                all_front_balls.extend(adaptive_results[i]['front_balls'])
                all_back_balls.extend(adaptive_results[i]['back_balls'])
            
            # ç»Ÿè®¡å·ç å‡ºç°é¢‘ç‡
            front_counter = Counter(all_front_balls)
            back_counter = Counter(all_back_balls)
            
            # é€‰æ‹©å‡ºç°é¢‘ç‡æœ€é«˜çš„å·ç 
            front_balls = [ball for ball, _ in front_counter.most_common(5)]
            back_balls = [ball for ball, _ in back_counter.most_common(2)]
            
            # å¦‚æœå·ç ä¸è¶³ï¼Œéšæœºè¡¥å……
            while len(front_balls) < 5:
                ball = np.random.randint(1, 36)
                if ball not in front_balls:
                    front_balls.append(ball)
            
            while len(back_balls) < 2:
                ball = np.random.randint(1, 13)
                if ball not in back_balls:
                    back_balls.append(ball)
            
            # æ„å»ºç»“æœ
            result = {
                'front_balls': sorted(front_balls),
                'back_balls': sorted(back_balls),
                'method': 'ultimate_ensemble',
                'confidence': 0.98,
                'ensemble_methods': ['stacking', 'weighted', 'adaptive']
            }
            
            results.append(result)
        
        return results


# å…¨å±€å®ä¾‹
_integrator = None

def get_integrator() -> IntegratedPredictor:
    """è·å–é›†æˆé¢„æµ‹å™¨å®ä¾‹"""
    global _integrator
    if _integrator is None:
        _integrator = IntegratedPredictor()
    return _integrator


if __name__ == "__main__":
    # æµ‹è¯•é›†æˆæ¨¡å—
    print("ğŸ”„ æµ‹è¯•é›†æˆæ¨¡å—...")
    
    # è·å–é›†æˆé¢„æµ‹å™¨
    integrator = get_integrator()
    
    # æµ‹è¯•Stackingé›†æˆé¢„æµ‹
    print("\nğŸ¯ Stackingé›†æˆé¢„æµ‹...")
    stacking_results = integrator.stacking_predict(3)
    for i, result in enumerate(stacking_results):
        front_str = ' '.join([str(b).zfill(2) for b in result['front_balls']])
        back_str = ' '.join([str(b).zfill(2) for b in result['back_balls']])
        print(f"  ç¬¬ {i+1} æ³¨: {front_str} + {back_str}")
        print(f"  ä½¿ç”¨é¢„æµ‹å™¨: {len(result['predictors_used'])} ä¸ª")
    
    # æµ‹è¯•åŠ æƒé›†æˆé¢„æµ‹
    print("\nğŸ¯ åŠ æƒé›†æˆé¢„æµ‹...")
    weighted_results = integrator.weighted_ensemble_predict(3)
    for i, result in enumerate(weighted_results):
        front_str = ' '.join([str(b).zfill(2) for b in result['front_balls']])
        back_str = ' '.join([str(b).zfill(2) for b in result['back_balls']])
        print(f"  ç¬¬ {i+1} æ³¨: {front_str} + {back_str}")
        print(f"  ä½¿ç”¨é¢„æµ‹å™¨: {len(result['predictors_used'])} ä¸ª")
    
    # æµ‹è¯•è‡ªé€‚åº”é›†æˆé¢„æµ‹
    print("\nğŸ¯ è‡ªé€‚åº”é›†æˆé¢„æµ‹...")
    adaptive_results = integrator.adaptive_ensemble_predict(3)
    for i, result in enumerate(adaptive_results):
        front_str = ' '.join([str(b).zfill(2) for b in result['front_balls']])
        back_str = ' '.join([str(b).zfill(2) for b in result['back_balls']])
        print(f"  ç¬¬ {i+1} æ³¨: {front_str} + {back_str}")
        print(f"  ä½¿ç”¨é¢„æµ‹å™¨: {len(result['predictors_used'])} ä¸ª")
    
    # æµ‹è¯•ç»ˆæé›†æˆé¢„æµ‹
    print("\nğŸ¯ ç»ˆæé›†æˆé¢„æµ‹...")
    ultimate_results = integrator.ultimate_ensemble_predict(3)
    for i, result in enumerate(ultimate_results):
        front_str = ' '.join([str(b).zfill(2) for b in result['front_balls']])
        back_str = ' '.join([str(b).zfill(2) for b in result['back_balls']])
        print(f"  ç¬¬ {i+1} æ³¨: {front_str} + {back_str}")
        print(f"  é›†æˆæ–¹æ³•: {result['ensemble_methods']}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ")