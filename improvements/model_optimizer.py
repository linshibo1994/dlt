#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ¨¡å‹ä¼˜åŒ–å™¨
æä¾›è‡ªåŠ¨åŒ–çš„æ¨¡å‹å‚æ•°ä¼˜åŒ–åŠŸèƒ½
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import List, Dict, Tuple, Any, Callable, Union
from datetime import datetime
import json
import time
from tqdm import tqdm
from collections import defaultdict
import itertools
import random

# å°è¯•å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from core_modules import logger_manager, data_manager, cache_manager
except ImportError:
    # å¦‚æœåœ¨ä¸åŒç›®å½•è¿è¡Œï¼Œæ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from core_modules import logger_manager, data_manager, cache_manager

# å°è¯•å¯¼å…¥æ¨¡å‹åŸºå‡†æµ‹è¯•æ¡†æ¶
try:
    from improvements.model_benchmark import ModelBenchmark, get_model_benchmark
except ImportError:
    logger_manager.error("æ¨¡å‹åŸºå‡†æµ‹è¯•æ¡†æ¶æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿improvements/model_benchmark.pyæ–‡ä»¶å­˜åœ¨")
    ModelBenchmark = None
    get_model_benchmark = None

# å°è¯•å¯¼å…¥scikit-learnå’Œscikit-optimize
try:
    from sklearn.model_selection import ParameterGrid, ParameterSampler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    from skopt import gp_minimize
    from skopt.space import Real, Integer, Categorical
    SKOPT_AVAILABLE = True
except ImportError:
    SKOPT_AVAILABLE = False


class ModelOptimizer:
    """æ¨¡å‹ä¼˜åŒ–å™¨"""
    
    def __init__(self, model_creator: Callable, param_space: Dict, 
                optimization_method: str = 'grid', n_iter: int = 50):
        """åˆå§‹åŒ–æ¨¡å‹ä¼˜åŒ–å™¨
        
        Args:
            model_creator: æ¨¡å‹åˆ›å»ºå‡½æ•°ï¼Œæ¥å—å‚æ•°å­—å…¸ï¼Œè¿”å›æ¨¡å‹å®ä¾‹
            param_space: å‚æ•°ç©ºé—´ï¼Œå­—å…¸å½¢å¼ï¼Œé”®ä¸ºå‚æ•°åï¼Œå€¼ä¸ºå‚æ•°å¯èƒ½çš„å–å€¼åˆ—è¡¨
            optimization_method: ä¼˜åŒ–æ–¹æ³•ï¼Œå¯é€‰å€¼: 'grid', 'random', 'bayesian'
            n_iter: éšæœºæœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ–çš„è¿­ä»£æ¬¡æ•°
        """
        self.model_creator = model_creator
        self.param_space = param_space
        self.optimization_method = optimization_method
        self.n_iter = n_iter
        
        # ä¼˜åŒ–ç»“æœ
        self.best_params = None
        self.best_score = -float('inf')
        self.best_model = None
        self.results = []
        
        # è·å–æ•°æ®
        self.df = data_manager.get_data()
        if self.df is None:
            logger_manager.error("æ•°æ®æœªåŠ è½½")
        
        # è·å–åŸºå‡†æµ‹è¯•å®ä¾‹
        if ModelBenchmark is not None:
            self.benchmark = get_model_benchmark()
        else:
            self.benchmark = None
            logger_manager.error("æ¨¡å‹åŸºå‡†æµ‹è¯•æ¡†æ¶æœªæ‰¾åˆ°ï¼Œæ€§èƒ½è¯„ä¼°åŠŸèƒ½å°†ä¸å¯ç”¨")
    
    def optimize(self, train_periods: int = 500, val_periods: int = 50, 
                metric: str = 'accuracy', verbose: bool = True) -> Dict:
        """æ‰§è¡Œå‚æ•°ä¼˜åŒ–
        
        Args:
            train_periods: è®­ç»ƒæ•°æ®æœŸæ•°
            val_periods: éªŒè¯æ•°æ®æœŸæ•°
            metric: ä¼˜åŒ–æŒ‡æ ‡ï¼Œå¯é€‰å€¼: 'accuracy', 'hit_rate', 'roi'
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            
        Returns:
            Dict: ä¼˜åŒ–ç»“æœ
        """
        if self.df is None or len(self.df) < train_periods + val_periods:
            logger_manager.error("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå‚æ•°ä¼˜åŒ–")
            return {}
        
        # å‡†å¤‡æ•°æ®
        train_data = self.df.iloc[val_periods:val_periods+train_periods]
        val_data = self.df.iloc[:val_periods]
        
        # æ ¹æ®ä¼˜åŒ–æ–¹æ³•é€‰æ‹©å‚æ•°ç»„åˆ
        param_combinations = self._get_param_combinations()
        
        if verbose:
            logger_manager.info(f"å¼€å§‹å‚æ•°ä¼˜åŒ–ï¼Œæ–¹æ³•: {self.optimization_method}, å‚æ•°ç»„åˆæ•°: {len(param_combinations)}")
            iterator = tqdm(param_combinations, desc="å‚æ•°ä¼˜åŒ–")
        else:
            iterator = param_combinations
        
        # è¯„ä¼°æ¯ä¸ªå‚æ•°ç»„åˆ
        for params in iterator:
            try:
                # ä½¿ç”¨å½“å‰å‚æ•°åˆ›å»ºæ¨¡å‹
                model = self.model_creator(**params)
                
                # è®­ç»ƒæ¨¡å‹
                if hasattr(model, 'fit'):
                    model.fit(train_data)
                elif hasattr(model, 'train'):
                    model.train(train_data)
                
                # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
                score = self._evaluate_model(model, val_data, metric)
                
                # è®°å½•ç»“æœ
                result = {
                    'params': params,
                    'score': score,
                    'timestamp': datetime.now().isoformat()
                }
                self.results.append(result)
                
                # æ›´æ–°æœ€ä½³å‚æ•°
                if score > self.best_score:
                    self.best_score = score
                    self.best_params = params
                    self.best_model = model
                    
                    if verbose:
                        logger_manager.info(f"å‘ç°æ›´å¥½çš„å‚æ•°: {params}, å¾—åˆ†: {score:.4f}")
                
            except Exception as e:
                logger_manager.error(f"è¯„ä¼°å‚æ•° {params} å¤±è´¥: {e}")
        
        # æ•´ç†ç»“æœ
        optimization_result = {
            'best_params': self.best_params,
            'best_score': self.best_score,
            'all_results': self.results,
            'optimization_method': self.optimization_method,
            'metric': metric,
            'timestamp': datetime.now().isoformat()
        }
        
        if verbose:
            logger_manager.info(f"å‚æ•°ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å‚æ•°: {self.best_params}, æœ€ä½³å¾—åˆ†: {self.best_score:.4f}")
        
        return optimization_result
    
    def _get_param_combinations(self):
        """è·å–å‚æ•°ç»„åˆ"""
        if self.optimization_method == 'grid':
            # ç½‘æ ¼æœç´¢
            if SKLEARN_AVAILABLE:
                return list(ParameterGrid(self.param_space))
            else:
                # æ‰‹åŠ¨å®ç°ç½‘æ ¼æœç´¢
                keys = self.param_space.keys()
                values = self.param_space.values()
                combinations = list(itertools.product(*values))
                return [dict(zip(keys, combo)) for combo in combinations]
        
        elif self.optimization_method == 'random':
            # éšæœºæœç´¢
            if SKLEARN_AVAILABLE:
                return list(ParameterSampler(self.param_space, n_iter=self.n_iter, random_state=42))
            else:
                # æ‰‹åŠ¨å®ç°éšæœºæœç´¢
                random.seed(42)
                
                combinations = []
                for _ in range(self.n_iter):
                    params = {}
                    for key, values in self.param_space.items():
                        params[key] = random.choice(values)
                    combinations.append(params)
                
                return combinations
        
        elif self.optimization_method == 'bayesian':
            # è´å¶æ–¯ä¼˜åŒ–
            if SKOPT_AVAILABLE:
                # å°†å‚æ•°ç©ºé—´è½¬æ¢ä¸ºskoptæ ¼å¼
                skopt_space = []
                for key, values in self.param_space.items():
                    if isinstance(values[0], int):
                        skopt_space.append(Integer(min(values), max(values), name=key))
                    elif isinstance(values[0], float):
                        skopt_space.append(Real(min(values), max(values), name=key))
                    else:
                        skopt_space.append(Categorical(values, name=key))
                
                # ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ç”Ÿæˆå‚æ•°ç»„åˆ
                from skopt.sampler import Sobol
                from skopt.space import Space
                
                space = Space(skopt_space)
                sobol = Sobol()
                return [dict(zip(self.param_space.keys(), x)) for x in sobol.generate(space.dimensions, self.n_iter)]
            else:
                # å¦‚æœskoptä¸å¯ç”¨ï¼Œé€€å›åˆ°éšæœºæœç´¢
                logger_manager.warning("scikit-optimizeä¸å¯ç”¨ï¼Œé€€å›åˆ°éšæœºæœç´¢")
                return self._get_param_combinations('random')
        
        else:
            logger_manager.error(f"æœªçŸ¥çš„ä¼˜åŒ–æ–¹æ³•: {self.optimization_method}")
            return []
    
    def _evaluate_model(self, model, val_data, metric):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        # åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹
        predictions = []
        
        for i in range(len(val_data)):
            try:
                # è·å–éªŒè¯æœŸçš„å®é™…ç»“æœ
                val_row = val_data.iloc[i]
                actual_front, actual_back = data_manager.parse_balls(val_row)
                
                # ä½¿ç”¨åç»­æ•°æ®è¿›è¡Œé¢„æµ‹
                historical_data = val_data.iloc[i+1:]
                
                # è°ƒç”¨æ¨¡å‹çš„é¢„æµ‹æ–¹æ³•
                if hasattr(model, 'predict'):
                    pred = model.predict(historical_data)
                elif hasattr(model, 'predict_next'):
                    pred = model.predict_next(historical_data)
                else:
                    logger_manager.error("æ¨¡å‹æ²¡æœ‰predictæˆ–predict_nextæ–¹æ³•")
                    return -float('inf')
                
                # è§£æé¢„æµ‹ç»“æœ
                if isinstance(pred, list) and len(pred) > 0:
                    if isinstance(pred[0], tuple) and len(pred[0]) == 2:
                        pred_front, pred_back = pred[0]
                    elif isinstance(pred[0], dict) and 'front_balls' in pred[0] and 'back_balls' in pred[0]:
                        pred_front = pred[0]['front_balls']
                        pred_back = pred[0]['back_balls']
                    else:
                        logger_manager.warning(f"æ— æ³•è§£æé¢„æµ‹ç»“æœ: {pred[0]}")
                        continue
                elif isinstance(pred, tuple) and len(pred) == 2:
                    pred_front, pred_back = pred
                else:
                    logger_manager.warning(f"æ— æ³•è§£æé¢„æµ‹ç»“æœ: {pred}")
                    continue
                
                # è®¡ç®—å‘½ä¸­æƒ…å†µ
                front_hits = len(set(pred_front) & set(actual_front))
                back_hits = len(set(pred_back) & set(actual_back))
                
                # è®°å½•é¢„æµ‹ç»“æœ
                predictions.append({
                    'front_hits': front_hits,
                    'back_hits': back_hits,
                    'actual_front': actual_front,
                    'actual_back': actual_back,
                    'pred_front': pred_front,
                    'pred_back': pred_back
                })
                
            except Exception as e:
                logger_manager.error(f"é¢„æµ‹éªŒè¯æœŸ {i} å¤±è´¥: {e}")
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        if not predictions:
            return -float('inf')
        
        if metric == 'accuracy':
            # å‡†ç¡®ç‡ï¼ˆåŠ æƒå¾—åˆ†ï¼‰
            scores = []
            for pred in predictions:
                front_hits = pred['front_hits']
                back_hits = pred['back_hits']
                
                # å‰åŒºæƒé‡
                front_weight = 0.7
                # ååŒºæƒé‡
                back_weight = 0.3
                
                # å‰åŒºå¾—åˆ†ï¼ˆæ»¡åˆ†ä¸º5ï¼‰
                front_score = front_hits / 5
                # ååŒºå¾—åˆ†ï¼ˆæ»¡åˆ†ä¸º2ï¼‰
                back_score = back_hits / 2
                
                # åŠ æƒæ€»åˆ†
                score = front_weight * front_score + back_weight * back_score
                scores.append(score)
            
            return np.mean(scores)
        
        elif metric == 'hit_rate':
            # å‘½ä¸­ç‡ï¼ˆä»»æ„å·ç å‘½ä¸­ï¼‰
            hit_count = sum(1 for pred in predictions if pred['front_hits'] > 0 or pred['back_hits'] > 0)
            return hit_count / len(predictions)
        
        elif metric == 'roi':
            # æŠ•èµ„å›æŠ¥ç‡
            total_cost = len(predictions) * 2  # å‡è®¾æ¯æ³¨2å…ƒ
            total_prize = 0
            
            for pred in predictions:
                front_hits = pred['front_hits']
                back_hits = pred['back_hits']
                
                # è®¡ç®—å¥–é‡‘
                if front_hits == 5 and back_hits == 2:
                    total_prize += 10000000  # ä¸€ç­‰å¥–
                elif front_hits == 5 and back_hits == 1:
                    total_prize += 100000  # äºŒç­‰å¥–
                elif front_hits == 5 and back_hits == 0:
                    total_prize += 3000  # ä¸‰ç­‰å¥–
                elif front_hits == 4 and back_hits == 2:
                    total_prize += 200  # å››ç­‰å¥–
                elif front_hits == 4 and back_hits == 1:
                    total_prize += 10  # äº”ç­‰å¥–
                elif front_hits == 3 and back_hits == 2:
                    total_prize += 10  # äº”ç­‰å¥–
                elif front_hits == 4 and back_hits == 0:
                    total_prize += 5  # å…­ç­‰å¥–
                elif front_hits == 3 and back_hits == 1:
                    total_prize += 5  # å…­ç­‰å¥–
                elif front_hits == 2 and back_hits == 2:
                    total_prize += 5  # å…­ç­‰å¥–
                elif front_hits == 0 and back_hits == 2:
                    total_prize += 5  # å…­ç­‰å¥–
            
            return (total_prize - total_cost) / total_cost if total_cost > 0 else 0
        
        else:
            logger_manager.error(f"æœªçŸ¥çš„è¯„ä¼°æŒ‡æ ‡: {metric}")
            return -float('inf')
    
    def benchmark_best_model(self, model_name: str, test_periods: int = 50, verbose: bool = True) -> Dict:
        """ä½¿ç”¨åŸºå‡†æµ‹è¯•æ¡†æ¶è¯„ä¼°æœ€ä½³æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            test_periods: æµ‹è¯•æœŸæ•°
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            
        Returns:
            Dict: è¯„ä¼°ç»“æœ
        """
        if self.benchmark is None:
            logger_manager.error("æ¨¡å‹åŸºå‡†æµ‹è¯•æ¡†æ¶æœªæ‰¾åˆ°ï¼Œæ— æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•")
            return {}
        
        if self.best_model is None:
            logger_manager.error("æ²¡æœ‰æœ€ä½³æ¨¡å‹å¯ä¾›è¯„ä¼°ï¼Œè¯·å…ˆè¿è¡Œoptimizeæ–¹æ³•")
            return {}
        
        # æ³¨å†Œæœ€ä½³æ¨¡å‹
        self.benchmark.register_model(
            model_name,
            lambda data: self.best_model.predict(data) if hasattr(self.best_model, 'predict') else self.best_model.predict_next(data),
            f"ä¼˜åŒ–åçš„æ¨¡å‹ (å‚æ•°: {self.best_params})",
            "optimized"
        )
        
        # è¯„ä¼°æ¨¡å‹
        result = self.benchmark.evaluate_model(model_name, test_periods, verbose=verbose)
        
        return result
    
    def visualize_optimization_process(self, output_path=None):
        """å¯è§†åŒ–ä¼˜åŒ–è¿‡ç¨‹
        
        Args:
            output_path: å›¾è¡¨è¾“å‡ºè·¯å¾„
        """
        if not self.results:
            logger_manager.warning("æ²¡æœ‰ä¼˜åŒ–ç»“æœå¯ä¾›å¯è§†åŒ–")
            return
        
        try:
            # æå–å¾—åˆ†
            scores = [result['score'] for result in self.results]
            iterations = list(range(1, len(scores) + 1))
            
            # åˆ›å»ºå›¾è¡¨
            plt.figure(figsize=(10, 6))
            
            # ç»˜åˆ¶å¾—åˆ†æ›²çº¿
            plt.plot(iterations, scores, 'b-', alpha=0.6)
            plt.plot(iterations, scores, 'bo', alpha=0.5)
            
            # æ ‡è®°æœ€ä½³å¾—åˆ†
            best_idx = scores.index(max(scores))
            plt.plot(best_idx + 1, scores[best_idx], 'ro', markersize=10)
            plt.annotate(f"æœ€ä½³: {scores[best_idx]:.4f}", 
                        xy=(best_idx + 1, scores[best_idx]),
                        xytext=(best_idx + 1 + 5, scores[best_idx]),
                        arrowprops=dict(facecolor='black', shrink=0.05))
            
            # æ·»åŠ ç§»åŠ¨å¹³å‡çº¿
            window = min(10, len(scores))
            if window > 1:
                moving_avg = np.convolve(scores, np.ones(window)/window, mode='valid')
                plt.plot(range(window, len(scores) + 1), moving_avg, 'r-', alpha=0.8, label=f'{window}æ¬¡è¿­ä»£ç§»åŠ¨å¹³å‡')
            
            # è®¾ç½®å›¾è¡¨å±æ€§
            plt.title('å‚æ•°ä¼˜åŒ–è¿‡ç¨‹')
            plt.xlabel('è¿­ä»£æ¬¡æ•°')
            plt.ylabel('è¯„ä¼°å¾—åˆ†')
            plt.grid(True, alpha=0.3)
            plt.legend()
            
            # ä¿å­˜æˆ–æ˜¾ç¤ºå›¾è¡¨
            if output_path:
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                plt.savefig(output_path)
                logger_manager.info(f"ä¼˜åŒ–è¿‡ç¨‹å›¾è¡¨å·²ä¿å­˜åˆ° {output_path}")
            else:
                plt.show()
                
        except Exception as e:
            logger_manager.error(f"å¯è§†åŒ–ä¼˜åŒ–è¿‡ç¨‹å¤±è´¥: {e}")
    
    def visualize_parameter_importance(self, output_path=None):
        """å¯è§†åŒ–å‚æ•°é‡è¦æ€§
        
        Args:
            output_path: å›¾è¡¨è¾“å‡ºè·¯å¾„
        """
        if not self.results or not self.best_params:
            logger_manager.warning("æ²¡æœ‰ä¼˜åŒ–ç»“æœå¯ä¾›å¯è§†åŒ–")
            return
        
        try:
            # åˆ†ææ¯ä¸ªå‚æ•°çš„å½±å“
            param_importance = {}
            
            for param_name in self.best_params.keys():
                # æ”¶é›†è¯¥å‚æ•°çš„æ‰€æœ‰å–å€¼å’Œå¯¹åº”çš„å¾—åˆ†
                param_values = {}
                
                for result in self.results:
                    param_value = result['params'].get(param_name)
                    score = result['score']
                    
                    if param_value not in param_values:
                        param_values[param_value] = []
                    
                    param_values[param_value].append(score)
                
                # è®¡ç®—æ¯ä¸ªå‚æ•°å€¼çš„å¹³å‡å¾—åˆ†
                param_avg_scores = {value: np.mean(scores) for value, scores in param_values.items()}
                
                # è®¡ç®—å‚æ•°é‡è¦æ€§ï¼ˆæœ€é«˜å¹³å‡åˆ†ä¸æœ€ä½å¹³å‡åˆ†çš„å·®å€¼ï¼‰
                if param_avg_scores:
                    max_score = max(param_avg_scores.values())
                    min_score = min(param_avg_scores.values())
                    importance = max_score - min_score
                    param_importance[param_name] = {
                        'importance': importance,
                        'avg_scores': param_avg_scores,
                        'best_value': self.best_params[param_name]
                    }
            
            # æŒ‰é‡è¦æ€§æ’åº
            sorted_params = sorted(param_importance.items(), key=lambda x: x[1]['importance'], reverse=True)
            
            # åˆ›å»ºå›¾è¡¨
            fig, axes = plt.subplots(len(sorted_params), 1, figsize=(10, 4 * len(sorted_params)))
            if len(sorted_params) == 1:
                axes = [axes]
            
            for i, (param_name, info) in enumerate(sorted_params):
                ax = axes[i]
                
                # å‡†å¤‡æ•°æ®
                values = []
                scores = []
                colors = []
                
                for value, score in info['avg_scores'].items():
                    values.append(str(value))
                    scores.append(score)
                    # æœ€ä½³å€¼ç”¨çº¢è‰²æ ‡è®°
                    if value == info['best_value']:
                        colors.append('red')
                    else:
                        colors.append('skyblue')
                
                # ç»˜åˆ¶æ¡å½¢å›¾
                bars = ax.bar(values, scores, color=colors, alpha=0.7)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar in bars:
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'{height:.4f}', ha='center', va='bottom', fontsize=8)
                
                # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
                ax.set_title(f'å‚æ•° {param_name} çš„å½±å“ (é‡è¦æ€§: {info["importance"]:.4f})')
                ax.set_ylabel('å¹³å‡å¾—åˆ†')
                ax.set_ylim(bottom=0)
                
                # æ ‡è®°æœ€ä½³å€¼
                best_idx = values.index(str(info['best_value']))
                ax.text(best_idx, scores[best_idx] / 2, 'æœ€ä½³', ha='center', color='white', fontweight='bold')
            
            plt.tight_layout()
            
            # ä¿å­˜æˆ–æ˜¾ç¤ºå›¾è¡¨
            if output_path:
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                plt.savefig(output_path)
                logger_manager.info(f"å‚æ•°é‡è¦æ€§å›¾è¡¨å·²ä¿å­˜åˆ° {output_path}")
            else:
                plt.show()
                
        except Exception as e:
            logger_manager.error(f"å¯è§†åŒ–å‚æ•°é‡è¦æ€§å¤±è´¥: {e}")
    
    def save_results(self, output_path):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ
        
        Args:
            output_path: ç»“æœè¾“å‡ºè·¯å¾„
        """
        try:
            # å‡†å¤‡ç»“æœæ•°æ®
            result_data = {
                'best_params': self.best_params,
                'best_score': self.best_score,
                'optimization_method': self.optimization_method,
                'param_space': self.param_space,
                'results': self.results,
                'timestamp': datetime.now().isoformat()
            }
            
            # ä¿å­˜ä¸ºJSON
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            logger_manager.info(f"ä¼˜åŒ–ç»“æœå·²ä¿å­˜åˆ° {output_path}")
            
        except Exception as e:
            logger_manager.error(f"ä¿å­˜ä¼˜åŒ–ç»“æœå¤±è´¥: {e}")
    
    def load_results(self, input_path):
        """åŠ è½½ä¼˜åŒ–ç»“æœ
        
        Args:
            input_path: ç»“æœè¾“å…¥è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(input_path):
                logger_manager.error(f"ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
                return False
            
            # åŠ è½½JSON
            with open(input_path, 'r', encoding='utf-8') as f:
                load_data = json.load(f)
            
            # æ›´æ–°ä¼˜åŒ–ç»“æœ
            self.best_params = load_data.get('best_params')
            self.best_score = load_data.get('best_score')
            self.results = load_data.get('results', [])
            
            logger_manager.info(f"ä¼˜åŒ–ç»“æœå·²ä» {input_path} åŠ è½½")
            
            # ä½¿ç”¨æœ€ä½³å‚æ•°åˆ›å»ºæ¨¡å‹
            if self.best_params:
                try:
                    self.best_model = self.model_creator(**self.best_params)
                    logger_manager.info(f"å·²ä½¿ç”¨æœ€ä½³å‚æ•°åˆ›å»ºæ¨¡å‹")
                except Exception as e:
                    logger_manager.error(f"ä½¿ç”¨æœ€ä½³å‚æ•°åˆ›å»ºæ¨¡å‹å¤±è´¥: {e}")
            
            return True
            
        except Exception as e:
            logger_manager.error(f"åŠ è½½ä¼˜åŒ–ç»“æœå¤±è´¥: {e}")
            return False


# ç¤ºä¾‹æ¨¡å‹ç±»
class SimplePredictor:
    """ç®€å•é¢„æµ‹æ¨¡å‹ï¼Œç”¨äºæµ‹è¯•å‚æ•°ä¼˜åŒ–"""
    
    def __init__(self, weight_frequency=0.5, weight_missing=0.3, weight_hot_cold=0.2):
        """åˆå§‹åŒ–ç®€å•é¢„æµ‹æ¨¡å‹
        
        Args:
            weight_frequency: é¢‘ç‡æƒé‡
            weight_missing: é—æ¼æƒé‡
            weight_hot_cold: å†·çƒ­æƒé‡
        """
        self.weight_frequency = weight_frequency
        self.weight_missing = weight_missing
        self.weight_hot_cold = weight_hot_cold
        
        # ç»Ÿè®¡æ•°æ®
        self.frequency_stats = None
        self.missing_stats = None
        self.hot_cold_stats = None
    
    def fit(self, train_data):
        """è®­ç»ƒæ¨¡å‹
        
        Args:
            train_data: è®­ç»ƒæ•°æ®
        """
        # è®¡ç®—é¢‘ç‡ç»Ÿè®¡
        front_counter = {}
        back_counter = {}
        
        for _, row in train_data.iterrows():
            front_balls, back_balls = data_manager.parse_balls(row)
            
            for ball in front_balls:
                front_counter[ball] = front_counter.get(ball, 0) + 1
            
            for ball in back_balls:
                back_counter[ball] = back_counter.get(ball, 0) + 1
        
        # å½’ä¸€åŒ–é¢‘ç‡
        total_front = sum(front_counter.values()) if front_counter else 0
        total_back = sum(back_counter.values()) if back_counter else 0
        
        self.frequency_stats = {
            'front': {ball: count/total_front if total_front > 0 else 0 for ball, count in front_counter.items()},
            'back': {ball: count/total_back if total_back > 0 else 0 for ball, count in back_counter.items()}
        }
        
        # è®¡ç®—é—æ¼ç»Ÿè®¡
        front_missing = {i: 0 for i in range(1, 36)}
        back_missing = {i: 0 for i in range(1, 13)}
        
        for i, row in train_data.iterrows():
            front_balls, back_balls = data_manager.parse_balls(row)
            
            for ball in range(1, 36):
                if ball in front_balls:
                    front_missing[ball] = 0
                else:
                    front_missing[ball] += 1
            
            for ball in range(1, 13):
                if ball in back_balls:
                    back_missing[ball] = 0
                else:
                    back_missing[ball] += 1
        
        # å½’ä¸€åŒ–é—æ¼å€¼ï¼ˆå€’æ•°ï¼Œé—æ¼è¶Šå¤§ï¼Œå€¼è¶Šå°ï¼‰
        max_front_missing = max(front_missing.values()) if front_missing else 1
        max_back_missing = max(back_missing.values()) if back_missing else 1
        
        self.missing_stats = {
            'front': {ball: 1 - missing/max_front_missing if max_front_missing > 0 else 0 for ball, missing in front_missing.items()},
            'back': {ball: 1 - missing/max_back_missing if max_back_missing > 0 else 0 for ball, missing in back_missing.items()}
        }
        
        # è®¡ç®—å†·çƒ­ç»Ÿè®¡
        front_avg = np.mean(list(self.frequency_stats['front'].values())) if self.frequency_stats['front'] else 0
        back_avg = np.mean(list(self.frequency_stats['back'].values())) if self.frequency_stats['back'] else 0
        
        self.hot_cold_stats = {
            'front': {ball: 1 if freq > front_avg else 0 for ball, freq in self.frequency_stats['front'].items()},
            'back': {ball: 1 if freq > back_avg else 0 for ball, freq in self.frequency_stats['back'].items()}
        }
    
    def predict(self, data=None):
        """é¢„æµ‹ä¸‹ä¸€æœŸå·ç 
        
        Args:
            data: å†å²æ•°æ®ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            List[Tuple[List[int], List[int]]]: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        if self.frequency_stats is None or self.missing_stats is None or self.hot_cold_stats is None:
            return []
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        front_scores = {}
        back_scores = {}
        
        for ball in range(1, 36):
            # é¢‘ç‡å¾—åˆ†
            freq_score = self.frequency_stats['front'].get(ball, 0)
            # é—æ¼å¾—åˆ†
            missing_score = self.missing_stats['front'].get(ball, 0)
            # å†·çƒ­å¾—åˆ†
            hot_cold_score = self.hot_cold_stats['front'].get(ball, 0)
            
            # ç»¼åˆå¾—åˆ†
            front_scores[ball] = self.weight_frequency * freq_score + \
                               self.weight_missing * missing_score + \
                               self.weight_hot_cold * hot_cold_score
        
        for ball in range(1, 13):
            # é¢‘ç‡å¾—åˆ†
            freq_score = self.frequency_stats['back'].get(ball, 0)
            # é—æ¼å¾—åˆ†
            missing_score = self.missing_stats['back'].get(ball, 0)
            # å†·çƒ­å¾—åˆ†
            hot_cold_score = self.hot_cold_stats['back'].get(ball, 0)
            
            # ç»¼åˆå¾—åˆ†
            back_scores[ball] = self.weight_frequency * freq_score + \
                              self.weight_missing * missing_score + \
                              self.weight_hot_cold * hot_cold_score
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å·ç 
        front_sorted = sorted(front_scores.items(), key=lambda x: x[1], reverse=True)
        back_sorted = sorted(back_scores.items(), key=lambda x: x[1], reverse=True)
        
        front_balls = [ball for ball, _ in front_sorted[:5]]
        back_balls = [ball for ball, _ in back_sorted[:2]]
        
        return [(sorted(front_balls), sorted(back_balls))]


if __name__ == "__main__":
    # æµ‹è¯•å‚æ•°ä¼˜åŒ–
    print("ğŸ” æµ‹è¯•å‚æ•°ä¼˜åŒ–æ¡†æ¶...")
    
    # å®šä¹‰å‚æ•°ç©ºé—´
    param_space = {
        'weight_frequency': [0.1, 0.3, 0.5, 0.7, 0.9],
        'weight_missing': [0.1, 0.2, 0.3, 0.4, 0.5],
        'weight_hot_cold': [0.1, 0.2, 0.3, 0.4, 0.5]
    }
    
    # å®šä¹‰æ¨¡å‹åˆ›å»ºå‡½æ•°
    def create_model(**params):
        return SimplePredictor(**params)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = ModelOptimizer(
        model_creator=create_model,
        param_space=param_space,
        optimization_method='grid'
    )
    
    # æ‰§è¡Œä¼˜åŒ–
    print("\nğŸ“Š æ‰§è¡Œç½‘æ ¼æœç´¢ä¼˜åŒ–...")
    result = optimizer.optimize(train_periods=300, val_periods=50, metric='accuracy')
    
    # æ‰“å°æœ€ä½³å‚æ•°
    print(f"\nğŸ† æœ€ä½³å‚æ•°: {optimizer.best_params}")
    print(f"ğŸ¯ æœ€ä½³å¾—åˆ†: {optimizer.best_score:.4f}")
    
    # å¯è§†åŒ–ä¼˜åŒ–è¿‡ç¨‹
    print("\nğŸ“ˆ å¯è§†åŒ–ä¼˜åŒ–è¿‡ç¨‹...")
    optimizer.visualize_optimization_process("output/parameter_optimization.png")
    
    # å¯è§†åŒ–å‚æ•°é‡è¦æ€§
    print("\nğŸ“Š å¯è§†åŒ–å‚æ•°é‡è¦æ€§...")
    optimizer.visualize_parameter_importance("output/parameter_importance.png")
    
    # ä½¿ç”¨åŸºå‡†æµ‹è¯•æ¡†æ¶è¯„ä¼°æœ€ä½³æ¨¡å‹
    if optimizer.benchmark is not None:
        print("\nğŸ” ä½¿ç”¨åŸºå‡†æµ‹è¯•æ¡†æ¶è¯„ä¼°æœ€ä½³æ¨¡å‹...")
        benchmark_result = optimizer.benchmark_best_model("ä¼˜åŒ–åçš„ç®€å•é¢„æµ‹å™¨", test_periods=20)
        
        # æ¯”è¾ƒåŸºå‡†æ¨¡å‹å’Œä¼˜åŒ–æ¨¡å‹
        print("\nğŸ”„ æ¯”è¾ƒåŸºå‡†æ¨¡å‹å’Œä¼˜åŒ–æ¨¡å‹...")
        optimizer.benchmark.register_model(
            "åŸºå‡†ç®€å•é¢„æµ‹å™¨",
            lambda data: SimplePredictor().fit(data) or SimplePredictor().predict(data),
            "æœªä¼˜åŒ–çš„ç®€å•é¢„æµ‹å™¨",
            "baseline"
        )
        optimizer.benchmark.evaluate_model("åŸºå‡†ç®€å•é¢„æµ‹å™¨", test_periods=20)
        optimizer.benchmark.compare_models(categories=["baseline", "optimized"])
    
    # ä¿å­˜ä¼˜åŒ–ç»“æœ
    print("\nğŸ’¾ ä¿å­˜ä¼˜åŒ–ç»“æœ...")
    optimizer.save_results("output/parameter_optimization.json")
    
    print("\nâœ… å‚æ•°ä¼˜åŒ–æµ‹è¯•å®Œæˆ")