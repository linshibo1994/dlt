#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿ - ä¼˜åŒ–ç‰ˆä¸»ç¨‹åº
æ”¯æŒå»¶è¿ŸåŠ è½½ï¼Œé¿å…å¯åŠ¨æ—¶é—´è¿‡é•¿
"""

import argparse
import sys
import os
from datetime import datetime
from typing import List, Dict

# åªå¯¼å…¥æ ¸å¿ƒæ¨¡å—
from core_modules import cache_manager, logger_manager, data_manager, task_manager


class DLTPredictorSystem:
    """å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self):
        self.analyzers = {}
        self.predictors = {}
        self.adaptive_predictor = None
        
        # å»¶è¿ŸåŠ è½½æ ‡å¿—
        self._analyzers_loaded = False
        self._predictors_loaded = False
        self._adaptive_loaded = False
    
    def _load_analyzers(self):
        """å»¶è¿ŸåŠ è½½åˆ†æå™¨"""
        if not self._analyzers_loaded:
            print("ğŸ“Š åŠ è½½åˆ†æå™¨æ¨¡å—...")
            from analyzer_modules import basic_analyzer, advanced_analyzer, comprehensive_analyzer, visualization_analyzer
            self.analyzers = {
                'basic': basic_analyzer,
                'advanced': advanced_analyzer,
                'comprehensive': comprehensive_analyzer,
                'visualization': visualization_analyzer
            }
            self._analyzers_loaded = True
    
    def _load_predictors(self):
        """å»¶è¿ŸåŠ è½½é¢„æµ‹å™¨"""
        if not self._predictors_loaded:
            print("ğŸ¯ åŠ è½½é¢„æµ‹å™¨æ¨¡å—...")
            from predictor_modules import get_traditional_predictor, get_advanced_predictor, get_super_predictor, CompoundPredictor
            self.predictors = {
                'traditional': get_traditional_predictor(),
                'advanced': get_advanced_predictor(),
                'super': get_super_predictor(),
                'compound': CompoundPredictor()
            }
            self._predictors_loaded = True
    
    def _load_adaptive_predictor(self):
        """å»¶è¿ŸåŠ è½½è‡ªé€‚åº”é¢„æµ‹å™¨"""
        if not self._adaptive_loaded:
            print("ğŸš€ åŠ è½½è‡ªé€‚åº”å­¦ä¹ æ¨¡å—...")
            from adaptive_learning_modules import enhanced_adaptive_predictor
            self.adaptive_predictor = enhanced_adaptive_predictor
            self._adaptive_loaded = True
    
    def run_data_command(self, args):
        """å¤„ç†æ•°æ®ç®¡ç†å‘½ä»¤"""
        if args.data_action == 'status':
            print("ğŸ“Š æ•°æ®çŠ¶æ€:")
            stats = data_manager.get_stats()
            print(f"  æ€»æœŸæ•°: {stats.get('total_periods', 0)}")
            print(f"  æ•°æ®èŒƒå›´: {stats.get('date_range', {}).get('start', 'N/A')} åˆ° {stats.get('date_range', {}).get('end', 'N/A')}")
            print(f"  æœ€æ–°æœŸå·: {stats.get('latest_issue', 'N/A')}")

            # ç¼“å­˜ä¿¡æ¯
            cache_info = cache_manager.get_cache_info()
            print(f"\nğŸ’¾ ç¼“å­˜çŠ¶æ€:")
            print(f"  æ€»æ–‡ä»¶æ•°: {cache_info['total']['files']}")
            print(f"  æ€»å¤§å°: {cache_info['total']['size_mb']:.2f} MB")

        elif args.data_action == 'latest':
            print("ğŸ” è·å–æœ€æ–°å¼€å¥–ç»“æœ...")
            try:
                # è·å–æœ¬åœ°æœ€æ–°æ•°æ®
                df = data_manager.get_data()
                if df is not None and len(df) > 0:
                    latest_row = df.iloc[0]  # ç¬¬ä¸€è¡Œæ˜¯æœ€æ–°æ•°æ®
                    front_balls, back_balls = data_manager.parse_balls(latest_row)

                    print("âœ… æœ€æ–°å¼€å¥–ç»“æœ:")
                    print(f"  æœŸå·: {latest_row['issue']}")
                    print(f"  æ—¥æœŸ: {latest_row['date']}")
                    print(f"  å¼€å¥–å·ç : {' '.join([str(b).zfill(2) for b in front_balls])} + {' '.join([str(b).zfill(2) for b in back_balls])}")

                    # å¦‚æœæŒ‡å®šäº†æ¯”è¾ƒé€‰é¡¹
                    if hasattr(args, 'compare') and args.compare:
                        self._compare_with_latest(front_balls, back_balls)
                else:
                    print("âŒ æ²¡æœ‰æ‰¾åˆ°å¼€å¥–æ•°æ®")
            except Exception as e:
                print(f"âŒ è·å–æœ€æ–°å¼€å¥–ç»“æœå¤±è´¥: {e}")

        elif args.data_action == 'update':
            # å¤„ç†æ›´æ–°å‚æ•°
            periods = getattr(args, 'periods', None)

            print(f"ğŸ”„ æ›´æ–°æ•°æ® (æ•°æ®æº: {args.source}" + (f", æœŸæ•°: {periods}" if periods else "") + ")...")
            try:
                if args.source == 'zhcw':
                    from crawlers import ZhcwCrawler
                    crawler = ZhcwCrawler()
                    if periods:
                        # æ›´æ–°æŒ‡å®šæœŸæ•°
                        count = crawler.crawl_recent_data(periods)
                    else:
                        # æ›´æ–°æ‰€æœ‰æ•°æ®
                        count = crawler.crawl_all_data()
                elif args.source == '500':
                    from crawlers import Crawler500
                    crawler = Crawler500()
                    count = crawler.crawl_all_data()

                # æ¸…ç†ç¼“å­˜å¹¶é‡æ–°åŠ è½½æ•°æ®
                cache_manager.clear_cache('data')
                data_manager._load_data()
                print(f"âœ… æ•°æ®æ›´æ–°å®Œæˆï¼Œæ–°å¢ {count} æœŸæ•°æ®")
            except ImportError:
                print("âŒ çˆ¬è™«æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥crawlers.pyæ–‡ä»¶")
            except Exception as e:
                print(f"âŒ æ•°æ®æ›´æ–°å¤±è´¥: {e}")

    def _compare_with_latest(self, actual_front: List[int], actual_back: List[int]):
        """ä¸æœ€æ–°å¼€å¥–ç»“æœæ¯”è¾ƒ"""
        print("\nğŸ¯ å·ç æ¯”è¾ƒåŠŸèƒ½:")
        print("è¯·è¾“å…¥æ‚¨çš„å·ç è¿›è¡Œæ¯”è¾ƒ")

        try:
            # è¾“å…¥å‰åŒºå·ç 
            front_input = input("å‰åŒºå·ç  (5ä¸ªå·ç ï¼Œç”¨ç©ºæ ¼åˆ†éš”): ").strip()
            front_numbers = [int(x) for x in front_input.split()]

            if len(front_numbers) != 5:
                print("âŒ å‰åŒºå·ç å¿…é¡»æ˜¯5ä¸ª")
                return

            # è¾“å…¥ååŒºå·ç 
            back_input = input("ååŒºå·ç  (2ä¸ªå·ç ï¼Œç”¨ç©ºæ ¼åˆ†éš”): ").strip()
            back_numbers = [int(x) for x in back_input.split()]

            if len(back_numbers) != 2:
                print("âŒ ååŒºå·ç å¿…é¡»æ˜¯2ä¸ª")
                return

            # è®¡ç®—ä¸­å¥–æƒ…å†µ
            from adaptive_learning_modules import AccuracyTracker
            tracker = AccuracyTracker()
            prize_level, front_hits, back_hits = tracker._calculate_prize_level(
                front_numbers, back_numbers, actual_front, actual_back
            )

            print(f"\nğŸ† æ¯”è¾ƒç»“æœ:")
            print(f"  æ‚¨çš„å·ç : {' '.join([str(b).zfill(2) for b in front_numbers])} + {' '.join([str(b).zfill(2) for b in back_numbers])}")
            print(f"  å¼€å¥–å·ç : {' '.join([str(b).zfill(2) for b in actual_front])} + {' '.join([str(b).zfill(2) for b in actual_back])}")
            print(f"  å‰åŒºå‘½ä¸­: {front_hits} ä¸ª")
            print(f"  ååŒºå‘½ä¸­: {back_hits} ä¸ª")
            print(f"  ä¸­å¥–ç­‰çº§: {prize_level}")

        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nâš ï¸  æ“ä½œè¢«å–æ¶ˆ")
        except Exception as e:
            print(f"âŒ æ¯”è¾ƒå¤±è´¥: {e}")
    
    def run_analyze_command(self, args):
        """å¤„ç†åˆ†æå‘½ä»¤"""
        self._load_analyzers()
        
        print(f"ğŸ“Š å¼€å§‹{args.type}åˆ†æ (æœŸæ•°: {args.periods})...")
        
        try:
            if args.type == 'basic':
                # åŸºç¡€åˆ†æ
                freq_result = self.analyzers['basic'].frequency_analysis(args.periods)
                hot_cold_result = self.analyzers['basic'].hot_cold_analysis(args.periods)
                
                print("âœ… åŸºç¡€åˆ†æå®Œæˆ")
                print(f"  é¢‘ç‡åˆ†æ: {len(freq_result.get('front_frequency', {}))} ä¸ªå‰åŒºå·ç ")
                print(f"  å†·çƒ­åˆ†æ: çƒ­å· {len(hot_cold_result.get('front_hot', []))} ä¸ªï¼Œå†·å· {len(hot_cold_result.get('front_cold', []))} ä¸ª")
            
            elif args.type == 'advanced':
                # é«˜çº§åˆ†æ
                markov_result = self.analyzers['advanced'].markov_analysis(args.periods)
                bayesian_result = self.analyzers['advanced'].bayesian_analysis(args.periods)
                
                print("âœ… é«˜çº§åˆ†æå®Œæˆ")
                print(f"  é©¬å°”å¯å¤«åˆ†æ: {len(markov_result.get('front_transition_probs', {}))} ä¸ªè½¬ç§»æ¦‚ç‡")
                print(f"  è´å¶æ–¯åˆ†æ: åéªŒæ¦‚ç‡è®¡ç®—å®Œæˆ")
            
            elif args.type == 'comprehensive':
                # ç»¼åˆåˆ†æ
                comp_result = self.analyzers['comprehensive'].comprehensive_analysis(args.periods)
                
                print("âœ… ç»¼åˆåˆ†æå®Œæˆ")
                
                if args.report:
                    # ç”ŸæˆæŠ¥å‘Š
                    report = self.analyzers['comprehensive'].generate_analysis_report(args.periods)
                    print("\n" + report)
                    
                    # ä¿å­˜æŠ¥å‘Š
                    if args.save:
                        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                        output_dir = "output/reports"
                        os.makedirs(output_dir, exist_ok=True)

                        if args.save.endswith('.txt'):
                            filename = os.path.join(output_dir, args.save)
                        else:
                            filename = os.path.join(output_dir, f"{args.save}.txt")

                        with open(filename, 'w', encoding='utf-8') as f:
                            f.write(report)
                        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {filename}")

            # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            if hasattr(args, 'visualize') and args.visualize:
                print("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
                viz_success = self.analyzers['visualization'].generate_all_charts("output", args.periods)
                if viz_success:
                    print("âœ… å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼Œä¿å­˜åœ¨ output/ ç›®å½•")
                else:
                    print("âŒ å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå¤±è´¥")

        except Exception as e:
            logger_manager.error("åˆ†æå¤±è´¥", e)
            print(f"âŒ åˆ†æå¤±è´¥: {e}")
    
    def run_predict_command(self, args):
        """å¤„ç†é¢„æµ‹å‘½ä»¤"""
        self._load_predictors()
        
        print(f"ğŸ¯ å¼€å§‹{args.method}é¢„æµ‹ (æ³¨æ•°: {args.count})...")
        
        try:
            predictions = []
            
            if args.method in ['frequency', 'hot_cold', 'missing']:
                # ä¼ ç»Ÿé¢„æµ‹æ–¹æ³•
                if args.method == 'frequency':
                    results = self.predictors['traditional'].frequency_predict(args.count)
                elif args.method == 'hot_cold':
                    results = self.predictors['traditional'].hot_cold_predict(args.count)
                elif args.method == 'missing':
                    results = self.predictors['traditional'].missing_predict(args.count)
                
                predictions = [{'front_balls': r[0], 'back_balls': r[1], 'method': args.method} for r in results]
            
            elif args.method in ['markov', 'bayesian', 'ensemble']:
                # é«˜çº§é¢„æµ‹æ–¹æ³•
                if args.method == 'markov':
                    results = self.predictors['advanced'].markov_predict(args.count)
                elif args.method == 'bayesian':
                    results = self.predictors['advanced'].bayesian_predict(args.count)
                elif args.method == 'ensemble':
                    results = self.predictors['advanced'].ensemble_predict(args.count)
                
                predictions = [{'front_balls': r[0], 'back_balls': r[1], 'method': args.method} for r in results]
            
            elif args.method == 'super':
                # è¶…çº§é¢„æµ‹
                results = self.predictors['super'].predict_super(args.count)
                predictions = results
            
            elif args.method == 'adaptive':
                # è‡ªé€‚åº”é¢„æµ‹
                self._load_adaptive_predictor()
                results = self.adaptive_predictor.generate_enhanced_prediction(args.count)
                predictions = results

            elif args.method == 'compound':
                # å¤å¼æŠ•æ³¨é¢„æµ‹
                front_count = getattr(args, 'front_count', 8)
                back_count = getattr(args, 'back_count', 4)
                result = self.predictors['compound'].predict_compound(front_count, back_count, 'ensemble')
                if result:
                    predictions = [result]
                else:
                    predictions = []

            elif args.method == 'duplex':
                # èƒ†æ‹–æŠ•æ³¨é¢„æµ‹
                result = self.predictors['compound'].predict_duplex()
                if result:
                    predictions = [result]
                else:
                    predictions = []

            elif args.method == 'markov_custom':
                # é©¬å°”å¯å¤«è‡ªå®šä¹‰æœŸæ•°é¢„æµ‹
                analysis_periods = getattr(args, 'analysis_periods', 300)
                predict_periods = getattr(args, 'predict_periods', 1)
                results = self.predictors['advanced'].markov_predict_custom(
                    count=args.count,
                    analysis_periods=analysis_periods,
                    predict_periods=predict_periods
                )
                predictions = results

            elif args.method == 'mixed_strategy':
                # æ··åˆç­–ç•¥é¢„æµ‹
                strategy = getattr(args, 'strategy', 'balanced')
                results = self.predictors['advanced'].mixed_strategy_predict(
                    count=args.count,
                    strategy=strategy
                )
                predictions = results

            elif args.method == 'highly_integrated':
                # é«˜åº¦é›†æˆå¤å¼é¢„æµ‹
                front_count = getattr(args, 'front_count', 10)
                back_count = getattr(args, 'back_count', 5)
                integration_level = getattr(args, 'integration_level', 'ultimate')
                result = self.predictors['compound'].predict_highly_integrated_compound(
                    front_count=front_count,
                    back_count=back_count,
                    integration_level=integration_level
                )
                if result:
                    predictions = [result]
                else:
                    predictions = []

            elif args.method == 'advanced_integration':
                # é«˜çº§é›†æˆåˆ†æé¢„æµ‹
                integration_type = getattr(args, 'integration_type', 'comprehensive')
                results = self.predictors['advanced'].advanced_integration_predict(
                    count=args.count,
                    integration_type=integration_type
                )
                predictions = results

            elif args.method == 'nine_models':
                # 9ç§æ•°å­¦æ¨¡å‹é¢„æµ‹
                results = self.predictors['advanced'].nine_models_predict(count=args.count)
                predictions = results

            elif args.method == 'nine_models_compound':
                # 9ç§æ•°å­¦æ¨¡å‹å¤å¼é¢„æµ‹
                front_count = getattr(args, 'front_count', 8)
                back_count = getattr(args, 'back_count', 4)
                result = self.predictors['advanced'].nine_models_compound_predict(
                    front_count=front_count,
                    back_count=back_count
                )
                if result:
                    predictions = [result]
                else:
                    predictions = []

            elif args.method == 'markov_compound':
                # é©¬å°”å¯å¤«é“¾å¤å¼é¢„æµ‹
                front_count = getattr(args, 'front_count', 8)
                back_count = getattr(args, 'back_count', 4)
                markov_periods = getattr(args, 'markov_periods', 500)
                result = self.predictors['advanced'].markov_compound_predict(
                    front_count=front_count,
                    back_count=back_count,
                    analysis_periods=markov_periods
                )
                if result:
                    predictions = [result]
                else:
                    predictions = []

            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            print("âœ… é¢„æµ‹å®Œæˆ!")
            print("\nğŸ“‹ é¢„æµ‹ç»“æœ:")

            for i, pred in enumerate(predictions):
                if pred.get('front_dan'):
                    # èƒ†æ‹–æŠ•æ³¨æ˜¾ç¤º
                    front_dan_str = ' '.join([str(b).zfill(2) for b in pred['front_dan']])
                    front_tuo_str = ' '.join([str(b).zfill(2) for b in pred['front_tuo']])
                    back_dan_str = ' '.join([str(b).zfill(2) for b in pred['back_dan']])
                    back_tuo_str = ' '.join([str(b).zfill(2) for b in pred['back_tuo']])

                    print(f"  ç¬¬ {i+1} æ³¨èƒ†æ‹–:")
                    print(f"    å‰åŒº: {front_dan_str} + ({front_tuo_str})")
                    print(f"    ååŒº: {back_dan_str} + ({back_tuo_str})")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")

                elif pred.get('front_count'):
                    # å¤å¼æŠ•æ³¨æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    method_name = pred.get('method', 'compound').replace('_', ' ').title()
                    print(f"  ç¬¬ {i+1} æ³¨å¤å¼ ({method_name}): {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    ç½®ä¿¡åº¦: {pred.get('confidence', 0.5):.3f}")

                    # æ˜¾ç¤ºç‰¹å®šæ–¹æ³•çš„è¯¦ç»†ä¿¡æ¯
                    if pred.get('method') == 'nine_models_compound':
                        if 'models_used' in pred:
                            print(f"    ä½¿ç”¨æ¨¡å‹: {len(pred['models_used'])} ç§")
                        if 'model_details' in pred:
                            details = pred['model_details']
                            print(f"    ç»Ÿè®¡å­¦æƒé‡: {details.get('statistical_score', 0):.3f}")
                            print(f"    æ¦‚ç‡è®ºæƒé‡: {details.get('probability_score', 0):.3f}")
                            print(f"    é©¬å°”å¯å¤«æƒé‡: {details.get('markov_score', 0):.3f}")
                            print(f"    è´å¶æ–¯æƒé‡: {details.get('bayesian_score', 0):.3f}")

                    elif pred.get('method') == 'markov_compound':
                        print(f"    åˆ†ææœŸæ•°: {pred.get('analysis_periods', 500)}")
                        if 'markov_details' in pred:
                            details = pred['markov_details']
                            print(f"    è½¬ç§»çŸ©é˜µè§„æ¨¡: {details.get('transition_matrix_size', 0)}")
                            print(f"    çŠ¶æ€æ•°é‡: {details.get('state_count', 0)}")
                            print(f"    é¢„æµ‹å‡†ç¡®æ€§: {details.get('prediction_accuracy', 0):.3f}")

                    elif pred.get('integration_level'):
                        print(f"    é›†æˆçº§åˆ«: {pred['integration_level']}")
                        print(f"    ä½¿ç”¨ç®—æ³•: {len(pred.get('algorithms_used', []))} ç§")

                elif pred.get('overall_stability'):
                    # é©¬å°”å¯å¤«è‡ªå®šä¹‰é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  ç¬¬ {pred['index']} æ³¨ (æœŸ {pred['period']}): {front_str} + {back_str}")
                    print(f"    ç¨³å®šæ€§å¾—åˆ†: {pred['overall_stability']:.3f}")
                    print(f"    å‰åŒºç¨³å®šæ€§: {pred['front_stability']:.3f}")
                    print(f"    ååŒºç¨³å®šæ€§: {pred['back_stability']:.3f}")
                    print(f"    åˆ†ææœŸæ•°: {pred['analysis_periods']}")

                elif pred.get('strategy'):
                    # æ··åˆç­–ç•¥é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  ç¬¬ {pred['index']} æ³¨ ({pred['strategy']}ç­–ç•¥): {front_str} + {back_str}")
                    print(f"    é£é™©ç­‰çº§: {pred['risk_level']}")
                    print(f"    ç­–ç•¥æè¿°: {pred['description']}")
                    print(f"    æƒé‡é…ç½®: {pred['weights']}")

                elif pred.get('integration_level'):
                    # é«˜åº¦é›†æˆå¤å¼é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  é«˜åº¦é›†æˆå¤å¼ ({pred['integration_level']}çº§): {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    é›†æˆç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    print(f"    ä½¿ç”¨ç®—æ³•: {len(pred['algorithms_used'])} ç§")
                    if 'candidate_scores' in pred:
                        print(f"    å‰åŒºçƒ­é—¨: {list(pred['candidate_scores']['front_top10'].keys())[:5]}")
                        print(f"    ååŒºçƒ­é—¨: {list(pred['candidate_scores']['back_top8'].keys())[:3]}")

                elif pred.get('integration_type'):
                    # é«˜çº§é›†æˆåˆ†æé¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  ç¬¬ {pred['index']} æ³¨ ({pred['integration_type']}é›†æˆ): {front_str} + {back_str}")
                    print(f"    é›†æˆç±»å‹: {pred['integration_type']}")
                    print(f"    åˆ†ææ–¹æ³•: {pred['method']}")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    if 'analysis_source' in pred:
                        print(f"    åˆ†ææ—¶é—´: {pred['analysis_source']}")

                elif pred.get('method') == 'nine_mathematical_models':
                    # 9ç§æ•°å­¦æ¨¡å‹é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  ç¬¬ {pred['index']} æ³¨ (9ç§æ•°å­¦æ¨¡å‹): {front_str} + {back_str}")
                    print(f"    åˆ†ææ–¹æ³•: {pred['method']}")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    if 'models_used' in pred:
                        print(f"    ä½¿ç”¨æ¨¡å‹: {len(pred['models_used'])} ç§")
                    if 'model_consensus' in pred:
                        print(f"    æ¨¡å‹ä¸€è‡´æ€§: {pred['model_consensus']:.3f}")
                    if 'analysis_timestamp' in pred:
                        print(f"    åˆ†ææ—¶é—´: {pred['analysis_timestamp']}")

                elif pred.get('method') == 'nine_models_compound':
                    # 9ç§æ•°å­¦æ¨¡å‹å¤å¼é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  9ç§æ•°å­¦æ¨¡å‹å¤å¼: {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    if 'models_used' in pred:
                        print(f"    ä½¿ç”¨æ¨¡å‹: {len(pred['models_used'])} ç§")
                    if 'model_details' in pred:
                        details = pred['model_details']
                        print(f"    ç»Ÿè®¡å­¦æƒé‡: {details.get('statistical_score', 0):.3f}")
                        print(f"    æ¦‚ç‡è®ºæƒé‡: {details.get('probability_score', 0):.3f}")
                        print(f"    é©¬å°”å¯å¤«æƒé‡: {details.get('markov_score', 0):.3f}")
                        print(f"    è´å¶æ–¯æƒé‡: {details.get('bayesian_score', 0):.3f}")

                elif pred.get('method') and 'compound' in pred['method']:
                    # é€šç”¨å¤å¼é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    method_name = pred['method'].replace('_', ' ').title()
                    print(f"  {method_name}: {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")

                elif pred.get('method') == 'markov_compound':
                    # é©¬å°”å¯å¤«é“¾å¤å¼é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  é©¬å°”å¯å¤«é“¾å¤å¼: {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    print(f"    åˆ†ææœŸæ•°: {pred.get('analysis_periods', 500)}")
                    if 'markov_details' in pred:
                        details = pred['markov_details']
                        print(f"    è½¬ç§»çŸ©é˜µè§„æ¨¡: {details.get('transition_matrix_size', 0)}")
                        print(f"    çŠ¶æ€æ•°é‡: {details.get('state_count', 0)}")
                        print(f"    é¢„æµ‹å‡†ç¡®æ€§: {details.get('prediction_accuracy', 0):.3f}")

                else:
                    # å•å¼æŠ•æ³¨æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])
                    method = pred.get('method', args.method)
                    confidence = pred.get('confidence', 0.5)

                    print(f"  ç¬¬ {i+1} æ³¨: {front_str} + {back_str} (æ–¹æ³•: {method}, ç½®ä¿¡åº¦: {confidence:.3f})")

            # ä¿å­˜é¢„æµ‹ç»“æœ
            if args.save:
                import json

                # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                output_dir = "output/predictions"
                os.makedirs(output_dir, exist_ok=True)

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                if args.save.endswith('.json'):
                    filename = os.path.join(output_dir, args.save)
                else:
                    filename = os.path.join(output_dir, f"predictions_{args.method}_{timestamp}.json")

                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(predictions, f, ensure_ascii=False, indent=2, default=str)

                print(f"ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜: {filename}")
        
        except Exception as e:
            logger_manager.error("é¢„æµ‹å¤±è´¥", e)
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
    
    def run_learn_command(self, args):
        """å¤„ç†å­¦ä¹ å‘½ä»¤"""
        self._load_adaptive_predictor()
        
        print(f"ğŸš€ å¼€å§‹è‡ªé€‚åº”å­¦ä¹  (ç®—æ³•: {args.algorithm})...")
        print(f"ğŸ“Š èµ·å§‹æœŸæ•°: {args.start}, æµ‹è¯•æœŸæ•°: {args.test}")
        
        try:
            # è®¾ç½®å¤šè‡‚è€è™æœºç®—æ³•
            self.adaptive_predictor.bandit.algorithm = args.algorithm
            
            # è¿›è¡Œå­¦ä¹ 
            results = self.adaptive_predictor.enhanced_adaptive_learning(
                start_period=args.start,
                test_periods=args.test
            )
            
            if results:
                print("âœ… è‡ªé€‚åº”å­¦ä¹ å®Œæˆ!")
                print(f"ğŸ“Š ä¸­å¥–ç‡: {results['win_rate']:.3f}")
                print(f"ğŸ“ˆ å¹³å‡å¾—åˆ†: {results['average_score']:.2f}")
                print(f"ğŸ¯ æ€»æµ‹è¯•æœŸæ•°: {results['total_periods']}")
                
                # æ˜¾ç¤ºé¢„æµ‹å™¨æ€§èƒ½
                print("\nğŸ† é¢„æµ‹å™¨æ€§èƒ½æ’å:")
                bandit_values = results['bandit_final_values']
                predictor_names = self.adaptive_predictor.predictor_names
                
                performance_ranking = sorted(
                    zip(predictor_names, bandit_values), 
                    key=lambda x: x[1], 
                    reverse=True
                )
                
                for i, (name, value) in enumerate(performance_ranking[:5]):
                    print(f"  {i+1}. {name}: {value:.3f}")
                
                # ä¿å­˜å­¦ä¹ ç»“æœ
                output_dir = "output/learning"
                os.makedirs(output_dir, exist_ok=True)

                if args.save:
                    if args.save.endswith('.json'):
                        filename = os.path.join(output_dir, args.save)
                    else:
                        filename = os.path.join(output_dir, f"{args.save}.json")
                else:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = os.path.join(output_dir, f"learning_{args.algorithm}_{timestamp}.json")

                saved_file = self.adaptive_predictor.save_enhanced_results(filename)
                if saved_file:
                    print(f"ğŸ’¾ å­¦ä¹ ç»“æœå·²ä¿å­˜: {saved_file}")
            else:
                print("âŒ è‡ªé€‚åº”å­¦ä¹ å¤±è´¥")
        
        except Exception as e:
            logger_manager.error("å­¦ä¹ å¤±è´¥", e)
            print(f"âŒ å­¦ä¹ å¤±è´¥: {e}")
    
    def run_smart_command(self, args):
        """å¤„ç†æ™ºèƒ½é¢„æµ‹å‘½ä»¤"""
        self._load_adaptive_predictor()

        # ç¡®å®šé¢„æµ‹ç±»å‹
        if args.compound:
            print(f"ğŸ§  æ™ºèƒ½å¤å¼é¢„æµ‹ ({args.front_count}+{args.back_count})...")
        elif args.duplex:
            print(f"ğŸ§  æ™ºèƒ½èƒ†æ‹–é¢„æµ‹ (å‰åŒº{args.front_dan}èƒ†{args.front_tuo}æ‹–, ååŒº{args.back_dan}èƒ†{args.back_tuo}æ‹–)...")
        else:
            print(f"ğŸ§  æ™ºèƒ½é¢„æµ‹ (æ³¨æ•°: {args.count})...")

        try:
            # åŠ è½½å­¦ä¹ ç»“æœ
            if args.load:
                if self.adaptive_predictor.load_enhanced_results(args.load):
                    print(f"âœ… å·²åŠ è½½å­¦ä¹ ç»“æœ: {args.load}")
                else:
                    print(f"âŒ åŠ è½½å­¦ä¹ ç»“æœå¤±è´¥: {args.load}")
                    return
            else:
                print("âš ï¸  æœªåŠ è½½å­¦ä¹ ç»“æœï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

            # æ ¹æ®ç±»å‹ç”Ÿæˆé¢„æµ‹
            if args.compound:
                # å¤å¼æŠ•æ³¨é¢„æµ‹
                result = self.adaptive_predictor.smart_predict_compound(
                    front_count=args.front_count,
                    back_count=args.back_count
                )

                if result:
                    print("âœ… æ™ºèƒ½å¤å¼é¢„æµ‹å®Œæˆ!")
                    print("\nğŸ§  æ™ºèƒ½å¤å¼é¢„æµ‹ç»“æœ:")

                    front_str = ' '.join([str(b).zfill(2) for b in result['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in result['back_balls']])

                    print(f"  å¤å¼å·ç : {front_str} + {back_str}")
                    print(f"  å‰åŒº: {result['front_count']} ä¸ªå·ç ")
                    print(f"  ååŒº: {result['back_count']} ä¸ªå·ç ")
                    print(f"  æ€»ç»„åˆæ•°: {result['total_combinations']} æ³¨")
                    print(f"  æ€»æŠ•æ³¨é¢: {result['total_cost']} å…ƒ")
                    print(f"  ç½®ä¿¡åº¦: {result['confidence']:.3f}")
                    print(f"  ä½¿ç”¨é¢„æµ‹å™¨: {result['top_predictors']}")
                else:
                    print("âŒ æ™ºèƒ½å¤å¼é¢„æµ‹å¤±è´¥")

            elif args.duplex:
                # èƒ†æ‹–æŠ•æ³¨é¢„æµ‹
                result = self.adaptive_predictor.smart_predict_duplex(
                    front_dan_count=args.front_dan,
                    back_dan_count=args.back_dan,
                    front_tuo_count=args.front_tuo,
                    back_tuo_count=args.back_tuo
                )

                if result:
                    print("âœ… æ™ºèƒ½èƒ†æ‹–é¢„æµ‹å®Œæˆ!")
                    print("\nğŸ§  æ™ºèƒ½èƒ†æ‹–é¢„æµ‹ç»“æœ:")

                    front_dan_str = ' '.join([str(b).zfill(2) for b in result['front_dan']])
                    front_tuo_str = ' '.join([str(b).zfill(2) for b in result['front_tuo']])
                    back_dan_str = ' '.join([str(b).zfill(2) for b in result['back_dan']])
                    back_tuo_str = ' '.join([str(b).zfill(2) for b in result['back_tuo']])

                    print(f"  å‰åŒºèƒ†ç : {front_dan_str}")
                    print(f"  å‰åŒºæ‹–ç : {front_tuo_str}")
                    print(f"  ååŒºèƒ†ç : {back_dan_str}")
                    print(f"  ååŒºæ‹–ç : {back_tuo_str}")
                    print(f"  æ€»ç»„åˆæ•°: {result['total_combinations']} æ³¨")
                    print(f"  æ€»æŠ•æ³¨é¢: {result['total_cost']} å…ƒ")
                    print(f"  ç½®ä¿¡åº¦: {result['confidence']:.3f}")
                    print(f"  æœ€ä¼˜é¢„æµ‹å™¨: {result['best_predictor']}")
                else:
                    print("âŒ æ™ºèƒ½èƒ†æ‹–é¢„æµ‹å¤±è´¥")

            else:
                # å•å¼æŠ•æ³¨é¢„æµ‹
                predictions = self.adaptive_predictor.generate_enhanced_prediction(args.count)

                if predictions:
                    print("âœ… æ™ºèƒ½é¢„æµ‹å®Œæˆ!")
                    print("\nğŸ§  æ™ºèƒ½é¢„æµ‹ç»“æœ:")

                    for pred in predictions:
                        front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                        back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])
                        predictor = pred['predictor_used']
                        confidence = pred['confidence']
                        expected_reward = pred['expected_reward']

                        print(f"  ç¬¬ {pred['index']} æ³¨: {front_str} + {back_str}")
                        print(f"    é¢„æµ‹å™¨: {predictor}")
                        print(f"    ç½®ä¿¡åº¦: {confidence:.3f}")
                        print(f"    æœŸæœ›å¥–åŠ±: {expected_reward:.3f}")
                else:
                    print("âŒ æ™ºèƒ½é¢„æµ‹å¤±è´¥")

        except Exception as e:
            logger_manager.error("æ™ºèƒ½é¢„æµ‹å¤±è´¥", e)
            print(f"âŒ æ™ºèƒ½é¢„æµ‹å¤±è´¥: {e}")

    def run_optimize_command(self, args):
        """å¤„ç†å‚æ•°ä¼˜åŒ–å‘½ä»¤"""
        self._load_adaptive_predictor()

        print(f"âš™ï¸ å‚æ•°ä¼˜åŒ– (æµ‹è¯•æœŸæ•°: {args.test_periods}, ä¼˜åŒ–è½®æ•°: {args.rounds})...")

        try:
            # è¿›è¡Œå‚æ•°ä¼˜åŒ–
            results = self.adaptive_predictor.parameter_optimization(
                test_periods=args.test_periods,
                optimization_rounds=args.rounds
            )

            if results:
                print("âœ… å‚æ•°ä¼˜åŒ–å®Œæˆ!")
                print(f"\nğŸ† æœ€ä½³å‚æ•°:")
                for param, value in results['best_params'].items():
                    print(f"  {param}: {value}")

                print(f"\nğŸ“Š æœ€ä½³å¾—åˆ†: {results['best_score']:.3f}")

                print(f"\nğŸ“ˆ ä¼˜åŒ–å†å²:")
                for history in results['optimization_history'][-5:]:  # æ˜¾ç¤ºæœ€å5è½®
                    print(f"  è½®æ¬¡ {history['round']}: å¾—åˆ† {history['score']:.3f}, ä¸­å¥–ç‡ {history['win_rate']:.3f}")

                # ä¿å­˜ä¼˜åŒ–ç»“æœ
                if args.save:
                    import json

                    output_dir = "output/optimization"
                    os.makedirs(output_dir, exist_ok=True)

                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    if args.save.endswith('.json'):
                        filename = os.path.join(output_dir, args.save)
                    else:
                        filename = os.path.join(output_dir, f"optimization_{timestamp}.json")

                    with open(filename, 'w', encoding='utf-8') as f:
                        json.dump(results, f, ensure_ascii=False, indent=2, default=str)

                    print(f"ğŸ’¾ ä¼˜åŒ–ç»“æœå·²ä¿å­˜: {filename}")
            else:
                print("âŒ å‚æ•°ä¼˜åŒ–å¤±è´¥")

        except Exception as e:
            logger_manager.error("å‚æ•°ä¼˜åŒ–å¤±è´¥", e)
            print(f"âŒ å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")

    def run_backtest_command(self, args):
        """å¤„ç†å›æµ‹å‘½ä»¤"""
        self._load_predictors()

        print(f"ğŸ“ˆ å¼€å§‹å†å²å›æµ‹ (æ–¹æ³•: {args.method})...")
        print(f"ğŸ“Š èµ·å§‹æœŸæ•°: {args.start}, æµ‹è¯•æœŸæ•°: {args.test}")

        try:
            from adaptive_learning_modules import AccuracyTracker

            # åˆ›å»ºå‡†ç¡®ç‡è·Ÿè¸ªå™¨
            tracker = AccuracyTracker()

            # è·å–æ•°æ®
            df = data_manager.get_data()
            if df is None or len(df) < args.start + args.test:
                print("âŒ æ•°æ®ä¸è¶³")
                return

            total_predictions = 0
            total_wins = 0
            prize_stats = {}

            print(f"ğŸ”„ å¼€å§‹å›æµ‹...")

            for i in range(args.test):
                period_idx = args.start + i

                if period_idx >= len(df):
                    break

                # è·å–å½“å‰æœŸçš„çœŸå®å¼€å¥–å·ç 
                current_row = df.iloc[period_idx]
                actual_front, actual_back = data_manager.parse_balls(current_row)

                # è¿›è¡Œé¢„æµ‹
                try:
                    if args.method in ['frequency', 'hot_cold', 'missing']:
                        if args.method == 'frequency':
                            result = self.predictors['traditional'].frequency_predict(1)
                        elif args.method == 'hot_cold':
                            result = self.predictors['traditional'].hot_cold_predict(1)
                        elif args.method == 'missing':
                            result = self.predictors['traditional'].missing_predict(1)

                        predicted_front, predicted_back = result[0]

                    elif args.method in ['markov', 'bayesian', 'ensemble']:
                        if args.method == 'markov':
                            result = self.predictors['advanced'].markov_predict(1)
                        elif args.method == 'bayesian':
                            result = self.predictors['advanced'].bayesian_predict(1)
                        elif args.method == 'ensemble':
                            result = self.predictors['advanced'].ensemble_predict(1)

                        predicted_front, predicted_back = result[0]

                    else:
                        print(f"âŒ ä¸æ”¯æŒçš„å›æµ‹æ–¹æ³•: {args.method}")
                        return

                    # è®¡ç®—ä¸­å¥–æƒ…å†µ
                    prize_level, front_hits, back_hits = tracker._calculate_prize_level(
                        predicted_front, predicted_back, actual_front, actual_back
                    )

                    total_predictions += 1
                    if prize_level != "æœªä¸­å¥–":
                        total_wins += 1

                    # ç»Ÿè®¡ä¸­å¥–ç­‰çº§
                    prize_stats[prize_level] = prize_stats.get(prize_level, 0) + 1

                    # æ˜¾ç¤ºè¿›åº¦
                    if (i + 1) % 50 == 0:
                        win_rate = total_wins / total_predictions
                        print(f"  è¿›åº¦: {i+1}/{args.test}, ä¸­å¥–ç‡: {win_rate:.3f}")

                except Exception as e:
                    logger_manager.error(f"ç¬¬ {i+1} æœŸå›æµ‹å¤±è´¥", e)
                    continue

            # æ˜¾ç¤ºå›æµ‹ç»“æœ
            print("âœ… å›æµ‹å®Œæˆ!")
            print(f"\nğŸ“Š å›æµ‹ç»“æœç»Ÿè®¡:")
            print(f"  æ€»é¢„æµ‹æœŸæ•°: {total_predictions}")
            print(f"  ä¸­å¥–æœŸæ•°: {total_wins}")
            print(f"  ä¸­å¥–ç‡: {total_wins/total_predictions:.3f}" if total_predictions > 0 else "  ä¸­å¥–ç‡: 0.000")

            print(f"\nğŸ† ä¸­å¥–ç­‰çº§åˆ†å¸ƒ:")
            for prize, count in sorted(prize_stats.items()):
                rate = count / total_predictions if total_predictions > 0 else 0
                print(f"  {prize}: {count} æ¬¡ ({rate:.3f})")

        except Exception as e:
            logger_manager.error("å›æµ‹å¤±è´¥", e)
            print(f"âŒ å›æµ‹å¤±è´¥: {e}")

    def run_system_command(self, args):
        """å¤„ç†ç³»ç»Ÿç®¡ç†å‘½ä»¤"""
        if args.system_action == 'cache':
            if args.action == 'info':
                print("ğŸ’¾ ç¼“å­˜ä¿¡æ¯:")
                cache_info = cache_manager.get_cache_info()

                for cache_type in ['models', 'analysis', 'data']:
                    info = cache_info[cache_type]
                    print(f"  {cache_type}: {info['files']} ä¸ªæ–‡ä»¶, {info['size_mb']:.2f} MB")

                print(f"  æ€»è®¡: {cache_info['total']['files']} ä¸ªæ–‡ä»¶, {cache_info['total']['size_mb']:.2f} MB")

            elif args.action == 'clear':
                print(f"ğŸ—‘ï¸  æ¸…ç†{args.type}ç¼“å­˜...")
                cleared_count = cache_manager.clear_cache(args.type)
                print(f"âœ… å·²æ¸…ç† {cleared_count} ä¸ªç¼“å­˜æ–‡ä»¶")
    
    def show_version(self):
        """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
        print("ğŸ¯ å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿ")
        print("ç‰ˆæœ¬: 2.0.0")
        print("ä½œè€…: AI Assistant")
        print("æ›´æ–°æ—¶é—´: 2024-12-19")
        print("\nğŸ“¦ åŠŸèƒ½æ¨¡å—:")
        print("  âœ… æ•°æ®çˆ¬å–ä¸ç®¡ç†")
        print("  âœ… åŸºç¡€ä¸é«˜çº§åˆ†æ")
        print("  âœ… å¤šç§é¢„æµ‹ç®—æ³•")
        print("  âœ… è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿ")
        print("  âœ… æ™ºèƒ½é¢„æµ‹ä¸å›æµ‹")
        print("  âœ… ç¼“å­˜ä¸æ—¥å¿—ç®¡ç†")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿ - ä¼˜åŒ–ç‰ˆ")
    
    # æ·»åŠ å­å‘½ä»¤
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ==================== æ•°æ®ç®¡ç†å‘½ä»¤ ====================
    data_parser = subparsers.add_parser('data', help='æ•°æ®ç®¡ç†')
    data_subparsers = data_parser.add_subparsers(dest='data_action', help='æ•°æ®æ“ä½œ')

    # æ•°æ®çŠ¶æ€
    data_status_parser = data_subparsers.add_parser('status', help='æŸ¥çœ‹æ•°æ®çŠ¶æ€')

    # æœ€æ–°å¼€å¥–ç»“æœ
    data_latest_parser = data_subparsers.add_parser('latest', help='è·å–æœ€æ–°å¼€å¥–ç»“æœ')
    data_latest_parser.add_argument('--compare', action='store_true', help='ä¸ç”¨æˆ·å·ç æ¯”è¾ƒ')

    # æ•°æ®æ›´æ–°
    data_update_parser = data_subparsers.add_parser('update', help='æ›´æ–°æ•°æ®')
    data_update_parser.add_argument('--source', choices=['zhcw', '500'], default='zhcw', help='æ•°æ®æº')
    data_update_parser.add_argument('--periods', type=int, help='æ›´æ–°æŒ‡å®šæœŸæ•°')
    
    # ==================== åˆ†æå‘½ä»¤ ====================
    analyze_parser = subparsers.add_parser('analyze', help='æ•°æ®åˆ†æ')
    analyze_parser.add_argument('-t', '--type', choices=['basic', 'advanced', 'comprehensive'],
                               default='comprehensive', help='åˆ†æç±»å‹')
    analyze_parser.add_argument('-p', '--periods', type=int, default=500, help='åˆ†ææœŸæ•°')
    analyze_parser.add_argument('--report', action='store_true', help='ç”Ÿæˆåˆ†ææŠ¥å‘Š')
    analyze_parser.add_argument('--visualize', action='store_true', help='ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨')
    analyze_parser.add_argument('--save', help='ä¿å­˜åˆ†æç»“æœ')

    # ==================== é¢„æµ‹å‘½ä»¤ ====================
    predict_parser = subparsers.add_parser('predict', help='å·ç é¢„æµ‹')
    predict_parser.add_argument('-m', '--method',
                               choices=['frequency', 'hot_cold', 'missing', 'markov', 'bayesian',
                                       'ensemble', 'super', 'adaptive', 'compound', 'duplex', 'markov_custom', 'mixed_strategy', 'highly_integrated', 'advanced_integration', 'nine_models', 'nine_models_compound', 'markov_compound'],
                               default='ensemble', help='é¢„æµ‹æ–¹æ³•')
    predict_parser.add_argument('-c', '--count', type=int, default=1, help='ç”Ÿæˆæ³¨æ•°')
    predict_parser.add_argument('--front-count', type=int, default=8, help='å¤å¼æŠ•æ³¨å‰åŒºå·ç æ•°é‡')
    predict_parser.add_argument('--back-count', type=int, default=4, help='å¤å¼æŠ•æ³¨ååŒºå·ç æ•°é‡')
    predict_parser.add_argument('--analysis-periods', type=int, default=300, help='é©¬å°”å¯å¤«åˆ†ææœŸæ•°')
    predict_parser.add_argument('--predict-periods', type=int, default=1, help='é©¬å°”å¯å¤«é¢„æµ‹æœŸæ•°')
    predict_parser.add_argument('--strategy', choices=['conservative', 'aggressive', 'balanced'],
                               default='balanced', help='æ··åˆç­–ç•¥ç±»å‹')
    predict_parser.add_argument('--integration-level', choices=['high', 'ultimate'],
                               default='ultimate', help='é«˜åº¦é›†æˆçº§åˆ«')
    predict_parser.add_argument('--integration-type', choices=['comprehensive', 'markov_bayesian', 'hot_cold_markov', 'multi_dimensional'],
                               default='comprehensive', help='é«˜çº§é›†æˆåˆ†æç±»å‹')
    predict_parser.add_argument('--markov-periods', type=int, default=500, help='é©¬å°”å¯å¤«åˆ†ææœŸæ•°')
    predict_parser.add_argument('--save', help='ä¿å­˜é¢„æµ‹ç»“æœ')
    
    # ==================== è‡ªé€‚åº”å­¦ä¹ å‘½ä»¤ ====================
    learn_parser = subparsers.add_parser('learn', help='è‡ªé€‚åº”å­¦ä¹ ')
    learn_parser.add_argument('-s', '--start', type=int, default=100, help='èµ·å§‹æœŸæ•°')
    learn_parser.add_argument('-t', '--test', type=int, default=1000, help='æµ‹è¯•æœŸæ•°')
    learn_parser.add_argument('--algorithm', choices=['epsilon_greedy', 'ucb1', 'thompson_sampling'], 
                             default='ucb1', help='å¤šè‡‚è€è™æœºç®—æ³•')
    learn_parser.add_argument('--save', help='ä¿å­˜å­¦ä¹ ç»“æœ')
    
    # ==================== æ™ºèƒ½é¢„æµ‹å‘½ä»¤ ====================
    smart_parser = subparsers.add_parser('smart', help='æ™ºèƒ½é¢„æµ‹ï¼ˆåŸºäºå­¦ä¹ ç»“æœï¼‰')
    smart_parser.add_argument('-c', '--count', type=int, default=1, help='ç”Ÿæˆæ³¨æ•°')
    smart_parser.add_argument('--load', help='åŠ è½½å­¦ä¹ ç»“æœæ–‡ä»¶')
    smart_parser.add_argument('--compound', action='store_true', help='ç”Ÿæˆå¤å¼æŠ•æ³¨')
    smart_parser.add_argument('--front-count', type=int, default=8, help='å¤å¼å‰åŒºå·ç æ•°é‡')
    smart_parser.add_argument('--back-count', type=int, default=4, help='å¤å¼ååŒºå·ç æ•°é‡')
    smart_parser.add_argument('--duplex', action='store_true', help='ç”Ÿæˆèƒ†æ‹–æŠ•æ³¨')
    smart_parser.add_argument('--front-dan', type=int, default=2, help='å‰åŒºèƒ†ç æ•°é‡')
    smart_parser.add_argument('--back-dan', type=int, default=1, help='ååŒºèƒ†ç æ•°é‡')
    smart_parser.add_argument('--front-tuo', type=int, default=6, help='å‰åŒºæ‹–ç æ•°é‡')
    smart_parser.add_argument('--back-tuo', type=int, default=4, help='ååŒºæ‹–ç æ•°é‡')

    # ==================== å‚æ•°ä¼˜åŒ–å‘½ä»¤ ====================
    optimize_parser = subparsers.add_parser('optimize', help='å‚æ•°ä¼˜åŒ–')
    optimize_parser.add_argument('-t', '--test-periods', type=int, default=100, help='æµ‹è¯•æœŸæ•°')
    optimize_parser.add_argument('-r', '--rounds', type=int, default=10, help='ä¼˜åŒ–è½®æ•°')
    optimize_parser.add_argument('--save', help='ä¿å­˜ä¼˜åŒ–ç»“æœ')

    # ==================== å›æµ‹å‘½ä»¤ ====================
    backtest_parser = subparsers.add_parser('backtest', help='å†å²å›æµ‹')
    backtest_parser.add_argument('-s', '--start', type=int, default=100, help='èµ·å§‹æœŸæ•°')
    backtest_parser.add_argument('-t', '--test', type=int, default=500, help='æµ‹è¯•æœŸæ•°')
    backtest_parser.add_argument('-m', '--method',
                                choices=['frequency', 'hot_cold', 'missing', 'markov', 'bayesian', 'ensemble'],
                                default='ensemble', help='é¢„æµ‹æ–¹æ³•')

    # ==================== ç³»ç»Ÿç®¡ç†å‘½ä»¤ ====================
    system_parser = subparsers.add_parser('system', help='ç³»ç»Ÿç®¡ç†')
    system_subparsers = system_parser.add_subparsers(dest='system_action', help='ç³»ç»Ÿæ“ä½œ')
    
    # ç¼“å­˜ç®¡ç†
    cache_parser = system_subparsers.add_parser('cache', help='ç¼“å­˜ç®¡ç†')
    cache_parser.add_argument('action', choices=['info', 'clear'], help='ç¼“å­˜æ“ä½œ')
    cache_parser.add_argument('--type', choices=['all', 'models', 'analysis', 'data'], 
                             default='all', help='ç¼“å­˜ç±»å‹')
    
    # ==================== å¸®åŠ©å’Œç‰ˆæœ¬ ====================
    version_parser = subparsers.add_parser('version', help='æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = DLTPredictorSystem()
    
    # æ‰§è¡Œå¯¹åº”çš„å‘½ä»¤
    try:
        if args.command == 'data':
            system.run_data_command(args)
        elif args.command == 'analyze':
            system.run_analyze_command(args)
        elif args.command == 'predict':
            system.run_predict_command(args)
        elif args.command == 'learn':
            system.run_learn_command(args)
        elif args.command == 'smart':
            system.run_smart_command(args)
        elif args.command == 'optimize':
            system.run_optimize_command(args)
        elif args.command == 'backtest':
            system.run_backtest_command(args)
        elif args.command == 'system':
            system.run_system_command(args)
        elif args.command == 'version':
            system.show_version()
    except KeyboardInterrupt:
        print("\nâš ï¸  æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        task_manager.interrupt_current_task()
    except Exception as e:
        logger_manager.error("å‘½ä»¤æ‰§è¡Œå¤±è´¥", e)
        print(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
