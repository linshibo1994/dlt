#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿ - ä¼˜åŒ–ç‰ˆä¸»ç¨‹åº
æ”¯æŒå»¶è¿ŸåŠ è½½ï¼Œé¿å…å¯åŠ¨æ—¶é—´è¿‡é•¿
"""

import argparse
import sys
import os
from datetime import datetime
from typing import List, Dict

# åªå¯¼å…¥æ ¸å¿ƒæ¨¡å—
from core_modules import cache_manager, logger_manager, data_manager, task_manager

# å¯¼å…¥å¢å¼ºåŠŸèƒ½é›†æˆæ¨¡å—
try:
    from enhanced_integration import enhanced_dlt_system, is_enhanced_available
    ENHANCED_INTEGRATION_AVAILABLE = True
except ImportError as e:
    ENHANCED_INTEGRATION_AVAILABLE = False
    print(f"âš ï¸ å¢å¼ºåŠŸèƒ½é›†æˆæ¨¡å—åŠ è½½å¤±è´¥: {e}")


class DLTPredictorSystem:
    """å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self):
        self.analyzers = {}
        self.predictors = {}
        self.adaptive_predictor = None

        # å»¶è¿ŸåŠ è½½æ ‡å¿—
        self._analyzers_loaded = False
        self._predictors_loaded = False
        self._adaptive_loaded = False

        # åˆå§‹åŒ–å¢å¼ºåŠŸèƒ½
        self.enhanced_available = ENHANCED_INTEGRATION_AVAILABLE and is_enhanced_available()
        if self.enhanced_available:
            self.enhanced_system = enhanced_dlt_system
            logger_manager.info("âœ… å¢å¼ºåŠŸèƒ½å·²é›†æˆåˆ°ä¸»ç³»ç»Ÿ")
        else:
            self.enhanced_system = None
            logger_manager.info("âš ï¸ ä½¿ç”¨åŸºç¡€åŠŸèƒ½æ¨¡å¼")
    
    def _load_analyzers(self):
        """å»¶è¿ŸåŠ è½½åˆ†æå™¨"""
        if not self._analyzers_loaded:
            print("ğŸ“Š åŠ è½½åˆ†æå™¨æ¨¡å—...")
            from analyzer_modules import basic_analyzer, advanced_analyzer, comprehensive_analyzer, visualization_analyzer
            self.analyzers = {
                'basic': basic_analyzer,
                'advanced': advanced_analyzer,
                'comprehensive': comprehensive_analyzer,
                'visualization': visualization_analyzer
            }
            self._analyzers_loaded = True
    
    def _load_predictors(self):
        """å»¶è¿ŸåŠ è½½é¢„æµ‹å™¨"""
        if not self._predictors_loaded:
            print("ğŸ¯ åŠ è½½é¢„æµ‹å™¨æ¨¡å—...")
            from predictor_modules import get_traditional_predictor, get_advanced_predictor, get_super_predictor, CompoundPredictor
            self.predictors = {
                'traditional': get_traditional_predictor(),
                'advanced': get_advanced_predictor(),
                'super': get_super_predictor(),
                'compound': CompoundPredictor()
            }
            self._predictors_loaded = True
    
    def _load_adaptive_predictor(self):
        """å»¶è¿ŸåŠ è½½è‡ªé€‚åº”é¢„æµ‹å™¨"""
        if not self._adaptive_loaded:
            print("ğŸš€ åŠ è½½è‡ªé€‚åº”å­¦ä¹ æ¨¡å—...")
            from adaptive_learning_modules import enhanced_adaptive_predictor
            self.adaptive_predictor = enhanced_adaptive_predictor
            self._adaptive_loaded = True
    
    def run_data_command(self, args):
        """å¤„ç†æ•°æ®ç®¡ç†å‘½ä»¤"""
        if args.data_action == 'status':
            print("ğŸ“Š æ•°æ®çŠ¶æ€:")
            stats = data_manager.get_stats()
            print(f"  æ€»æœŸæ•°: {stats.get('total_periods', 0)}")
            print(f"  æ•°æ®èŒƒå›´: {stats.get('date_range', {}).get('start', 'N/A')} åˆ° {stats.get('date_range', {}).get('end', 'N/A')}")
            print(f"  æœ€æ–°æœŸå·: {stats.get('latest_issue', 'N/A')}")

            # ç¼“å­˜ä¿¡æ¯
            cache_info = cache_manager.get_cache_info()
            print(f"\nğŸ’¾ ç¼“å­˜çŠ¶æ€:")
            print(f"  æ€»æ–‡ä»¶æ•°: {cache_info['total']['files']}")
            print(f"  æ€»å¤§å°: {cache_info['total']['size_mb']:.2f} MB")

        elif args.data_action == 'latest':
            print("ğŸ” è·å–æœ€æ–°å¼€å¥–ç»“æœ...")
            try:
                # è·å–æœ¬åœ°æœ€æ–°æ•°æ®
                df = data_manager.get_data()
                if df is not None and len(df) > 0:
                    latest_row = df.iloc[0]  # ç¬¬ä¸€è¡Œæ˜¯æœ€æ–°æ•°æ®
                    front_balls, back_balls = data_manager.parse_balls(latest_row)

                    print("âœ… æœ€æ–°å¼€å¥–ç»“æœ:")
                    print(f"  æœŸå·: {latest_row['issue']}")
                    print(f"  æ—¥æœŸ: {latest_row['date']}")
                    print(f"  å¼€å¥–å·ç : {' '.join([str(b).zfill(2) for b in front_balls])} + {' '.join([str(b).zfill(2) for b in back_balls])}")

                    # å¦‚æœæŒ‡å®šäº†æ¯”è¾ƒé€‰é¡¹
                    if hasattr(args, 'compare') and args.compare:
                        self._compare_with_latest(front_balls, back_balls)
                else:
                    print("âŒ æ²¡æœ‰æ‰¾åˆ°å¼€å¥–æ•°æ®")
            except Exception as e:
                print(f"âŒ è·å–æœ€æ–°å¼€å¥–ç»“æœå¤±è´¥: {e}")

        elif args.data_action == 'update':
            # å¤„ç†æ›´æ–°å‚æ•°
            periods = getattr(args, 'periods', None)
            incremental = getattr(args, 'incremental', False)

            update_type = "å¢é‡æ›´æ–°" if incremental else "å®Œæ•´æ›´æ–°"
            print(f"ğŸ”„ {update_type} (æ•°æ®æº: {args.source}" + (f", æœŸæ•°: {periods}" if periods else "") + ")...")

            try:
                from crawlers import ZhcwCrawler
                crawler = ZhcwCrawler()

                if incremental:
                    # å¢é‡æ›´æ–°ï¼šåªè·å–æœ€æ–°çš„å‡ é¡µæ•°æ®
                    count = crawler.crawl_recent_data(3)
                elif periods:
                    # æ›´æ–°æŒ‡å®šæœŸæ•°
                    count = crawler.crawl_recent_data(periods)
                else:
                    # æ›´æ–°æ‰€æœ‰æ•°æ®
                    count = crawler.crawl_all_data()

                # æ¸…ç†ç¼“å­˜å¹¶é‡æ–°åŠ è½½æ•°æ®
                cache_manager.clear_cache('data')
                data_manager._load_data()
                print(f"âœ… æ•°æ®æ›´æ–°å®Œæˆï¼Œæ–°å¢ {count} æœŸæ•°æ®")

            except ImportError:
                print("âŒ çˆ¬è™«æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥crawlers.pyæ–‡ä»¶")
            except Exception as e:
                print(f"âŒ æ•°æ®æ›´æ–°å¤±è´¥: {e}")

    def _compare_with_latest(self, actual_front: List[int], actual_back: List[int]):
        """ä¸æœ€æ–°å¼€å¥–ç»“æœæ¯”è¾ƒ"""
        print("\nğŸ¯ å·ç æ¯”è¾ƒåŠŸèƒ½:")
        print("è¯·è¾“å…¥æ‚¨çš„å·ç è¿›è¡Œæ¯”è¾ƒ")

        try:
            # è¾“å…¥å‰åŒºå·ç 
            front_input = input("å‰åŒºå·ç  (5ä¸ªå·ç ï¼Œç”¨ç©ºæ ¼åˆ†éš”): ").strip()
            front_numbers = [int(x) for x in front_input.split()]

            if len(front_numbers) != 5:
                print("âŒ å‰åŒºå·ç å¿…é¡»æ˜¯5ä¸ª")
                return

            # è¾“å…¥ååŒºå·ç 
            back_input = input("ååŒºå·ç  (2ä¸ªå·ç ï¼Œç”¨ç©ºæ ¼åˆ†éš”): ").strip()
            back_numbers = [int(x) for x in back_input.split()]

            if len(back_numbers) != 2:
                print("âŒ ååŒºå·ç å¿…é¡»æ˜¯2ä¸ª")
                return

            # è®¡ç®—ä¸­å¥–æƒ…å†µ
            from adaptive_learning_modules import AccuracyTracker
            tracker = AccuracyTracker()
            prize_level, front_hits, back_hits = tracker._calculate_prize_level(
                front_numbers, back_numbers, actual_front, actual_back
            )

            print(f"\nğŸ† æ¯”è¾ƒç»“æœ:")
            print(f"  æ‚¨çš„å·ç : {' '.join([str(b).zfill(2) for b in front_numbers])} + {' '.join([str(b).zfill(2) for b in back_numbers])}")
            print(f"  å¼€å¥–å·ç : {' '.join([str(b).zfill(2) for b in actual_front])} + {' '.join([str(b).zfill(2) for b in actual_back])}")
            print(f"  å‰åŒºå‘½ä¸­: {front_hits} ä¸ª")
            print(f"  ååŒºå‘½ä¸­: {back_hits} ä¸ª")
            print(f"  ä¸­å¥–ç­‰çº§: {prize_level}")

        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nâš ï¸  æ“ä½œè¢«å–æ¶ˆ")
        except Exception as e:
            print(f"âŒ æ¯”è¾ƒå¤±è´¥: {e}")
    
    def run_analyze_command(self, args):
        """å¤„ç†åˆ†æå‘½ä»¤"""
        self._load_analyzers()
        
        print(f"ğŸ“Š å¼€å§‹{args.type}åˆ†æ (æœŸæ•°: {args.periods})...")
        
        try:
            if args.type == 'basic':
                # åŸºç¡€åˆ†æ
                freq_result = self.analyzers['basic'].frequency_analysis(args.periods)
                hot_cold_result = self.analyzers['basic'].hot_cold_analysis(args.periods)
                
                print("âœ… åŸºç¡€åˆ†æå®Œæˆ")
                print(f"  é¢‘ç‡åˆ†æ: {len(freq_result.get('front_frequency', {}))} ä¸ªå‰åŒºå·ç ")
                print(f"  å†·çƒ­åˆ†æ: çƒ­å· {len(hot_cold_result.get('front_hot', []))} ä¸ªï¼Œå†·å· {len(hot_cold_result.get('front_cold', []))} ä¸ª")
            
            elif args.type == 'advanced':
                # é«˜çº§åˆ†æ
                markov_result = self.analyzers['advanced'].markov_analysis(args.periods)
                bayesian_result = self.analyzers['advanced'].bayesian_analysis(args.periods)
                
                print("âœ… é«˜çº§åˆ†æå®Œæˆ")
                print(f"  é©¬å°”å¯å¤«åˆ†æ: {len(markov_result.get('front_transition_probs', {}))} ä¸ªè½¬ç§»æ¦‚ç‡")
                print(f"  è´å¶æ–¯åˆ†æ: åéªŒæ¦‚ç‡è®¡ç®—å®Œæˆ")
            
            elif args.type == 'comprehensive':
                # ç»¼åˆåˆ†æ
                comp_result = self.analyzers['comprehensive'].comprehensive_analysis(args.periods)
                
                print("âœ… ç»¼åˆåˆ†æå®Œæˆ")
                
                if args.report:
                    # ç”ŸæˆæŠ¥å‘Š
                    report = self.analyzers['comprehensive'].generate_analysis_report(args.periods)
                    print("\n" + report)
                    
                    # ä¿å­˜æŠ¥å‘Š
                    if args.save:
                        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                        output_dir = "output/reports"
                        os.makedirs(output_dir, exist_ok=True)

                        if args.save.endswith('.txt'):
                            filename = os.path.join(output_dir, args.save)
                        else:
                            filename = os.path.join(output_dir, f"{args.save}.txt")

                        with open(filename, 'w', encoding='utf-8') as f:
                            f.write(report)
                        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {filename}")

            # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            if hasattr(args, 'visualize') and args.visualize:
                print("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
                viz_success = self.analyzers['visualization'].generate_all_charts("output", args.periods)
                if viz_success:
                    print("âœ… å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼Œä¿å­˜åœ¨ output/ ç›®å½•")
                else:
                    print("âŒ å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå¤±è´¥")

        except Exception as e:
            logger_manager.error("åˆ†æå¤±è´¥", e)
            print(f"âŒ åˆ†æå¤±è´¥: {e}")
    
    def run_predict_command(self, args):
        """å¤„ç†é¢„æµ‹å‘½ä»¤"""
        self._load_predictors()

        # å‚æ•°éªŒè¯
        if args.count < 1 or args.count > 100:
            print("âŒ æ³¨æ•°å¿…é¡»åœ¨1-100ä¹‹é—´")
            return

        if args.periods < 50 or args.periods > 2748:
            print("âŒ åˆ†ææœŸæ•°å¿…é¡»åœ¨50-2748ä¹‹é—´")
            return

        print(f"ğŸ¯ å¼€å§‹{args.method}é¢„æµ‹ (åˆ†ææœŸæ•°: {args.periods}, ç”Ÿæˆæ³¨æ•°: {args.count})...")

        # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨å¢å¼ºåŠŸèƒ½
        use_enhanced = self.enhanced_available and args.method in ['lstm', 'transformer', 'gan', 'ensemble', 'enhanced', 'stacking', 'adaptive_ensemble', 'ultimate_ensemble']

        if use_enhanced:
            print("ğŸš€ ä½¿ç”¨å¢å¼ºé¢„æµ‹å¼•æ“...")
            try:
                # ä½¿ç”¨å¢å¼ºé¢„æµ‹åŠŸèƒ½
                if args.method == 'enhanced':
                    # ä½¿ç”¨å¢å¼ºç³»ç»Ÿçš„è‡ªåŠ¨é¢„æµ‹
                    result = self.enhanced_system.enhanced_predict(
                        data=f"predict_{args.count}_numbers_periods_{args.periods}",
                        method="auto",
                        periods=args.periods,
                        count=args.count
                    )
                    if result.get('success'):
                        print("âœ… å¢å¼ºé¢„æµ‹å®Œæˆ")
                        print(f"é¢„æµ‹ç»“æœ: {result['result']}")
                        print(f"ä½¿ç”¨æ–¹æ³•: {result['method']}")
                        print(f"å·²ç¼“å­˜: {result['cached']}")
                        return
                    else:
                        print(f"âŒ å¢å¼ºé¢„æµ‹å¤±è´¥: {result.get('error')}")
                        print("ğŸ”„ å›é€€åˆ°ä¼ ç»Ÿé¢„æµ‹æ–¹æ³•...")

                elif args.method in ['lstm', 'transformer', 'gan', 'ensemble', 'stacking', 'adaptive_ensemble', 'ultimate_ensemble']:
                    # ä½¿ç”¨å¢å¼ºæ·±åº¦å­¦ä¹ æ¨¡å‹æˆ–é›†æˆæ–¹æ³•
                    try:
                        if args.method in ['lstm', 'transformer', 'gan', 'ensemble']:
                            # æ·±åº¦å­¦ä¹ æ¨¡å‹
                            from enhanced_deep_learning.models import model_registry
                            model = model_registry.get_model(args.method)

                            if model:
                                print(f"ğŸš€ ä½¿ç”¨{args.method.upper()}æ·±åº¦å­¦ä¹ æ¨¡å‹...")
                                historical_data = data_manager.get_data()
                                if historical_data is not None and len(historical_data) > args.periods:
                                    historical_data = historical_data.head(args.periods)
                                    print(f"ğŸ“Š ä½¿ç”¨æœ€æ–°{args.periods}æœŸæ•°æ®è¿›è¡Œ{args.method.upper()}æ¨¡å‹è®­ç»ƒ...")

                                predictions = model.predict_lottery(data=historical_data, count=args.count, periods=args.periods)

                                if predictions:
                                    print(f"âœ… {args.method.upper()}é¢„æµ‹å®Œæˆ")
                                    self._display_enhanced_predictions(predictions, args.method)
                                    return
                                else:
                                    print(f"âŒ {args.method}æ·±åº¦å­¦ä¹ æ¨¡å‹é¢„æµ‹å¤±è´¥ï¼Œå°è¯•é›†æˆæ–¹æ³•...")
                            else:
                                print(f"âŒ {args.method}æ·±åº¦å­¦ä¹ æ¨¡å‹æœªæ‰¾åˆ°ï¼Œå°è¯•é›†æˆæ–¹æ³•...")

                        # å¦‚æœæ·±åº¦å­¦ä¹ æ¨¡å‹å¤±è´¥æˆ–è€…æ˜¯é›†æˆæ–¹æ³•ï¼Œä½¿ç”¨improvementsæ¨¡å—
                        from improvements.integration import get_integrator
                        integrator = get_integrator()

                        if args.method == 'lstm':
                            print("ğŸ§  LSTMé›†æˆé¢„æµ‹...")
                            # å°è¯•ä½¿ç”¨advanced_lstm_predictorä½œä¸ºå›é€€
                            try:
                                from advanced_lstm_predictor import AdvancedLSTMPredictor
                                lstm_predictor = AdvancedLSTMPredictor()
                                results = lstm_predictor.lstm_predict(count=args.count, periods=args.periods)
                                predictions = [{'front_balls': r[0], 'back_balls': r[1], 'method': 'lstm', 'confidence': 0.85} for r in results]
                            except Exception as e:
                                print(f"âŒ LSTMé¢„æµ‹å¤±è´¥: {e}")
                                predictions = []
                        elif args.method == 'transformer':
                            print("ğŸ§® Transformeræ·±åº¦å­¦ä¹ é¢„æµ‹...")
                            predictions = integrator.transformer_predict(args.count, args.periods)
                        elif args.method == 'gan':
                            print("ğŸ® GANç”Ÿæˆé¢„æµ‹...")
                            predictions = integrator.gan_predict(args.count, args.periods)
                        elif args.method == 'stacking':
                            print("ğŸ”„ Stackingé›†æˆé¢„æµ‹...")
                            predictions = integrator.stacking_predict(args.count)
                        elif args.method == 'adaptive_ensemble':
                            print("ğŸ§  è‡ªé€‚åº”é›†æˆé¢„æµ‹...")
                            predictions = integrator.adaptive_ensemble_predict(args.count)
                        elif args.method == 'ultimate_ensemble':
                            print("ğŸŒŸ ç»ˆæé›†æˆé¢„æµ‹...")
                            predictions = integrator.ultimate_ensemble_predict(args.count)
                        else:
                            predictions = []

                        if predictions:
                            print(f"âœ… {args.method.upper()}é¢„æµ‹å®Œæˆ")
                            self._display_enhanced_predictions(predictions, args.method)
                            return
                        else:
                            print(f"âŒ {args.method}é¢„æµ‹å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•...")

                    except Exception as e:
                        print(f"âŒ å¢å¼ºé¢„æµ‹å¤±è´¥: {e}")
                        print("ğŸ”„ å›é€€åˆ°ä¼ ç»Ÿé¢„æµ‹æ–¹æ³•...")

            except Exception as e:
                logger_manager.error(f"å¢å¼ºé¢„æµ‹å¤±è´¥: {e}")
                print(f"âŒ å¢å¼ºé¢„æµ‹å¤±è´¥: {e}")
                print("ğŸ”„ å›é€€åˆ°ä¼ ç»Ÿé¢„æµ‹æ–¹æ³•...")

        try:
            predictions = []

            if args.method in ['frequency', 'hot_cold', 'missing']:
                # ä¼ ç»Ÿé¢„æµ‹æ–¹æ³•
                if args.method == 'frequency':
                    print(f"ğŸ“Š é¢‘ç‡åˆ†æé¢„æµ‹ (åˆ†æ{args.periods}æœŸæ•°æ®)...")
                    results = self.predictors['traditional'].frequency_predict(count=args.count, periods=args.periods)
                elif args.method == 'hot_cold':
                    print(f"ğŸŒ¡ï¸ å†·çƒ­å·åˆ†æé¢„æµ‹ (åˆ†æ{args.periods}æœŸæ•°æ®)...")
                    print("ğŸ“Š åˆ†æå†·çƒ­å·åˆ†å¸ƒ...")

                    # è·å–å†·çƒ­å·åˆ†æç»“æœ
                    from analyzer_modules import basic_analyzer
                    hot_cold_analysis = basic_analyzer.hot_cold_analysis(args.periods)

                    front_hot = hot_cold_analysis.get('front_hot', [])
                    front_cold = hot_cold_analysis.get('front_cold', [])
                    back_hot = hot_cold_analysis.get('back_hot', [])
                    back_cold = hot_cold_analysis.get('back_cold', [])

                    print(f"âœ… å†·çƒ­å·è¯†åˆ«å®Œæˆ:")
                    print(f"  å‰åŒºçƒ­å· ({len(front_hot)}ä¸ª): {sorted(front_hot)[:10]}{'...' if len(front_hot) > 10 else ''}")
                    print(f"  å‰åŒºå†·å· ({len(front_cold)}ä¸ª): {sorted(front_cold)[:10]}{'...' if len(front_cold) > 10 else ''}")
                    print(f"  ååŒºçƒ­å· ({len(back_hot)}ä¸ª): {sorted(back_hot)}")
                    print(f"  ååŒºå†·å· ({len(back_cold)}ä¸ª): {sorted(back_cold)}")
                    print("ğŸ¯ åŸºäºå†·çƒ­å·åˆ†å¸ƒè¿›è¡Œæ™ºèƒ½é¢„æµ‹...")

                    results = self.predictors['traditional'].hot_cold_predict(count=args.count, periods=args.periods)
                elif args.method == 'missing':
                    print(f"â° é—æ¼å€¼åˆ†æé¢„æµ‹ (åˆ†æ{args.periods}æœŸæ•°æ®)...")
                    results = self.predictors['traditional'].missing_predict(count=args.count, periods=args.periods)
                
                predictions = [{'front_balls': r[0], 'back_balls': r[1], 'method': args.method} for r in results]
            
            elif args.method in ['markov', 'bayesian', 'ensemble']:
                # é«˜çº§é¢„æµ‹æ–¹æ³•
                if args.method == 'markov':
                    results = self.predictors['advanced'].markov_predict(args.count, args.periods)
                elif args.method == 'bayesian':
                    print(f"ğŸ² è´å¶æ–¯åˆ†æé¢„æµ‹ (åˆ†æ{args.periods}æœŸæ•°æ®)...")
                    print("ğŸ“Š è®¡ç®—å…ˆéªŒæ¦‚ç‡å’Œä¼¼ç„¶å‡½æ•°...")

                    # è·å–è´å¶æ–¯åˆ†æç»“æœ
                    from analyzer_modules import advanced_analyzer
                    bayesian_analysis = advanced_analyzer.bayesian_analysis(args.periods)

                    front_prior = bayesian_analysis.get('front_prior', {})
                    back_prior = bayesian_analysis.get('back_prior', {})
                    front_posterior = bayesian_analysis.get('front_posterior', {})
                    back_posterior = bayesian_analysis.get('back_posterior', {})

                    print(f"âœ… è´å¶æ–¯æ¨ç†å®Œæˆ:")
                    print(f"  å‰åŒºå…ˆéªŒæ¦‚ç‡è®¡ç®—: {len(front_prior)} ä¸ªå·ç ")
                    print(f"  å‰åŒºåéªŒæ¦‚ç‡è®¡ç®—: {len(front_posterior)} ä¸ªå·ç ")
                    print(f"  ååŒºå…ˆéªŒæ¦‚ç‡è®¡ç®—: {len(back_prior)} ä¸ªå·ç ")
                    print(f"  ååŒºåéªŒæ¦‚ç‡è®¡ç®—: {len(back_posterior)} ä¸ªå·ç ")

                    if front_posterior:
                        top_front = sorted(front_posterior.items(), key=lambda x: x[1], reverse=True)[:5]
                        print(f"  å‰åŒºæœ€é«˜åéªŒæ¦‚ç‡: {[f'{k}({v:.3f})' for k, v in top_front]}")

                    if back_posterior:
                        top_back = sorted(back_posterior.items(), key=lambda x: x[1], reverse=True)[:2]
                        print(f"  ååŒºæœ€é«˜åéªŒæ¦‚ç‡: {[f'{k}({v:.3f})' for k, v in top_back]}")

                    print("ğŸ¯ åŸºäºè´å¶æ–¯æ¨ç†è¿›è¡Œæ¦‚ç‡é¢„æµ‹...")

                    results = self.predictors['advanced'].bayesian_predict(count=args.count, periods=args.periods)
                elif args.method == 'ensemble':
                    results = self.predictors['advanced'].ensemble_predict(args.count, args.periods)
                
                predictions = [{'front_balls': r[0], 'back_balls': r[1], 'method': args.method} for r in results]
            
            elif args.method == 'super':
                # è¶…çº§é¢„æµ‹
                results = self.predictors['super'].predict_super(args.count, args.periods)
                predictions = results
            
            elif args.method == 'adaptive':
                # è‡ªé€‚åº”é¢„æµ‹
                self._load_adaptive_predictor()
                results = self.adaptive_predictor.generate_enhanced_prediction(args.count, args.periods)
                predictions = results

            elif args.method == 'compound':
                # å¤å¼æŠ•æ³¨é¢„æµ‹
                front_count = getattr(args, 'front_count', 8)
                back_count = getattr(args, 'back_count', 4)
                result = self.predictors['compound'].predict_compound(front_count, back_count, 'ensemble', args.periods)
                if result:
                    predictions = [result]
                else:
                    predictions = []

            elif args.method == 'duplex':
                # èƒ†æ‹–æŠ•æ³¨é¢„æµ‹
                result = self.predictors['compound'].predict_duplex(periods=args.periods)
                if result:
                    predictions = [result]
                else:
                    predictions = []
                    
            elif args.method in ['transformer', 'gan', 'stacking', 'adaptive_ensemble', 'ultimate_ensemble']:
                # å¢å¼ºé¢„æµ‹æ–¹æ³•
                try:
                    from improvements.integration import get_integrator
                    integrator = get_integrator()
                    
                    if args.method == 'transformer':
                        results = integrator.transformer_predict(args.count)
                    elif args.method == 'gan':
                        results = integrator.gan_predict(args.count)
                    elif args.method == 'stacking':
                        results = integrator.stacking_predict(args.count)
                    elif args.method == 'adaptive_ensemble':
                        results = integrator.adaptive_ensemble_predict(args.count)
                    elif args.method == 'ultimate_ensemble':
                        results = integrator.ultimate_ensemble_predict(args.count)
                    
                    predictions = results
                except ImportError:
                    print("âŒ å¢å¼ºé¢„æµ‹æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿improvementsç›®å½•å­˜åœ¨ä¸”åŒ…å«æ‰€éœ€æ–‡ä»¶")
                except Exception as e:
                    print(f"âŒ å¢å¼ºé¢„æµ‹å¤±è´¥: {e}")

            elif args.method == 'markov_custom':
                # é©¬å°”å¯å¤«è‡ªå®šä¹‰æœŸæ•°é¢„æµ‹
                analysis_periods = getattr(args, 'analysis_periods', 300)
                predict_periods = getattr(args, 'predict_periods', 1)
                results = self.predictors['advanced'].markov_predict_custom(
                    count=args.count,
                    analysis_periods=analysis_periods,
                    predict_periods=predict_periods
                )
                predictions = results

            elif args.method == 'mixed_strategy':
                # æ··åˆç­–ç•¥é¢„æµ‹
                strategy = getattr(args, 'strategy', 'balanced')
                results = self.predictors['advanced'].mixed_strategy_predict(
                    count=args.count,
                    strategy=strategy,
                    periods=args.periods
                )
                predictions = results

            elif args.method == 'highly_integrated':
                # é«˜åº¦é›†æˆå¤å¼é¢„æµ‹
                front_count = getattr(args, 'front_count', 10)
                back_count = getattr(args, 'back_count', 5)
                integration_level = getattr(args, 'integration_level', 'ultimate')
                result = self.predictors['compound'].predict_highly_integrated_compound(
                    front_count=front_count,
                    back_count=back_count,
                    integration_level=integration_level,
                    periods=args.periods
                )
                if result:
                    predictions = [result]
                else:
                    predictions = []

            elif args.method == 'advanced_integration':
                # é«˜çº§é›†æˆåˆ†æé¢„æµ‹
                integration_type = getattr(args, 'integration_type', 'comprehensive')
                results = self.predictors['advanced'].advanced_integration_predict(
                    count=args.count,
                    integration_type=integration_type,
                    periods=args.periods
                )
                predictions = results

            elif args.method == 'nine_models':
                # 9ç§æ•°å­¦æ¨¡å‹é¢„æµ‹
                results = self.predictors['advanced'].nine_models_predict(count=args.count, periods=args.periods)
                predictions = results

            elif args.method == 'nine_models_compound':
                # 9ç§æ•°å­¦æ¨¡å‹å¤å¼é¢„æµ‹
                front_count = getattr(args, 'front_count', 8)
                back_count = getattr(args, 'back_count', 4)
                result = self.predictors['advanced'].nine_models_compound_predict(
                    front_count=front_count,
                    back_count=back_count,
                    periods=args.periods
                )
                if result:
                    predictions = [result]
                else:
                    predictions = []

            elif args.method == 'markov_compound':
                # é©¬å°”å¯å¤«é“¾å¤å¼é¢„æµ‹
                front_count = getattr(args, 'front_count', 8)
                back_count = getattr(args, 'back_count', 4)
                markov_periods = args.periods  # ä½¿ç”¨æ–°çš„periodså‚æ•°
                result = self.predictors['advanced'].markov_compound_predict(
                    front_count=front_count,
                    back_count=back_count,
                    analysis_periods=markov_periods
                )
                if result:
                    predictions = [result]
                else:
                    predictions = []
                    
            elif args.method in ['markov_2nd', 'markov_3rd', 'adaptive_markov']:
                # å¢å¼ºç‰ˆé©¬å°”å¯å¤«é“¾é¢„æµ‹
                try:
                    from improvements.enhanced_markov import get_markov_predictor
                    
                    markov_periods = args.periods  # ä½¿ç”¨æ–°çš„periodså‚æ•°
                    
                    if args.method == 'markov_2nd':
                        print(f"ğŸ”„ äºŒé˜¶é©¬å°”å¯å¤«é“¾é¢„æµ‹ (åˆ†æ{markov_periods}æœŸæ•°æ®)...")
                        print("ğŸ“Š æ„å»ºäºŒé˜¶çŠ¶æ€è½¬ç§»çŸ©é˜µ...")
                        print("ğŸ”¢ æ¦‚ç‡è®¡ç®—: åŸºäºå†å²æ•°æ®è®¡ç®—è½¬ç§»æ¦‚ç‡")
                        print("ğŸ“ˆ çŸ©é˜µè®¡ç®—: æ„å»ºå¤åˆçŠ¶æ€è½¬ç§»çŸ©é˜µ")

                        markov_predictor = get_markov_predictor()

                        # è·å–äºŒé˜¶é©¬å°”å¯å¤«åˆ†æç»“æœ
                        markov_analyzer = markov_predictor.analyzer
                        analysis_result = markov_analyzer.multi_order_markov_analysis(markov_periods, max_order=2)

                        if analysis_result and 'orders' in analysis_result and 2 in analysis_result['orders']:
                            order_2_result = analysis_result['orders'][2]
                            front_stats = order_2_result.get('front_stats', {})
                            back_stats = order_2_result.get('back_stats', {})

                            print(f"âœ… äºŒé˜¶çŠ¶æ€è½¬ç§»çŸ©é˜µæ„å»ºå®Œæˆ:")
                            print(f"  ğŸ“Š æ¦‚ç‡è®¡ç®—: å‰åŒºè½¬ç§»æ¦‚ç‡æ•° {front_stats.get('total_transitions', 0)}")
                            print(f"  ğŸ“ˆ çŸ©é˜µè®¡ç®—: å‰åŒºçŠ¶æ€æ•° {front_stats.get('unique_states', 0)}")
                            print(f"  ğŸ”¢ æ¦‚ç‡è®¡ç®—: ååŒºè½¬ç§»æ¦‚ç‡æ•° {back_stats.get('total_transitions', 0)}")
                            print(f"  ğŸ“ˆ çŸ©é˜µè®¡ç®—: ååŒºçŠ¶æ€æ•° {back_stats.get('unique_states', 0)}")
                            print(f"  ğŸ¯ æœ€å¤§è½¬ç§»æ¦‚ç‡: å‰åŒº {front_stats.get('max_probability', 0):.4f}, ååŒº {back_stats.get('max_probability', 0):.4f}")

                        results = markov_predictor.multi_order_markov_predict(
                            count=args.count,
                            periods=markov_periods,
                            order=2
                        )
                        predictions = [{'front_balls': r[0], 'back_balls': r[1], 'method': 'markov_2nd', 'confidence': 0.85, 'order': 2} for r in results]
                    
                    elif args.method == 'markov_3rd':
                        print(f"ğŸ”„ ä¸‰é˜¶é©¬å°”å¯å¤«é“¾é¢„æµ‹ (åˆ†æ{markov_periods}æœŸæ•°æ®)...")
                        print("ğŸ“Š æ„å»ºä¸‰é˜¶çŠ¶æ€è½¬ç§»çŸ©é˜µ...")
                        print("ğŸ”¢ çŠ¶æ€è½¬ç§»æ˜¾ç¤º: å®Œæ•´çš„çŠ¶æ€è½¬ç§»çŸ©é˜µæ„å»ºå’Œç»Ÿè®¡ä¿¡æ¯")
                        print("ğŸ“ˆ è¶…é«˜é˜¶å»ºæ¨¡: è€ƒè™‘å‰ä¸‰æœŸçŠ¶æ€çš„å¤æ‚ä¾èµ–å…³ç³»")

                        markov_predictor = get_markov_predictor()

                        # è·å–ä¸‰é˜¶é©¬å°”å¯å¤«åˆ†æç»“æœ
                        markov_analyzer = markov_predictor.analyzer
                        analysis_result = markov_analyzer.multi_order_markov_analysis(markov_periods, max_order=3)

                        if analysis_result and 'orders' in analysis_result and 3 in analysis_result['orders']:
                            order_3_result = analysis_result['orders'][3]
                            front_stats = order_3_result.get('front_stats', {})
                            back_stats = order_3_result.get('back_stats', {})

                            print(f"âœ… ä¸‰é˜¶çŠ¶æ€è½¬ç§»çŸ©é˜µæ„å»ºå®Œæˆ:")
                            print(f"  å‰åŒºçŠ¶æ€æ•°: {front_stats.get('unique_states', 0)}")
                            print(f"  å‰åŒºè½¬ç§»æ¦‚ç‡æ•°: {front_stats.get('total_transitions', 0)}")
                            print(f"  å‰åŒºæœ€å¤§è½¬ç§»æ¦‚ç‡: {front_stats.get('max_probability', 0):.4f}")
                            print(f"  ååŒºçŠ¶æ€æ•°: {back_stats.get('unique_states', 0)}")
                            print(f"  ååŒºè½¬ç§»æ¦‚ç‡æ•°: {back_stats.get('total_transitions', 0)}")
                            print(f"  ååŒºæœ€å¤§è½¬ç§»æ¦‚ç‡: {back_stats.get('max_probability', 0):.4f}")

                        results = markov_predictor.multi_order_markov_predict(
                            count=args.count,
                            periods=markov_periods,
                            order=3
                        )
                        predictions = [{'front_balls': r[0], 'back_balls': r[1], 'method': 'markov_3rd', 'confidence': 0.9, 'order': 3} for r in results]
                    
                    elif args.method == 'adaptive_markov':
                        print("ğŸ”„ è‡ªé€‚åº”é©¬å°”å¯å¤«é“¾é¢„æµ‹...")
                        markov_predictor = get_markov_predictor()
                        predictions = markov_predictor.adaptive_order_markov_predict(
                            count=args.count, 
                            periods=markov_periods
                        )
                
                except ImportError:
                    print("âŒ å¢å¼ºç‰ˆé©¬å°”å¯å¤«é“¾æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿improvementsç›®å½•å­˜åœ¨ä¸”åŒ…å«æ‰€éœ€æ–‡ä»¶")
                    predictions = []
                except Exception as e:
                    print(f"âŒ å¢å¼ºç‰ˆé©¬å°”å¯å¤«é“¾é¢„æµ‹å¤±è´¥: {e}")
                    predictions = []
            

            

            


            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            print("âœ… é¢„æµ‹å®Œæˆ!")
            print("\nğŸ“‹ é¢„æµ‹ç»“æœ:")

            for i, pred in enumerate(predictions):
                if pred.get('front_dan'):
                    # èƒ†æ‹–æŠ•æ³¨æ˜¾ç¤º
                    front_dan_str = ' '.join([str(b).zfill(2) for b in pred['front_dan']])
                    front_tuo_str = ' '.join([str(b).zfill(2) for b in pred['front_tuo']])
                    back_dan_str = ' '.join([str(b).zfill(2) for b in pred['back_dan']])
                    back_tuo_str = ' '.join([str(b).zfill(2) for b in pred['back_tuo']])

                    print(f"  ç¬¬ {i+1} æ³¨èƒ†æ‹–:")
                    print(f"    å‰åŒº: {front_dan_str} + ({front_tuo_str})")
                    print(f"    ååŒº: {back_dan_str} + ({back_tuo_str})")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")

                elif pred.get('front_count'):
                    # å¤å¼æŠ•æ³¨æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    method_name = pred.get('method', 'compound').replace('_', ' ').title()
                    print(f"  ç¬¬ {i+1} æ³¨å¤å¼ ({method_name}): {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    ç½®ä¿¡åº¦: {pred.get('confidence', 0.5):.3f}")

                    # æ˜¾ç¤ºç‰¹å®šæ–¹æ³•çš„è¯¦ç»†ä¿¡æ¯
                    if pred.get('method') == 'nine_models_compound':
                        if 'models_used' in pred:
                            print(f"    ä½¿ç”¨æ¨¡å‹: {len(pred['models_used'])} ç§")
                        if 'model_details' in pred:
                            details = pred['model_details']
                            print(f"    ç»Ÿè®¡å­¦æƒé‡: {details.get('statistical_score', 0):.3f}")
                            print(f"    æ¦‚ç‡è®ºæƒé‡: {details.get('probability_score', 0):.3f}")
                            print(f"    é©¬å°”å¯å¤«æƒé‡: {details.get('markov_score', 0):.3f}")
                            print(f"    è´å¶æ–¯æƒé‡: {details.get('bayesian_score', 0):.3f}")

                    elif pred.get('method') == 'markov_compound':
                        print(f"    åˆ†ææœŸæ•°: {pred.get('analysis_periods', 500)}")
                        if 'markov_details' in pred:
                            details = pred['markov_details']
                            print(f"    è½¬ç§»çŸ©é˜µè§„æ¨¡: {details.get('transition_matrix_size', 0)}")
                            print(f"    çŠ¶æ€æ•°é‡: {details.get('state_count', 0)}")
                            print(f"    é¢„æµ‹å‡†ç¡®æ€§: {details.get('prediction_accuracy', 0):.3f}")

                    elif pred.get('integration_level'):
                        print(f"    é›†æˆçº§åˆ«: {pred['integration_level']}")
                        print(f"    ä½¿ç”¨ç®—æ³•: {len(pred.get('algorithms_used', []))} ç§")

                elif pred.get('overall_stability'):
                    # é©¬å°”å¯å¤«è‡ªå®šä¹‰é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  ç¬¬ {pred['index']} æ³¨ (æœŸ {pred['period']}): {front_str} + {back_str}")
                    print(f"    ç¨³å®šæ€§å¾—åˆ†: {pred['overall_stability']:.3f}")
                    print(f"    å‰åŒºç¨³å®šæ€§: {pred['front_stability']:.3f}")
                    print(f"    ååŒºç¨³å®šæ€§: {pred['back_stability']:.3f}")
                    print(f"    åˆ†ææœŸæ•°: {pred['analysis_periods']}")

                elif pred.get('strategy'):
                    # æ··åˆç­–ç•¥é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  ç¬¬ {pred['index']} æ³¨ ({pred['strategy']}ç­–ç•¥): {front_str} + {back_str}")
                    print(f"    é£é™©ç­‰çº§: {pred['risk_level']}")
                    print(f"    ç­–ç•¥æè¿°: {pred['description']}")
                    print(f"    æƒé‡é…ç½®: {pred['weights']}")

                elif pred.get('integration_level'):
                    # é«˜åº¦é›†æˆå¤å¼é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  é«˜åº¦é›†æˆå¤å¼ ({pred['integration_level']}çº§): {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    é›†æˆç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    print(f"    ä½¿ç”¨ç®—æ³•: {len(pred['algorithms_used'])} ç§")
                    if 'candidate_scores' in pred:
                        print(f"    å‰åŒºçƒ­é—¨: {list(pred['candidate_scores']['front_top10'].keys())[:5]}")
                        print(f"    ååŒºçƒ­é—¨: {list(pred['candidate_scores']['back_top8'].keys())[:3]}")

                elif pred.get('integration_type'):
                    # é«˜çº§é›†æˆåˆ†æé¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  ç¬¬ {pred['index']} æ³¨ ({pred['integration_type']}é›†æˆ): {front_str} + {back_str}")
                    print(f"    é›†æˆç±»å‹: {pred['integration_type']}")
                    print(f"    åˆ†ææ–¹æ³•: {pred['method']}")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    if 'analysis_source' in pred:
                        print(f"    åˆ†ææ—¶é—´: {pred['analysis_source']}")

                elif pred.get('method') == 'nine_mathematical_models':
                    # 9ç§æ•°å­¦æ¨¡å‹é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  ç¬¬ {pred['index']} æ³¨ (9ç§æ•°å­¦æ¨¡å‹): {front_str} + {back_str}")
                    print(f"    åˆ†ææ–¹æ³•: {pred['method']}")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    if 'models_used' in pred:
                        print(f"    ä½¿ç”¨æ¨¡å‹: {len(pred['models_used'])} ç§")
                    if 'model_consensus' in pred:
                        print(f"    æ¨¡å‹ä¸€è‡´æ€§: {pred['model_consensus']:.3f}")
                    if 'analysis_timestamp' in pred:
                        print(f"    åˆ†ææ—¶é—´: {pred['analysis_timestamp']}")

                elif pred.get('method') == 'nine_models_compound':
                    # 9ç§æ•°å­¦æ¨¡å‹å¤å¼é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  9ç§æ•°å­¦æ¨¡å‹å¤å¼: {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    if 'models_used' in pred:
                        print(f"    ä½¿ç”¨æ¨¡å‹: {len(pred['models_used'])} ç§")
                    if 'model_details' in pred:
                        details = pred['model_details']
                        print(f"    ç»Ÿè®¡å­¦æƒé‡: {details.get('statistical_score', 0):.3f}")
                        print(f"    æ¦‚ç‡è®ºæƒé‡: {details.get('probability_score', 0):.3f}")
                        print(f"    é©¬å°”å¯å¤«æƒé‡: {details.get('markov_score', 0):.3f}")
                        print(f"    è´å¶æ–¯æƒé‡: {details.get('bayesian_score', 0):.3f}")

                elif pred.get('method') and 'compound' in pred['method']:
                    # é€šç”¨å¤å¼é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    method_name = pred['method'].replace('_', ' ').title()
                    print(f"  {method_name}: {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")

                elif pred.get('method') == 'markov_compound':
                    # é©¬å°”å¯å¤«é“¾å¤å¼é¢„æµ‹æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])

                    print(f"  é©¬å°”å¯å¤«é“¾å¤å¼: {front_str} + {back_str}")
                    print(f"    å‰åŒº: {pred['front_count']} ä¸ªå·ç ")
                    print(f"    ååŒº: {pred['back_count']} ä¸ªå·ç ")
                    print(f"    æ€»ç»„åˆæ•°: {pred['total_combinations']} æ³¨")
                    print(f"    æ€»æŠ•æ³¨é¢: {pred['total_cost']} å…ƒ")
                    print(f"    ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
                    print(f"    åˆ†ææœŸæ•°: {pred.get('analysis_periods', 500)}")
                    if 'markov_details' in pred:
                        details = pred['markov_details']
                        print(f"    è½¬ç§»çŸ©é˜µè§„æ¨¡: {details.get('transition_matrix_size', 0)}")
                        print(f"    çŠ¶æ€æ•°é‡: {details.get('state_count', 0)}")
                        print(f"    é¢„æµ‹å‡†ç¡®æ€§: {details.get('prediction_accuracy', 0):.3f}")

                else:
                    # å•å¼æŠ•æ³¨æ˜¾ç¤º
                    front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])
                    method = pred.get('method', args.method)
                    confidence = pred.get('confidence', 0.5)

                    print(f"  ç¬¬ {i+1} æ³¨: {front_str} + {back_str} (æ–¹æ³•: {method}, ç½®ä¿¡åº¦: {confidence:.3f})")

            # ä¿å­˜é¢„æµ‹ç»“æœ
            if args.save:
                import json

                # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                output_dir = "output/predictions"
                os.makedirs(output_dir, exist_ok=True)

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                if args.save.endswith('.json'):
                    filename = os.path.join(output_dir, args.save)
                else:
                    filename = os.path.join(output_dir, f"predictions_{args.method}_{timestamp}.json")

                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(predictions, f, ensure_ascii=False, indent=2, default=str)

                print(f"ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜: {filename}")
        
        except Exception as e:
            logger_manager.error("é¢„æµ‹å¤±è´¥", e)
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")

    def _display_predictions(self, predictions, method):
        """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
        if not predictions:
            print("âŒ æ²¡æœ‰ç”Ÿæˆé¢„æµ‹ç»“æœ")
            return

        print(f"âœ… {method.upper()}é¢„æµ‹å®Œæˆ")
        print("=" * 50)

        if isinstance(predictions, list):
            for i, pred in enumerate(predictions, 1):
                if isinstance(pred, tuple) and len(pred) == 2:
                    front, back = pred
                    print(f"ç¬¬{i}æ³¨: å‰åŒº {front} ååŒº {back}")
                elif isinstance(pred, dict):
                    if 'front' in pred and 'back' in pred:
                        print(f"ç¬¬{i}æ³¨: å‰åŒº {pred['front']} ååŒº {pred['back']}")
                    else:
                        print(f"ç¬¬{i}æ³¨: {pred}")
                else:
                    print(f"ç¬¬{i}æ³¨: {pred}")
        else:
            print(f"é¢„æµ‹ç»“æœ: {predictions}")

        print("=" * 50)

    def _display_enhanced_predictions(self, predictions, method):
        """æ˜¾ç¤ºå¢å¼ºé¢„æµ‹ç»“æœ"""
        if not predictions:
            print("âŒ æ²¡æœ‰ç”Ÿæˆé¢„æµ‹ç»“æœ")
            return

        print(f"âœ… {method.upper()}æ·±åº¦å­¦ä¹ é¢„æµ‹å®Œæˆ")
        print("=" * 60)

        for i, pred in enumerate(predictions, 1):
            if isinstance(pred, dict):
                front = pred.get('front', [])
                back = pred.get('back', [])
                confidence = pred.get('confidence', 0.0)
                pred_method = pred.get('method', method)

                print(f"ç¬¬{i}æ³¨ [{pred_method}]:")
                print(f"  å‰åŒº: {' '.join(f'{n:02d}' for n in front)}")
                print(f"  ååŒº: {' '.join(f'{n:02d}' for n in back)}")
                print(f"  ç½®ä¿¡åº¦: {confidence:.1%}")
                print()
            else:
                print(f"ç¬¬{i}æ³¨: {pred}")

        print("=" * 60)
        print(f"ğŸ¯ ä½¿ç”¨{method.upper()}æ·±åº¦å­¦ä¹ ç®—æ³•ç”Ÿæˆ {len(predictions)} æ³¨é¢„æµ‹")
        print("ğŸ’¡ æ·±åº¦å­¦ä¹ æ¨¡å‹å·²è‡ªåŠ¨è®­ç»ƒå¹¶ä¼˜åŒ–å‚æ•°")

    def run_learn_command(self, args):
        """å¤„ç†å­¦ä¹ å‘½ä»¤"""
        self._load_adaptive_predictor()
        
        print(f"ğŸš€ å¼€å§‹è‡ªé€‚åº”å­¦ä¹  (ç®—æ³•: {args.algorithm})...")
        print(f"ğŸ“Š èµ·å§‹æœŸæ•°: {args.start}, æµ‹è¯•æœŸæ•°: {args.test}")
        
        try:
            # è®¾ç½®å¤šè‡‚è€è™æœºç®—æ³•
            self.adaptive_predictor.bandit.algorithm = args.algorithm
            
            # è¿›è¡Œå­¦ä¹ 
            results = self.adaptive_predictor.enhanced_adaptive_learning(
                start_period=args.start,
                test_periods=args.test
            )
            
            if results:
                print("âœ… è‡ªé€‚åº”å­¦ä¹ å®Œæˆ!")
                print(f"ğŸ“Š ä¸­å¥–ç‡: {results['win_rate']:.3f}")
                print(f"ğŸ“ˆ å¹³å‡å¾—åˆ†: {results['average_score']:.2f}")
                print(f"ğŸ¯ æ€»æµ‹è¯•æœŸæ•°: {results['total_periods']}")
                
                # æ˜¾ç¤ºé¢„æµ‹å™¨æ€§èƒ½
                print("\nğŸ† é¢„æµ‹å™¨æ€§èƒ½æ’å:")
                bandit_values = results['bandit_final_values']
                predictor_names = self.adaptive_predictor.predictor_names
                
                performance_ranking = sorted(
                    zip(predictor_names, bandit_values), 
                    key=lambda x: x[1], 
                    reverse=True
                )
                
                for i, (name, value) in enumerate(performance_ranking[:5]):
                    print(f"  {i+1}. {name}: {value:.3f}")
                
                # ä¿å­˜å­¦ä¹ ç»“æœ
                output_dir = "output/learning"
                os.makedirs(output_dir, exist_ok=True)

                if args.save:
                    if args.save.endswith('.json'):
                        filename = os.path.join(output_dir, args.save)
                    else:
                        filename = os.path.join(output_dir, f"{args.save}.json")
                else:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = os.path.join(output_dir, f"learning_{args.algorithm}_{timestamp}.json")

                saved_file = self.adaptive_predictor.save_enhanced_results(filename)
                if saved_file:
                    print(f"ğŸ’¾ å­¦ä¹ ç»“æœå·²ä¿å­˜: {saved_file}")
            else:
                print("âŒ è‡ªé€‚åº”å­¦ä¹ å¤±è´¥")
        
        except Exception as e:
            logger_manager.error("å­¦ä¹ å¤±è´¥", e)
            print(f"âŒ å­¦ä¹ å¤±è´¥: {e}")
    
    def run_smart_command(self, args):
        """å¤„ç†æ™ºèƒ½é¢„æµ‹å‘½ä»¤"""
        self._load_adaptive_predictor()

        # ç¡®å®šé¢„æµ‹ç±»å‹
        if args.compound:
            print(f"ğŸ§  æ™ºèƒ½å¤å¼é¢„æµ‹ ({args.front_count}+{args.back_count})...")
        elif args.duplex:
            print(f"ğŸ§  æ™ºèƒ½èƒ†æ‹–é¢„æµ‹ (å‰åŒº{args.front_dan}èƒ†{args.front_tuo}æ‹–, ååŒº{args.back_dan}èƒ†{args.back_tuo}æ‹–)...")
        else:
            print(f"ğŸ§  æ™ºèƒ½é¢„æµ‹ (æ³¨æ•°: {args.count})...")

        try:
            # åŠ è½½å­¦ä¹ ç»“æœ
            if args.load:
                if self.adaptive_predictor.load_enhanced_results(args.load):
                    print(f"âœ… å·²åŠ è½½å­¦ä¹ ç»“æœ: {args.load}")
                else:
                    print(f"âŒ åŠ è½½å­¦ä¹ ç»“æœå¤±è´¥: {args.load}")
                    return
            else:
                print("âš ï¸  æœªåŠ è½½å­¦ä¹ ç»“æœï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

            # æ ¹æ®ç±»å‹ç”Ÿæˆé¢„æµ‹
            if args.compound:
                # å¤å¼æŠ•æ³¨é¢„æµ‹
                result = self.adaptive_predictor.smart_predict_compound(
                    front_count=args.front_count,
                    back_count=args.back_count,
                    periods=args.periods
                )

                if result:
                    print("âœ… æ™ºèƒ½å¤å¼é¢„æµ‹å®Œæˆ!")
                    print("\nğŸ§  æ™ºèƒ½å¤å¼é¢„æµ‹ç»“æœ:")

                    front_str = ' '.join([str(b).zfill(2) for b in result['front_balls']])
                    back_str = ' '.join([str(b).zfill(2) for b in result['back_balls']])

                    print(f"  å¤å¼å·ç : {front_str} + {back_str}")
                    print(f"  å‰åŒº: {result['front_count']} ä¸ªå·ç ")
                    print(f"  ååŒº: {result['back_count']} ä¸ªå·ç ")
                    print(f"  æ€»ç»„åˆæ•°: {result['total_combinations']} æ³¨")
                    print(f"  æ€»æŠ•æ³¨é¢: {result['total_cost']} å…ƒ")
                    print(f"  ç½®ä¿¡åº¦: {result['confidence']:.3f}")
                    print(f"  ä½¿ç”¨é¢„æµ‹å™¨: {result['top_predictors']}")
                else:
                    print("âŒ æ™ºèƒ½å¤å¼é¢„æµ‹å¤±è´¥")

            elif args.duplex:
                # èƒ†æ‹–æŠ•æ³¨é¢„æµ‹
                result = self.adaptive_predictor.smart_predict_duplex(
                    front_dan_count=args.front_dan,
                    back_dan_count=args.back_dan,
                    front_tuo_count=args.front_tuo,
                    back_tuo_count=args.back_tuo,
                    periods=args.periods
                )

                if result:
                    print("âœ… æ™ºèƒ½èƒ†æ‹–é¢„æµ‹å®Œæˆ!")
                    print("\nğŸ§  æ™ºèƒ½èƒ†æ‹–é¢„æµ‹ç»“æœ:")

                    front_dan_str = ' '.join([str(b).zfill(2) for b in result['front_dan']])
                    front_tuo_str = ' '.join([str(b).zfill(2) for b in result['front_tuo']])
                    back_dan_str = ' '.join([str(b).zfill(2) for b in result['back_dan']])
                    back_tuo_str = ' '.join([str(b).zfill(2) for b in result['back_tuo']])

                    print(f"  å‰åŒºèƒ†ç : {front_dan_str}")
                    print(f"  å‰åŒºæ‹–ç : {front_tuo_str}")
                    print(f"  ååŒºèƒ†ç : {back_dan_str}")
                    print(f"  ååŒºæ‹–ç : {back_tuo_str}")
                    print(f"  æ€»ç»„åˆæ•°: {result['total_combinations']} æ³¨")
                    print(f"  æ€»æŠ•æ³¨é¢: {result['total_cost']} å…ƒ")
                    print(f"  ç½®ä¿¡åº¦: {result['confidence']:.3f}")
                    print(f"  æœ€ä¼˜é¢„æµ‹å™¨: {result['best_predictor']}")
                else:
                    print("âŒ æ™ºèƒ½èƒ†æ‹–é¢„æµ‹å¤±è´¥")

            else:
                # å•å¼æŠ•æ³¨é¢„æµ‹
                predictions = self.adaptive_predictor.generate_enhanced_prediction(args.count)

                if predictions:
                    print("âœ… æ™ºèƒ½é¢„æµ‹å®Œæˆ!")
                    print("\nğŸ§  æ™ºèƒ½é¢„æµ‹ç»“æœ:")

                    for pred in predictions:
                        front_str = ' '.join([str(b).zfill(2) for b in pred['front_balls']])
                        back_str = ' '.join([str(b).zfill(2) for b in pred['back_balls']])
                        predictor = pred['predictor_used']
                        confidence = pred['confidence']
                        expected_reward = pred['expected_reward']

                        print(f"  ç¬¬ {pred['index']} æ³¨: {front_str} + {back_str}")
                        print(f"    é¢„æµ‹å™¨: {predictor}")
                        print(f"    ç½®ä¿¡åº¦: {confidence:.3f}")
                        print(f"    æœŸæœ›å¥–åŠ±: {expected_reward:.3f}")
                else:
                    print("âŒ æ™ºèƒ½é¢„æµ‹å¤±è´¥")

        except Exception as e:
            logger_manager.error("æ™ºèƒ½é¢„æµ‹å¤±è´¥", e)
            print(f"âŒ æ™ºèƒ½é¢„æµ‹å¤±è´¥: {e}")

    def run_optimize_command(self, args):
        """å¤„ç†å‚æ•°ä¼˜åŒ–å‘½ä»¤"""
        self._load_adaptive_predictor()

        print(f"âš™ï¸ å‚æ•°ä¼˜åŒ– (æµ‹è¯•æœŸæ•°: {args.test_periods}, ä¼˜åŒ–è½®æ•°: {args.rounds})...")

        try:
            # è¿›è¡Œå‚æ•°ä¼˜åŒ–
            results = self.adaptive_predictor.parameter_optimization(
                test_periods=args.test_periods,
                optimization_rounds=args.rounds
            )

            if results:
                print("âœ… å‚æ•°ä¼˜åŒ–å®Œæˆ!")
                print(f"\nğŸ† æœ€ä½³å‚æ•°:")
                for param, value in results['best_params'].items():
                    print(f"  {param}: {value}")

                print(f"\nğŸ“Š æœ€ä½³å¾—åˆ†: {results['best_score']:.3f}")

                print(f"\nğŸ“ˆ ä¼˜åŒ–å†å²:")
                for history in results['optimization_history'][-5:]:  # æ˜¾ç¤ºæœ€å5è½®
                    print(f"  è½®æ¬¡ {history['round']}: å¾—åˆ† {history['score']:.3f}, ä¸­å¥–ç‡ {history['win_rate']:.3f}")

                # ä¿å­˜ä¼˜åŒ–ç»“æœ
                if args.save:
                    import json

                    output_dir = "output/optimization"
                    os.makedirs(output_dir, exist_ok=True)

                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    if args.save.endswith('.json'):
                        filename = os.path.join(output_dir, args.save)
                    else:
                        filename = os.path.join(output_dir, f"optimization_{timestamp}.json")

                    with open(filename, 'w', encoding='utf-8') as f:
                        json.dump(results, f, ensure_ascii=False, indent=2, default=str)

                    print(f"ğŸ’¾ ä¼˜åŒ–ç»“æœå·²ä¿å­˜: {filename}")
            else:
                print("âŒ å‚æ•°ä¼˜åŒ–å¤±è´¥")

        except Exception as e:
            logger_manager.error("å‚æ•°ä¼˜åŒ–å¤±è´¥", e)
            print(f"âŒ å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")

    def run_backtest_command(self, args):
        """å¤„ç†å›æµ‹å‘½ä»¤"""
        self._load_predictors()

        print(f"ğŸ“ˆ å¼€å§‹å†å²å›æµ‹ (æ–¹æ³•: {args.method})...")
        print(f"ğŸ“Š èµ·å§‹æœŸæ•°: {args.start}, æµ‹è¯•æœŸæ•°: {args.test}")

        try:
            from adaptive_learning_modules import AccuracyTracker

            # åˆ›å»ºå‡†ç¡®ç‡è·Ÿè¸ªå™¨
            tracker = AccuracyTracker()

            # è·å–æ•°æ®
            df = data_manager.get_data()
            if df is None or len(df) < args.start + args.test:
                print("âŒ æ•°æ®ä¸è¶³")
                return

            total_predictions = 0
            total_wins = 0
            prize_stats = {}

            print(f"ğŸ”„ å¼€å§‹å›æµ‹...")

            for i in range(args.test):
                period_idx = args.start + i

                if period_idx >= len(df):
                    break

                # è·å–å½“å‰æœŸçš„çœŸå®å¼€å¥–å·ç 
                current_row = df.iloc[period_idx]
                actual_front, actual_back = data_manager.parse_balls(current_row)

                # è¿›è¡Œé¢„æµ‹
                try:
                    if args.method in ['frequency', 'hot_cold', 'missing']:
                        if args.method == 'frequency':
                            result = self.predictors['traditional'].frequency_predict(1)
                        elif args.method == 'hot_cold':
                            result = self.predictors['traditional'].hot_cold_predict(1)
                        elif args.method == 'missing':
                            result = self.predictors['traditional'].missing_predict(1)

                        predicted_front, predicted_back = result[0]

                    elif args.method in ['markov', 'bayesian', 'ensemble']:
                        if args.method == 'markov':
                            result = self.predictors['advanced'].markov_predict(1)
                        elif args.method == 'bayesian':
                            result = self.predictors['advanced'].bayesian_predict(1)
                        elif args.method == 'ensemble':
                            result = self.predictors['advanced'].ensemble_predict(1)

                        predicted_front, predicted_back = result[0]

                    else:
                        print(f"âŒ ä¸æ”¯æŒçš„å›æµ‹æ–¹æ³•: {args.method}")
                        return

                    # è®¡ç®—ä¸­å¥–æƒ…å†µ
                    prize_level, front_hits, back_hits = tracker._calculate_prize_level(
                        predicted_front, predicted_back, actual_front, actual_back
                    )

                    total_predictions += 1
                    if prize_level != "æœªä¸­å¥–":
                        total_wins += 1

                    # ç»Ÿè®¡ä¸­å¥–ç­‰çº§
                    prize_stats[prize_level] = prize_stats.get(prize_level, 0) + 1

                    # æ˜¾ç¤ºè¿›åº¦
                    if (i + 1) % 50 == 0:
                        win_rate = total_wins / total_predictions
                        print(f"  è¿›åº¦: {i+1}/{args.test}, ä¸­å¥–ç‡: {win_rate:.3f}")

                except Exception as e:
                    logger_manager.error(f"ç¬¬ {i+1} æœŸå›æµ‹å¤±è´¥", e)
                    continue

            # æ˜¾ç¤ºå›æµ‹ç»“æœ
            print("âœ… å›æµ‹å®Œæˆ!")
            print(f"\nğŸ“Š å›æµ‹ç»“æœç»Ÿè®¡:")
            print(f"  æ€»é¢„æµ‹æœŸæ•°: {total_predictions}")
            print(f"  ä¸­å¥–æœŸæ•°: {total_wins}")
            print(f"  ä¸­å¥–ç‡: {total_wins/total_predictions:.3f}" if total_predictions > 0 else "  ä¸­å¥–ç‡: 0.000")

            print(f"\nğŸ† ä¸­å¥–ç­‰çº§åˆ†å¸ƒ:")
            for prize, count in sorted(prize_stats.items()):
                rate = count / total_predictions if total_predictions > 0 else 0
                print(f"  {prize}: {count} æ¬¡ ({rate:.3f})")

        except Exception as e:
            logger_manager.error("å›æµ‹å¤±è´¥", e)
            print(f"âŒ å›æµ‹å¤±è´¥: {e}")

    def run_system_command(self, args):
        """å¤„ç†ç³»ç»Ÿç®¡ç†å‘½ä»¤"""
        if args.system_action == 'cache':
            if args.action == 'info':
                print("ğŸ’¾ ç¼“å­˜ä¿¡æ¯:")
                cache_info = cache_manager.get_cache_info()

                for cache_type in ['models', 'analysis', 'data']:
                    info = cache_info[cache_type]
                    print(f"  {cache_type}: {info['files']} ä¸ªæ–‡ä»¶, {info['size_mb']:.2f} MB")

                print(f"  æ€»è®¡: {cache_info['total']['files']} ä¸ªæ–‡ä»¶, {cache_info['total']['size_mb']:.2f} MB")

            elif args.action == 'clear':
                print(f"ğŸ—‘ï¸  æ¸…ç†{args.type}ç¼“å­˜...")
                cleared_count = cache_manager.clear_cache(args.type)
                print(f"âœ… å·²æ¸…ç† {cleared_count} ä¸ªç¼“å­˜æ–‡ä»¶")
    
    def run_enhanced_command(self, args):
        """è¿è¡Œå¢å¼ºåŠŸèƒ½å‘½ä»¤"""
        if not self.enhanced_available:
            print("âŒ å¢å¼ºåŠŸèƒ½ä¸å¯ç”¨")
            print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…enhanced_deep_learningæ¨¡å—")
            return

        if args.enhanced_action == 'info':
            print("ğŸ” å¢å¼ºç³»ç»Ÿä¿¡æ¯")
            print("=" * 50)

            info = self.enhanced_system.get_system_info()
            print(f"ç³»ç»Ÿç±»å‹: {info['system_type']}")

            if 'platform' in info:
                platform = info['platform']
                print(f"æ“ä½œç³»ç»Ÿ: {platform['os']} {platform['version']}")
                print(f"æ¶æ„: {platform['architecture']}")
                print(f"Pythonç‰ˆæœ¬: {platform['python_version']}")

                hardware = info['hardware']
                print(f"CPUæ ¸å¿ƒ: {hardware['cpu_count']}")
                print(f"å†…å­˜: {hardware['memory_total_gb']:.1f} GB")
                print(f"GPUæ•°é‡: {hardware['gpu_count']}")

        elif args.enhanced_action == 'test':
            print("ğŸ§ª è¿è¡Œå…¼å®¹æ€§æµ‹è¯•")
            print("=" * 50)

            result = self.enhanced_system.run_compatibility_test()
            if result.get('success'):
                for test in result['test_results']:
                    status_icon = 'âœ…' if test['status'] == 'passed' else 'âŒ'
                    print(f"{status_icon} {test['name']}: {test['message']} ({test['duration']:.2f}s)")
            else:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        elif args.enhanced_action == 'predict':
            print("ğŸ”® å¢å¼ºé¢„æµ‹")
            print("=" * 50)

            if not args.data:
                print("âŒ è¯·æä¾›é¢„æµ‹æ•°æ® (-d å‚æ•°)")
                return

            result = self.enhanced_system.enhanced_predict(args.data, method=args.method)
            if result.get('success'):
                print(f"âœ… é¢„æµ‹æˆåŠŸ")
                print(f"æ–¹æ³•: {result['method']}")
                print(f"ç»“æœ: {result['result']}")
                print(f"å·²ç¼“å­˜: {result['cached']}")
            else:
                print(f"âŒ é¢„æµ‹å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        elif args.enhanced_action == 'visualize':
            print("ğŸ“Š å¢å¼ºå¯è§†åŒ–")
            print("=" * 50)

            if not args.data:
                print("âŒ è¯·æä¾›å¯è§†åŒ–æ•°æ® (-d å‚æ•°)")
                return

            result = self.enhanced_system.enhanced_visualize(args.data, chart_type=args.type)
            if result.get('success'):
                print(f"âœ… å¯è§†åŒ–æˆåŠŸ")
                print(f"å›¾è¡¨ç±»å‹: {result['chart_type']}")
                print(f"ç»“æœ: {result['result']}")
            else:
                print(f"âŒ å¯è§†åŒ–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        else:
            print("âŒ æœªçŸ¥çš„å¢å¼ºåŠŸèƒ½æ“ä½œ")
            print("å¯ç”¨æ“ä½œ: info, test, predict, visualize")

    def show_version(self):
        """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
        print("ğŸ¯ å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿ")
        print("ç‰ˆæœ¬: 2.0.0 Enhanced")
        print("ä½œè€…: AI Assistant")
        print("æ›´æ–°æ—¶é—´: 2024-12-19")
        print("\nğŸ“¦ åŠŸèƒ½æ¨¡å—:")
        print("  âœ… æ•°æ®çˆ¬å–ä¸ç®¡ç†")
        print("  âœ… åŸºç¡€ä¸é«˜çº§åˆ†æ")
        print("  âœ… å¤šç§é¢„æµ‹ç®—æ³•")
        print("  âœ… è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿ")
        print("  âœ… æ™ºèƒ½é¢„æµ‹ä¸å›æµ‹")
        print("  âœ… ç¼“å­˜ä¸æ—¥å¿—ç®¡ç†")

        # æ˜¾ç¤ºå¢å¼ºåŠŸèƒ½çŠ¶æ€
        if self.enhanced_available:
            print("\nğŸš€ å¢å¼ºåŠŸèƒ½æ¨¡å—:")
            print("  âœ… ä¼ä¸šçº§æ ¸å¿ƒæ¶æ„")
            print("  âœ… é«˜çº§æ•°æ®å¤„ç†")
            print("  âœ… æ™ºèƒ½æ¨¡å‹æ³¨å†Œè¡¨")
            print("  âœ… å¢å¼ºé¢„æµ‹å¼•æ“")
            print("  âœ… äº¤äº’å¼å¯è§†åŒ–")
            print("  âœ… å·¥ä½œæµç®¡ç†")
            print("  âœ… è·¨å¹³å°å…¼å®¹æ€§")
            print("  âœ… åˆ†å¸ƒå¼è®¡ç®—")
            print("  âœ… æ€§èƒ½ä¼˜åŒ–")
            print("  âœ… æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ")
        else:
            print("\nâš ï¸ å¢å¼ºåŠŸèƒ½: æœªå¯ç”¨")
            print("  æç¤º: è¿è¡Œ 'python dlt_main.py enhanced info' æŸ¥çœ‹è¯¦æƒ…")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¤§ä¹é€é¢„æµ‹ç³»ç»Ÿ - ä¼˜åŒ–ç‰ˆ")
    
    # æ·»åŠ å­å‘½ä»¤
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ==================== æ•°æ®ç®¡ç†å‘½ä»¤ ====================
    data_parser = subparsers.add_parser('data', help='æ•°æ®ç®¡ç†')
    data_subparsers = data_parser.add_subparsers(dest='data_action', help='æ•°æ®æ“ä½œ')

    # æ•°æ®çŠ¶æ€
    data_status_parser = data_subparsers.add_parser('status', help='æŸ¥çœ‹æ•°æ®çŠ¶æ€')

    # æœ€æ–°å¼€å¥–ç»“æœ
    data_latest_parser = data_subparsers.add_parser('latest', help='è·å–æœ€æ–°å¼€å¥–ç»“æœ')
    data_latest_parser.add_argument('--compare', action='store_true', help='ä¸ç”¨æˆ·å·ç æ¯”è¾ƒ')

    # æ•°æ®æ›´æ–°
    data_update_parser = data_subparsers.add_parser('update', help='æ›´æ–°æ•°æ®')
    data_update_parser.add_argument('--source', choices=['zhcw'], default='zhcw', help='æ•°æ®æº')
    data_update_parser.add_argument('--periods', type=int, help='æ›´æ–°æŒ‡å®šæœŸæ•°')
    data_update_parser.add_argument('--incremental', action='store_true', help='å¢é‡æ›´æ–°ï¼ˆåªè·å–æœ€æ–°æ•°æ®ï¼‰')
    
    # ==================== åˆ†æå‘½ä»¤ ====================
    analyze_parser = subparsers.add_parser('analyze', help='æ•°æ®åˆ†æ')
    analyze_parser.add_argument('-t', '--type', choices=['basic', 'advanced', 'comprehensive'],
                               default='comprehensive', help='åˆ†æç±»å‹')
    analyze_parser.add_argument('-p', '--periods', type=int, default=500, help='åˆ†ææœŸæ•°')
    analyze_parser.add_argument('--report', action='store_true', help='ç”Ÿæˆåˆ†ææŠ¥å‘Š')
    analyze_parser.add_argument('--visualize', action='store_true', help='ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨')
    analyze_parser.add_argument('--save', help='ä¿å­˜åˆ†æç»“æœ')

    # ==================== é¢„æµ‹å‘½ä»¤ ====================
    predict_parser = subparsers.add_parser('predict', help='å·ç é¢„æµ‹')
    predict_parser.add_argument('-m', '--method',
                               choices=['frequency', 'hot_cold', 'missing', 'markov', 'bayesian',
                                       'ensemble', 'super', 'adaptive', 'compound', 'duplex', 'markov_custom',
                                       'mixed_strategy', 'highly_integrated', 'advanced_integration',
                                       'nine_models', 'nine_models_compound', 'markov_compound',
                                       'lstm', 'transformer', 'gan', 'stacking', 'adaptive_ensemble', 'ultimate_ensemble',
                                       'markov_2nd', 'markov_3rd', 'adaptive_markov', 'enhanced'],
                               default='ensemble', help='é¢„æµ‹æ–¹æ³•')
    predict_parser.add_argument('--ensemble-method', choices=['stacking', 'weighted', 'adaptive'],
                               default='stacking', help='é«˜çº§é›†æˆæ–¹æ³•ç±»å‹')
    predict_parser.add_argument('-c', '--count', type=int, default=1, help='ç”Ÿæˆæ³¨æ•° (1-100)')
    predict_parser.add_argument('-p', '--periods', type=int, default=500, help='åˆ†ææœŸæ•° (50-2748ï¼Œé»˜è®¤500æœŸ)')
    predict_parser.add_argument('--front-count', type=int, default=8, help='å¤å¼æŠ•æ³¨å‰åŒºå·ç æ•°é‡')
    predict_parser.add_argument('--back-count', type=int, default=4, help='å¤å¼æŠ•æ³¨ååŒºå·ç æ•°é‡')
    predict_parser.add_argument('--analysis-periods', type=int, default=300, help='é©¬å°”å¯å¤«åˆ†ææœŸæ•°')
    predict_parser.add_argument('--predict-periods', type=int, default=1, help='é©¬å°”å¯å¤«é¢„æµ‹æœŸæ•°')
    predict_parser.add_argument('--strategy', choices=['conservative', 'aggressive', 'balanced'],
                               default='balanced', help='æ··åˆç­–ç•¥ç±»å‹')
    predict_parser.add_argument('--integration-level', choices=['high', 'ultimate'],
                               default='ultimate', help='é«˜åº¦é›†æˆçº§åˆ«')
    predict_parser.add_argument('--integration-type', choices=['comprehensive', 'markov_bayesian', 'hot_cold_markov', 'multi_dimensional'],
                               default='comprehensive', help='é«˜çº§é›†æˆåˆ†æç±»å‹')
    predict_parser.add_argument('--markov-periods', type=int, default=500, help='é©¬å°”å¯å¤«åˆ†ææœŸæ•°')
    predict_parser.add_argument('--save', help='ä¿å­˜é¢„æµ‹ç»“æœ')
    
    # ==================== è‡ªé€‚åº”å­¦ä¹ å‘½ä»¤ ====================
    learn_parser = subparsers.add_parser('learn', help='è‡ªé€‚åº”å­¦ä¹ ')
    learn_parser.add_argument('-s', '--start', type=int, default=100, help='èµ·å§‹æœŸæ•°')
    learn_parser.add_argument('-t', '--test', type=int, default=1000, help='æµ‹è¯•æœŸæ•°')
    learn_parser.add_argument('--algorithm', choices=['epsilon_greedy', 'ucb1', 'thompson_sampling'], 
                             default='ucb1', help='å¤šè‡‚è€è™æœºç®—æ³•')
    learn_parser.add_argument('--save', help='ä¿å­˜å­¦ä¹ ç»“æœ')
    
    # ==================== æ™ºèƒ½é¢„æµ‹å‘½ä»¤ ====================
    smart_parser = subparsers.add_parser('smart', help='æ™ºèƒ½é¢„æµ‹ï¼ˆåŸºäºå­¦ä¹ ç»“æœï¼‰')
    smart_parser.add_argument('-c', '--count', type=int, default=1, help='ç”Ÿæˆæ³¨æ•°')
    smart_parser.add_argument('-p', '--periods', type=int, default=500, help='åˆ†ææœŸæ•°')
    smart_parser.add_argument('--load', help='åŠ è½½å­¦ä¹ ç»“æœæ–‡ä»¶')
    smart_parser.add_argument('--compound', action='store_true', help='ç”Ÿæˆå¤å¼æŠ•æ³¨')
    smart_parser.add_argument('--front-count', type=int, default=8, help='å¤å¼å‰åŒºå·ç æ•°é‡')
    smart_parser.add_argument('--back-count', type=int, default=4, help='å¤å¼ååŒºå·ç æ•°é‡')
    smart_parser.add_argument('--duplex', action='store_true', help='ç”Ÿæˆèƒ†æ‹–æŠ•æ³¨')
    smart_parser.add_argument('--front-dan', type=int, default=2, help='å‰åŒºèƒ†ç æ•°é‡')
    smart_parser.add_argument('--back-dan', type=int, default=1, help='ååŒºèƒ†ç æ•°é‡')
    smart_parser.add_argument('--front-tuo', type=int, default=6, help='å‰åŒºæ‹–ç æ•°é‡')
    smart_parser.add_argument('--back-tuo', type=int, default=4, help='ååŒºæ‹–ç æ•°é‡')

    # ==================== å‚æ•°ä¼˜åŒ–å‘½ä»¤ ====================
    optimize_parser = subparsers.add_parser('optimize', help='å‚æ•°ä¼˜åŒ–')
    optimize_parser.add_argument('-t', '--test-periods', type=int, default=100, help='æµ‹è¯•æœŸæ•°')
    optimize_parser.add_argument('-r', '--rounds', type=int, default=10, help='ä¼˜åŒ–è½®æ•°')
    optimize_parser.add_argument('--save', help='ä¿å­˜ä¼˜åŒ–ç»“æœ')

    # ==================== å›æµ‹å‘½ä»¤ ====================
    backtest_parser = subparsers.add_parser('backtest', help='å†å²å›æµ‹')
    backtest_parser.add_argument('-s', '--start', type=int, default=100, help='èµ·å§‹æœŸæ•°')
    backtest_parser.add_argument('-t', '--test', type=int, default=500, help='æµ‹è¯•æœŸæ•°')
    backtest_parser.add_argument('-m', '--method',
                                choices=['frequency', 'hot_cold', 'missing', 'markov', 'bayesian', 'ensemble'],
                                default='ensemble', help='é¢„æµ‹æ–¹æ³•')

    # ==================== ç³»ç»Ÿç®¡ç†å‘½ä»¤ ====================
    system_parser = subparsers.add_parser('system', help='ç³»ç»Ÿç®¡ç†')
    system_subparsers = system_parser.add_subparsers(dest='system_action', help='ç³»ç»Ÿæ“ä½œ')
    
    # ç¼“å­˜ç®¡ç†
    cache_parser = system_subparsers.add_parser('cache', help='ç¼“å­˜ç®¡ç†')
    cache_parser.add_argument('action', choices=['info', 'clear'], help='ç¼“å­˜æ“ä½œ')
    cache_parser.add_argument('--type', choices=['all', 'models', 'analysis', 'data'], 
                             default='all', help='ç¼“å­˜ç±»å‹')
    
    # ==================== å¢å¼ºåŠŸèƒ½å‘½ä»¤ ====================
    enhanced_parser = subparsers.add_parser('enhanced', help='å¢å¼ºåŠŸèƒ½')
    enhanced_subparsers = enhanced_parser.add_subparsers(dest='enhanced_action', help='å¢å¼ºåŠŸèƒ½æ“ä½œ')

    # ç³»ç»Ÿä¿¡æ¯
    info_parser = enhanced_subparsers.add_parser('info', help='æ˜¾ç¤ºå¢å¼ºç³»ç»Ÿä¿¡æ¯')

    # å…¼å®¹æ€§æµ‹è¯•
    compat_parser = enhanced_subparsers.add_parser('test', help='è¿è¡Œå…¼å®¹æ€§æµ‹è¯•')

    # å¢å¼ºé¢„æµ‹
    epredict_parser = enhanced_subparsers.add_parser('predict', help='å¢å¼ºé¢„æµ‹')
    epredict_parser.add_argument('-d', '--data', help='é¢„æµ‹æ•°æ®')
    epredict_parser.add_argument('-m', '--method', default='auto', help='é¢„æµ‹æ–¹æ³•')

    # å¢å¼ºå¯è§†åŒ–
    evisualize_parser = enhanced_subparsers.add_parser('visualize', help='å¢å¼ºå¯è§†åŒ–')
    evisualize_parser.add_argument('-d', '--data', help='å¯è§†åŒ–æ•°æ®')
    evisualize_parser.add_argument('-t', '--type', default='auto', help='å›¾è¡¨ç±»å‹')

    # ==================== å¸®åŠ©å’Œç‰ˆæœ¬ ====================
    version_parser = subparsers.add_parser('version', help='æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = DLTPredictorSystem()
    
    # æ‰§è¡Œå¯¹åº”çš„å‘½ä»¤
    try:
        if args.command == 'data':
            system.run_data_command(args)
        elif args.command == 'analyze':
            system.run_analyze_command(args)
        elif args.command == 'predict':
            system.run_predict_command(args)
        elif args.command == 'learn':
            system.run_learn_command(args)
        elif args.command == 'smart':
            system.run_smart_command(args)
        elif args.command == 'optimize':
            system.run_optimize_command(args)
        elif args.command == 'backtest':
            system.run_backtest_command(args)
        elif args.command == 'system':
            system.run_system_command(args)
        elif args.command == 'enhanced':
            system.run_enhanced_command(args)
        elif args.command == 'version':
            system.show_version()
    except KeyboardInterrupt:
        print("\nâš ï¸  æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        task_manager.interrupt_current_task()
    except Exception as e:
        logger_manager.error("å‘½ä»¤æ‰§è¡Œå¤±è´¥", e)
        print(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
